## day 6 - 서버측의 LAN에는 무엇이 있는가? 
- 웹 서버의 설치 장소 
- 방화벽의 원리와 동작
- 복수 서버에 리퀘스트를 분배한 서버의 부하 분산
- 캐시 서버를 이용한 서버의 부하 분산
- 콘텐츠 배포 서비스

### 01. 웹 서버의 설치 장소
#### 사내에 웹 서버를 설치하는 경우
![img](https://github.com/koni114/TIL/blob/master/Network/books/one_percent_network/img/network_22.png)
- 인터넷을 빠져나와 서버에 도착할 때까지의 여정은 서버의 설치 장소에 따라 다름
- 가장 간단한 것은 위의 그림의 (a)와 같이 사내 LAN에 서버를 설치하고, 인터넷에서 직접 엑세스 하는 경우
- 이 방법은 주류에서 밀려났는데, 크게 2가지 이유
  - IP 주소의 부족. 사내 LANd에 설치한 기기에는 서버뿐만 아니라 클라이언트에도 글로벌 주소를 할당해야 함
  - 보안상의 이유. 인터넷에서 도착하는 패킷을 차단하는 것이 아니기 때문
- 지금은 (b)와 같이 방화벽을 두는 것이 일반화 됨
- <b>방화벽은 특정 서버에서 동작하는 특정 어플리케이션에 엑세스하는 패킷만 통과시키고, 그 외의 패킷은 차단하는 역할 수행</b>
- 이렇게 되면 애플리케이션에 보안 구멍이 있어도 위험성이 적어짐  
  위험성이 완전히 없어지지는 않는데, 그 이유는 엑세스를 허가한 애플리케이션에 보안 구멍이 있으면 공격받을 위험성이 남아있기 때문

#### 데이터센터에 웹 서버를 설치하는 경우
- 프로바이더가 소유하는 서버를 빌려쓰는 형태로 운영하는 경우도 있음
- 인터넷의 중심 부분에 고속 회선으로 접속되었으므로 여기에 서버를 설치하면 고속으로 엑세스 할 수 있음

### 02. 방화벽의 원리와 동작
#### 패킷 필터링형이 주류이다
- 서버의 설치 장소와 관계 없이 지금은 바로 앞에 방화벽이 있는 것이 보통임
- 네트워크에는 다양한 종류의 패킷이 많이 흐르는데, 이 중 통과시킬 패킷과 차단할 패킷을 구분하는 것은 간단한 일이 아니기 때문에 지금까지 다양한 방법이 고안됨
- 그 중에서 가장 보편화 된 것이 패킷 필터링형이 가장 많이 보급됨

#### 패킷 필터링의 조건 설정 개념
![img](https://github.com/koni114/TIL/blob/master/Network/books/one_percent_network/img/network_23.png)

- 공개용 서버를 설치하는 LAN과 사내 LAN이 분리되어 있고, 웹 서버는 공개용 서버 LAN에 접속되어 있다고 가정해보자
- <b>인터넷에서 웹 서버에 대한 액세스를 허가하지 않으면 웹서버에서 인터넷의 액세스를 금지하도록 패킷을 차단</b>
- 이전에는 <b>웹 서버에서 인터넷측에 대한 액세스를 금지하는 예가 적었음</b> 하지만 최근에는 부정 소프트웨어의 감염을 막기위해 웹 서버에서 인터넷측에 액세스하는 것을 금지하고 있음

- 패킷 필터링의 개념
  - 인터넷에서 흘러들어오는 패킷의 시점은 지정할 수 없지만, 흐름의 종점은 웹 서버가 되므로 이것을 조건으로 설정하고 조건에 해당하는 패킷만 통과시킴
  - 송신처 IP 주소에 따라 시점을 지정할 수 있으면 이것도 조건에 추가함
  - 패킷을 받으면 정확하게 도착했는지를 송신측에 알리는 수신 확인 응답의 구조가 작용함으로 웹 서버에서 인터넷측으로 흐르는 패킷도 있음
  - 웹 서버에서 클라이언트에 보내는 데이터가 있고, 이 패킷도 웹 서버에서 인터넷측으로 흘러간 후 그곳에서 시점이 웹 서버의 주소에 일치하는 패킷도 통과함
  - 이와 같이 수신처나 송신처의 주소에 따라 패킷이 어디서, 어디로 흘러들어가는지를 판단하여 통과시킬 것인지, 차단할 것인지 결정하는 것이 첫걸음

#### 애플리케이션을 한정할 때 포트 번호를 사용한다.
- 위의 시작점, 종단점을 파악하는 방법만 수행한다면, 인터넷과 웹 서버 사이를 흐르는 패킷은 전부 통과해서 위험하게 됨
- 따라서 추가적으로 TCP 헤더나 UDP 헤더에 기록되어 있는 포트 번호를 조건으로 추가
- 예를 들어 웹 서버의 포트는 80번으로 고정되어 있으므로, 수신처 IP 주소 및 송신처 IP 주소의 수신처 포트 번호가 80번인 경우 추가

#### 컨트롤 비트로 접속 방향을 판단한다
- 위의 두가지만 가지고는 웹 서버에서 인터넷측에 액세스하는 동작을 정지시킬 수 없음
- 웹의 동작은 TCP 프로토콜을 사용하여 양방향으로 패킷이 흐르므로, 패킷이 흐르는 방향이 아니라 액세스 방향을 판단하여 정지시켜야 하는데, 여기에서 도움이 되는 것이 TCP 헤더에 있는 컨트롤 비트
- 최초 흐르는 패킷에는 SYN = 1, ACK = 0 이 됨으로, 최초의 패킷과 두 번째 이후의 패킷을 판별할 수 있음
- 최초의 패킷이 웹 서버 측에서 인터넷 측으로 흘러들어가는 것을 차단하면, 접속 동작이 반드시 실패하므로 웹 서버 -> 인터넷 액세스 동작을 막을 수 있음
- 다양한 조건(수신처 IP 주소, 송신처 IP 주소, 수신처, 송신처 포트 번호, TCP 컨트롤 비트)을 조합해서 <b>대상이 되는 패킷</b>을 찾아내서 통과시킴
- 위험한 것을 차단하고 나머지를 통과시키는 방법이라면 미지의 위험함 패킷을 통과시킬 가능성이 있음

#### 사내 LAN에서 공개 서버용 LAN으로 조건을 설정한다
- 위의 [5-2] 같은 경우 인터넷 <-> 공개 서버용 LAN, 사내 LAN <-> 공개 서버용 LAN 을 왕래하는 패킷의 조건도 설정해 주어야 함

#### 밖에서 사내 LAN으로 엑세스할 수 없다
- 주소 변환을 사용(private address <-> public address)하면 인터넷측에서 사내 LAN에는 접근할 수 없음

#### 방화벽을 통과한다
- 방화벽에는 여러 가지 조건이 설정되어 있음.  
  패킷이 도착하면 조건에 해당하는지 판정하고, 통과시킬지와 차단할지를 결정
- 차단하는 대상이 되면 패킷을 버리고, 버린 기록을 남김  
  (패킷 필터링 기능을 가진 라우터의 경우 패킷 기록을 남기는 경우는 드뭄. 저장 공간 이슈)
- 일단 통과시킨다고 결정되면 그 이상의 특별한 구조는 없음
- 패킷 필터링이라는 구조는 방화벽용 특별한 구조라고 생각할 것이 아니라 라우터의 패킷 중계 기능 중에서 부가 기능이라고 생각하는 것이 좋음
- 단 판정 조건이 복잡해지면 라우터의 명령으로 설정하기가 어려워지고, 패킷을 버린 기록을 남기는 것도 라우터에 크게 부담스러운 큰 작업이기 때문에 전용 H/W, S/W를 사용하는 것
- <b>패킷 필터링형 방화벽은 수신처 IP 주소, 송신처 IP 주소, 수신처 포트 번호, 송신처 포트 번호, 컨트롤 비트 등으로 패킷을 통과시킬지 판단함</b>

#### 방화벽으로 막을 수 없는 공격
- 방화벽은 시점과 종점의 정보를 기반으로 통과여부를 판단하는데, 예를 들어 웹서버에 좋지 않은 상태가 있어 특수한 데이터를 포한한 패킷을 받으면 웹 서버가 다운되는 상황에서 문제가 발생할 수 있음
- 위의 문제의 해결방법은 크게 2가지
  - 버그 자체를 해결
  - 패킷의 내용을 조사해서 위험한 데이터 여부를 파악하여 패킷 차단하거나 소프트웨어를 방화벽과는 별도로 준비하는 방법
- 위험한 데이터 여부 자체를(버그) 파악할 수 없는 경우도 있음

### 03. 복수 서버에 리퀘스트를 분배한 서버의 부하 분산
#### 처리 능력이 부족하면 복수 서버로 부하 분산된다
- 서버의 액세스가 증가할 때는 서버로 통하는 회선을 빠르게 하는 방법이 효과적이지만, 회선을 빠르게 하는 것만으로 부족한 경우도 있음
- 해결 방법은 '1. 고성능 서버로 교체, '2. 분산 처리 수행이 있음
- 분산 처리 수행 중 가장 간단한 방법은 <b>여러 대의 웹서버를 설치하고 한 대가 담당하는 사용자 수를 줄이는 방법</b>  
  이 방법을 취할 경우 클라이언트가 보내는 리퀘스트를 웹 서버에 분배하는 구조가 필요
- 그 중 하나는 <b>DNS 서버에서 분배하는 방법</b>이 가장 간단함  
  서버에 액세스할 때 DNS 서버에 조회하여 IP 조사시, DNS 서버에 같은 이름으로 여러 대의 웹 서버를 등록해 놓으면 DNS 서버는 조회가 있을 때마다 차례대로 IP 주소를 돌려줌
- 예를 들어, 3개의 IP 주소를 대응한다고 했을 때,  
  - `192.0.2.60`, `192.0.2.70`, `192.0.2.80`
  - `192.0.2.70`, `192.0.2.80`, `192.0.2.60`
  - `192.0.2.80`, `192.0.2.60`, `192.0.2.70`
- 1주기를 순환하고 돌아가는데, 이를 <b>라운드 로빈</b> 이라고 함. 이렇게 해서 복수의 서버를 균등하게 액세스를 분산시킬 수 있음
- 이 방법의 문제는 웹 서버가 많으면 이 중에서 고장나는 것도 있음  
  DNS 서버는 웹 서버가 동작하는지 확인하지 못하므로 웹 서버가 정지해도 상관하지 않고 IP 주소를 회답해버림
- 최근 브라우저는 IP 주소 액세스에 실패하면 다음 IP 주소를 시도함
- 또한 복수의 페이지(쿠팡에서 메인화면 -> 결제 화면 .. 연속적인 페이지)에 걸쳐 대화할 때, 웹 서버가 변하면 대화가 도중에 끊킬 수 있음

#### 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다 (중요!)
- 위에서 말한 fail-over 해결 불가, 연속 페이지 처리 문제 등을 해결하기 위해 <b>부하 분산 장치 또는 로드 벨런서</b> 라고 불리는 기기가 고안됨
- 로드 벨런서 사용할 때는 먼저 부하 분산 장치를 웹 서버 대신 DNS 서버에 등록
- 그러면 클라이언트는 로드 벨런서를 웹 서버라고 생각하여 리퀘스트 송부
- 핵심은 어느 웹 서버에 리퀘스트를 전송해야 할지 판단하는 것임.  
  - '1. 복수 페이지가 아닌 단순한 액세스라면 웹 서버의 부하 상태가 판단 근거가 됨  
    웹 서버와 정기적으로 정보를 교환하여 CPU나 메모리의 사용률 등을 수집하고, 이것을 바탕으로 어느 웹 서버에 부하가 낮은지 판단
  - '2. 시험 패킷을 웹 서버에 보내 응답 시간으로 부하를 판단하는 방법
  - '3. 위의 두 방법은 검사 자체가 네트워크 부하를 발생시키므로, 부하를 조사하지 않고 미리 웹 서버의 능력을 설정한 후 비율에 따라 리퀘스트를 분배 
- 대화가 복수 페이지에 걸쳐있을 때는 웹 서버의 부하와 상관 없이 이전의 리퀘스트와 같은 웹 서버에 전송해야 함
- 이러려면 대화가 복수 페이지에 걸쳐있는지 파악해야하는데, HTTP의 기본 동작은 리퀘스트 메세지를 보내기 전에 TCP의 접속 동작을 하고, 응답 메세지를 반송하면 연결을 끊음
- 그리고 다음에 웹 서버에 액세스할 때는 TCP의 접속 동작부터 다시 수행함
- <b>이것은 HTTP 프로토콜이 의도적으로 이렇게 하도록 만들어졌기 때문</b>
- 프록시를 사용하면 리퀘스트의 송신처 IP 주소가 프록시의 IP 주소로 되어 실제로 리퀘스트를 보낸 클라이언트가 누구인지 모르게 되기 때문
- 주소 변환도 중간의 public address <-> private address 구조로 되어있기 때문에 중간의 주소 변환 장치로 클라이언트를 판별할 수 없음
- 전후 관계를 판단하기 위해 여러가지 방법이 고안됨
  - 양식에 입력한 데이터를 보낼 때 그 안의 전후의 관련을 나타내는 정보를 부가
  - HTTP 사양을 확장하여 전후 관계를 판단하기 위한 정보를 HTTP 헤더 필드에 부가하는 방법(= 쿠키) 

### 04. 캐시 서버를 이용한 서버의 부하 분산
#### 캐시 서버의 이용
- DB 서버나 웹 서버의 역할에 따라 서버를 나누는 방법으로, 역할별 분산 처리 방법 중 하나인 캐시 서버를 사용하는 방법이 있음
- <b>캐시 서버는 프록시라는 구조를 사용하여 데이터를 캐시에 저장하는 서버</b>
- 프록시는 액세스 동작을 중개할 때, 웹 서버에서 받은 데이터를 디스크에 저장해 두고 웹 서버를 대신하여 데이터를 클라이언트에 반송하는 기능을 가지고 있음. 이를 <b>캐시</b>라고 부름 
- 웹 서버는 페이지의 데이터를 클라이언트에게 송신할 때 다소 시간이 걸림. 한편 캐시 서버는 웹 서버에서 받아 보존해둔 데이터를 클라이언트에게 송신하므로 웹 서버보다 빠르게 데이터를 송신할 수 있음
- 캐시에 데이터를 저장한 후 웹 서버 측에서 데이터가 변경되면 캐시의 데이터를 사용할 수 없음  
  따라서 언제든지 캐시의 데이터를 이용할 수 있는 것은 아님
- 액세스 동작의 일정 부분은 웹 서버를 번거롭게 하지 않고 캐시 서버에서 처리 가능
- 얼마라도 캐시 서버에서 액세스 동작을 고속화할 수 있으면 전체 성능이 향상됨

#### 캐시 서버는 갱신일로 콘텐츠를 관리한다
- 캐시 서버의 동작 살펴보기
- 캐시 서버를 웹 서버 대신 DNS 서버에 등록함
- 사용자는 캐시 서버에 HTTP request message를 보냄
- 캐시 서버는 해당 message를 받음
- 캐시 서버는 message 내용을 조사하여 데이터가 자신의 캐시에 저장되었는지 조사
- 위의 내용은 <b>'1. 캐시에 데이터가 있는 경우</b>와 <b>'2. 캐시에 데이터가 없는 경우</b>로 나뉨
- '1. 캐시에 데이터가 있는 경우
  - `If-Modified-Since` 라는 헤더 필드를 추가하여 웹 서버에 전송
  - 해당 헤더 필드의 값과 페이지 데이터의 최종 갱신 일자를 비교하여 변경이 없으면 변경이 없다고 응답 메세지를 반송
  - 최종 갱신 일자를 확인만 했으므로, 부담이 적어짐
  - 만약 갱신되었다면, 캐시에 데이터에 없는 경우와 동일한 프로세스 진행
- '2. 캐시에 데이터가 없는 경우
  - 캐시 서버는 리퀘스트 메세지가 via 라는 헤더 필드를 추가하여 웹 서버에 리퀘스트 전송
  - 웹서버가 1대만 있을 경우는 웹 서버의 도메인 명이나 IP 주소를 캐시 서버에 설정해 두고 무조건 거기에 전송
  - 웹서버가 여러 대인 경우 대표적인 방법은 리퀘스트 메세지의 URI 에 쓰여있는 디렉토리를 보고 판단  
    이 때 캐시 서버는 웹 서버에 클라이언트가 되어 소켓을 만들고 웹 서버의 소켓에 접속하여 리퀘스트 메세지 송부

#### 프록시의 원점은 프록시이다
- 보통 말하는 프록시는 웹 서버측에 두고 캐시 기능을 사용하는 것이지만, 클라이언트 측에 캐시 서버를 두는 방법도 있는데, 이를 <b>포워드 프록시</b>라고 함
- 포워드 프록시가 실제 프록시의 원형이며, 캐시 이용과 방화벽 실현이 주 목적이였음

![img](https://github.com/koni114/TIL/blob/master/Network/books/one_percent_network/img/network_24.png)

- 프록시에서 리퀘스트 메세지를 받아 인터넷을 향해 전송하면 필요한 것을 통과시킬 수 있다는 개념  
  이 때 프록시의 캐시를 이용하면 좀 더 효과적
- 프록시는 리퀘스트 내용을 조사한 후 전송하므로 리퀘스트의 내용에 따라 액세스가 가능한지 판단
- 패킷 필터링형 방화벽이라면 판단 근거로 IP 주소나 포트 번호라는 정보만 사용하므로 이렇게까지 자세히 조건을 설정하는 것을 불가능
- 포워드 프록시 사용의 경우, 브라우저의 설정 화면에 준비되어 있는 프록시 서버라는 항목에 포워드 프록시의 IP 주소를 설정함

#### 포워드 프록시 적용 전/후 차이점
- 브라우저의 리퀘스트 송신 동작 
  - 포워드 프록시 적용 X : 브라우저는 URL 에서 액세스 대상의 웹 서버를 계산함
  - 포워드 프록시 적용 O : URL의 내용과 상관없이 리퀘스트를 전부 포워드 프록시에 보냄
- 리퀘스트 메세지 내용
  - 포워드 프록시 적용 X : URL에서 웹 서버 이름 제외 후 파일/프로그램 경로명을 일부 추출
  - 포워드 프록시 적용 O : URL을 그대로 리퀘스트의 URL에 기록
- 메세지 전송 동작
  - 포워드 프록시 적용 X : 사전의 웹 서버를 설정해 두어야 함
  - 포워드 프록시 적용 O : URL이 전송 대상이 되므로, 전송 대상의 웹 서버를 사전에 설정해 둘 필요가 없음      

#### 포워드 프록시를 개량한 리버스 프록시
- 포워드 프록시를 사용할 경우에는 브라우저에 대한 설정이 꼭 필요한데, 이것이 포워드 프록시의 특징
- 브라우저 설정이 필요하다는 점은 이런 수고나 장애의 원인뿐만 아니라, 다른 제약 사항이 되기도 함
- 이에 따라 브라우저에 프록시를 설정하지 않아도 사용할 수 있도록 개량된 것이 리버스 프록시
- 리퀘스트 메세지의 URI에 쓰여있는 디렉토리 명과 전송 대상의 웹 서버를 대응시켜 URI 부분에 http://... 라고 쓰여있지 않은 보통의 리퀘스트 메세지를 전송할 수 있도록 함
- 서버ㅡㄱ에 설치하는 캐시 서버에 채택하고 있는 방식으로, 이를 리버스 프록시라고 함

#### 트랜스페어런트 프록시
- 캐시 서버에서 전송 대상을 판별하는 방법, 리퀘스트 메세지에서 패킷의 해더를 조사하는 방법이 있음
- 패킷의 맨 앞의 IP 헤더를 조사하여 액세스 대상 웹서버가 어디인지 알 수 있는데, 이를 <b>트렌스퍼어런트 프록시</b>라고 함
- 이 방법 사용시, 브라우저에 프록시를 설정할 필요도 없으며, 전송 대상을 캐시 서버에 설정할 필요도 없고, 어느 웹 서버에서나 전송할 수 있음
- 하지만 트렌스페어런트 프록시에 리퀘스트 메세지를 건네주는 방법을 주의해야함  
  트랜스페어런트 프록시는 브라우저에 프록시 설정을 하지 않으므로, 브라우저는 웹 서버에 리퀘스트 메세지를 보냄
- 트랜스페어런트 프록시는 리버스 프록시처럼 DNS 서버에 등록하는 것이 없음  
  만약 DNS 서버에 등록하면 트랜스페어런트 프록시 자체가 액세스 대상이 되어 수신처 IP 주소로 전송 대상의 웹 서버를 판단하는 중요한 구조를 이용할 수 없게 됨
- 이대로라면 리퀘스트 메세지는 브라우저에서 웹 서버로 흘러갈 뿐 트랜스페어런트 프록시에는 도착하지 않음
- 이를 해결하기 위해 브라우저에서 웹 서버로 리퀘스트 메세지가 흘러 들어가는 길에 트랜스페어런트 프록시를 설치
- 이렇게 해서 리퀘스트 메세지가 트랜스페어런트 프록시에 도착하고, 웹 서버에 전송 가능 
- 리퀘스트 메세지가 흐르는 길이 많으면, 여기에 전부 트랜스페어런트 프록시로 흐르는 길을 한 개로 수렴하는 형태로 만들고, 수렴되는 곳에 트랜스페어런트 프록시를 설치하는 것이 보통
- 인터넷에 연결하는 액세스 회선 부분이 이러한 형태로 되어 있으므로, 액세스 회선 부분에 설치해도 됨
- 트랜스페어런트 프록시를 사용하면 사용자가 프록시의 존재를 알아차릴 필요가 없음


### 콘텐츠 배포 서비스
#### 콘텐츠 배포 서비스를 이용한 부하 분산
- 캐시 서버는 클라이언트 측에 두느냐, 서버 측에 두느냐, 인터넷 주위에 캐시 서버를 두느냐에 따라서 장단점이 있음
- (a) 캐시 서버를 클라이언트 측에 두는 경우 
  - 인터넷의 트래픽을 억제하는 효과는 높음
  - 클라이언트 측에서 캐시 서버를 설치하므로, 서버 운영자는 캐시 서버를 제어할 수 없음
- (b) 웹 서버 직전에 캐시 서버를 두는 경우
  - 웹 서버의 부하를 줄일 수 있지만, 인터넷의 트래픽을 억제하는 효과는 없음
- (c) 인터넷의 주위에 캐시 서버를 두는 경우
  - 인터넷의 트래픽을 억제하는 효과가 있을 뿐만 아니라, 서버 운영자가 캐시 서버를 제어가능
  - 인터넷에 공개하는 서버는 인터넷의 어디에서 액세스하는지 알 수 없음. 따라서 이 방법을 전면적으로 실현하려면 프로바이더의 POP 전부에 캐시 서버를 설치해야하지만 비현실적임
- 웹 서버 운영자가 스스로 프로바이더와 계약하여 캐시 서버를 설치하는 것은비용면에서나 노력면에서 보통 일이 아닌데, 이를 해결하기 위하여 <b>콘텐츠 배포 서비스</b>를 사용할 수 있음    
- CDS(Contents Delivery Service)는 캐시 서버를 설치하고, 이것을 웹 서버 운영자에게 대출하는 서비스를 말함
- 해당 서비스를 제공하는 provider인 CDSP 는 증요한 프로바이더와 계약하고 그곳에 다수의 캐시 서버를 설치함
- 한편 CDSP는 웹 서버 운영자와도 계약하여 웹 서버와 CDSP 캐시 서버를 연대 시킴
- 설치한 캐시 서버를 다수의 웹서버 운영자가 공동으로 이용할 수 있으므로, 비용을 절감할 수 있음

#### 가장 가까운 캐시 서버의 관점
- 콘텐츠 배포 서비스를 사용하는 경우, 인터넷 전체의 설치된 다수 캐시 서버를 사용하고, 캐시 서버 중에서 가장 가까운 캐시 서버를 찾아내야함
- 브라우저에 프록시 서버를 설정하면 좋지만, 모든 사용자가 따르게 하는 것은 현실적으로 불가능함
- 사용자가 아무리 따라주어도 리퀘스트 메세지가 캐시 서버에 도착하는 것 같은 중간과정이 필요
- 캐시 서버를 찾는 방법 중 하나는, <b>DNS 서버가 웹 서버의 IP 주소를 회답할 때 가장 가까운 캐시 서버의 IP 주소를 회답하도록 DNS 서버를 세밀하게 설정하는 방법</b>
- 핵심은 클라이언트와 캐시 서버의 거리를 판단하는 방법인데, 다음과 같음
  - '1. 준비 단계로 캐시 서버의 설치 장소에 있는 라우터에서 경로 정보를 모음
  - '2. 라우터에서 경로표를 입수하여 n개의 경로표가 DNS 서버 곁으로 모임
  - '3. DNS 조회 메세지의 송신처, 즉 클라이언트측의 DNS 서버에 이르는 경로 정보롤 조사 

#### 리피터용 서버로 액세스 대상을 분배한다
- HTTP 헤더 필드 중, Location 헤더를 활용하여 웹 서버의 데이터를 다른 서버로 옮길 수 있음
- 다른 웹 서버에 액세스하도록 처리하는 것을 <b>리다이렉트(redirect)</b>라고 함
- 리다이렉트에 의해 가장 가까운 캐시 서버를 클라이언트에 통지할 때는 리다이렉트용 서버를 웹 서버측의 DNS 서버에 등록
- DNS 서버에 HTTP의 리퀘스트 메세지를 보내고, 리다이렉트 서버에는 DNS 서버와 같이 라우터에서 모은 경로가 있으며, 여기에서 가장 가까운 캐시 서버를 찾음

#### 캐시 내용의 갱신 방법에서 성능의 차이가 난다






## 용어 정리
- 프록시(proxy)
  - 클라이언트와 웹 서버 사이에 설치하여 액세스 동작을 중개하는 구조