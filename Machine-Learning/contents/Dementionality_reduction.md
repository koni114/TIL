# 차원 축소(Dimension shrink)
## 차원 축소
- 많은 경우 ML 문제는 훈련 샘플 각각이 수천, 수백만 개의 특성을 가지고 있음
- 이런 많은 특성은 훈련을 느리게 할 뿐만 아니라 좋은 솔루션을 찾기 어렵게 만듬
- 이런 문제를 종종 <b>차원의 저주(cuse of dimensionality)</b>라고 함
- 차원을 축소시키면 일부 정보가 유실되며, 훈련 속도는 빨라질 수 있지만 시스템의 성능이  
  조금 나빠질 수 있음
- 그러므로 차원 축소를 하기 전에 훈련이 너무 느린지, 원본 데이터로 시스템을 훈련해봐야 함
- 어떤 경우에는 훈련 데이터의 차원을 축소시키면 잡음이나 불필요한 세부사항을 걸러내므로  
  성능을 높일 수 있음
- 차원 축소는 훈련 속도를 높이는 것과 데이터 시각화에도 아주 유용함
- 차원 수를 둘로 줄이면 고차원 훈련 세트를 하나의 압축된 그래프로 그릴 수 있고,  
  군집 같은 시각적인 패턴을 감지해 중요한 통찰을 얻는 경우가 많이 있음

## 차원의 저주
- 우리는 3차원 세계에서 살고 있어 고차원 공간을 직관적으로 상상하기는 어려움
- 1,000차원 공간에서 휘어져 있는 200차원의 타원체는 고사하고 기본적인 4차원 초입방체 조차도  
  머릿속에 그리기가 어려움
- 단위 면적에서 임의의 두 점을 선택하면 두 점 사이의 거리는 평균적으로 대략 0.52가 됨
- 3차원 큐브에서 임의의 두 점을 선택하면 평균 거리는 대략 0.66
- 1,000,000 차원의 초입방체에서 두 점을 무작위로 선택하면 평균 거리는 428.25
- 고차원은 많은 공간을 가지고 있기 때문
- <b>이로 인해 고차원 데이터셋은 매우 희박할(Sparse) 위험이 있음</b> 
- 즉 대부분의 훈련 데이터가 서로 멀리 떨어져 있음. 이는 새로운 샘플도 훈련 샘플과 멀리 떨어져 있을 가능성이 높다는 의미
- 이 경우 예측을 위해서 훨씬 많은 외삽(extrapolation)을 해야하기 떄문에 저차원일 때보다 예측이 더 불안정함
- 간단히 말해 훈련 세트의 차원이 클수록 과대적합의 위험이 커짐
- 이론적으로 차원의 저주를 해결하는 해결책 하나는 훈련 샘플의 밀도가 충분히 높아질 때까지 훈련 세트의 크기를 키우는 것
- 불행하게도 일정 밀도에 도달하기 위해 필요한 샘플 수는 차원 수가 커짐에 따라 기하급수적으로 늘어남

## 차원 축소를 위한 접근 방법
- 차원을 감소시키는 두 가지 주요한 접근법인 투영(projection)과 매니폴드(manifold) 학습을 알아보자

### 투영(projection)
- 대부분의 실전 문제는 훈련 샘플이 모든 차원에 걸쳐 균일하게 퍼져 있지 않음
- 많은 특성들은 거의 변화가 없고, 다른 특성들은 서로 강하게 연관되어 있음
- 결과적으로 모든 훈련 샘플이 고차원 공간 안의 <b>저차원 부분 공간(subspace)</b>에 놓여 있음

### 매니폴드 학습
- 스위스 롤은 2D 매니폴드의 한 예
- 간단히 말해 2D 매니폴드는 고차원 공간에서 휘어지거나 뒤틀린 2D 모양
- 더 일반적으로 d차원 매니폴드는 국부적으로 d차원 초평면으로 보일 수 있는 n차원 공간의 일부(d < n)
- 스위스 롤의 경우에는 d = 2이고, n = 3임
- 많은 차원 축소 알고리즘이 훈련 샘플이 놓여 있는 매니폴드를 모델링하는 식으로 작동  
  이를 <b>매니폴드 학습</b>이라고 함
- 이는 대부분 실제 고차원 데이터셋이 더 낮은 저차원 매니폴드에 가깝게 놓여 있다는 <b>매니폴드 가정(manifold assumption)</b> 또는 매니폴드 가설에 근거
- 여기서 MNIST로 생각해보자. 전체 손글씨 숫자 이미지는 어느 정도 비슷한 면이 있는데,  
  선으로 연결되어 있고 경계는 흰색이고 어느 정도 중앙에 위치함
- 무작위로 생성된 이미지라면 그중 아주 적은 일부만 손글씨 숫자처럼 보일 것임 
- 다시 말해 숫자 이미지를 만들 때 가능한 자유도는 아무 이미지나 생성할 때의 자유도보다 훨씬 낮음
- 이런 제약은 데이터셋을 저차원의 매니폴드로 압축할 수 있도록 도와줌
- 매니폴드 가정은 이 저차원의 매니폴드 공간에 표현되면 더 간단해 질 것 이라는 가정을 동반  
  하지만 항상 이 가정이 맞는 것은 아님.
- 당연히 차원을 늘렸을 때 더 간단하게 데이터를 분할 시킬 수 있는 경우가 있음!
- 결과적으로 무조건 차원 수를 낮춘다고 성능 향상이 되는 것은 아님

## PCA(principal component Analysis)
- 주성분 분석은 가장 인기 있는 차원 축소 기법 중 하나
- 먼저 데이터에 가장 가까운 초평면을 정의한 다음, 데이터를 이 평면에 투영 시킴

### 분산 보존
- 저차원의 초평면에 훈련 세트를 투영하기 전에 먼저 올바른 초평면을 선택해야 함
- 2D 데이터셋을 1차원 초평면에 투영시킬 때, 분산이 최대한 보존되는 축을 선택하는 것이 정보가 가장 적게  
  손실되므로 합리적으로 보임
- 이 선택을 다른 방식으로 설명하면, <b>원본 데이터셋과 투영된 것 사이의 평균 제곱 거리를 최소화 하는 축</b>
- 이 방식이 PCA를 더 간단하게 설명할 수 있음

### 주성분
- PCA는 훈련 세트에서 분산이 최대인 축을 찾음
- 또한 첫 번째 축에서 직교하고 남은 분산을 최대한 보존하는 두 번째 축을 찾음
- 고차원 데이터셋이라면 PCA는 이전의 두축에 직교하는 세 번째 축을 찾으며 데이터셋에 있는 차원의 수만큼 네 번째, 다섯 번째, ... n번째 축을 찾음
- i번째 축을 이 데이터의 i번째 주성분(Principle Component)라고 부름
- 첫번째 축에서 두번째 주성분은 첫번째 축의 수직, <b>세 번째 축은 이 첫번째 두번째 축이 만드는 평면에 수직</b> 
- 각 주성분을 위해 PCA는 주성분 방향을 가리키고 원점에 중앙이 맞춰진 단위 벡터를 찾음
- 하나의 축에 단위 벡터가 반대 방향으로 두 개이므로, PCA가 반환하는 단위 벡터의 방향을 일정하지 않음
- 즉, <b>주성분의 방향은 일치하지 않음</b>
- 훈련 세트를 조금 섞은 다음, 다시 PCA를 적용하면 새로운 PC 중 일부가 원래 방향과 반대 방향일 수 있음
- 그러나 일반적으로 같은 축에 놓여 있을 것임
- 어떤 경우에는 한 쌍의 PC가 회전하거나 서로 바뀔 수 있지만 보통은 같은 평면을 구성함
- 훈련 세트의 주성분을 어떻게 찾을 수 있을까?
- 다행히 특잇값 분해(singular value decomposition, SVD)라는 표준 행렬 분해 기술이 있어  
  훈련 세트 행렬 X를 세 개의 행렬의 행렬 곱셈인 U* Sigma(V^T)로 분해 할 수 있음
- 여기서 찾고자 하는 모든 주성분의 단위 벡터가 V과 같이 담겨 있음  
  - V = (C1 C2 ... Cn)
- 사이킷런의 PCA 파이썬 클래스는 데이터의 평균을 0으로 해주는 작업을 대신 해줌

### 주성분 축 계산 
- 일반적으로 고유값-분해(eigenvalue-decomposition)과 특이값 분해(Singular value-decomposition)을 이용해 계산 가능

### d차원으로 투영하기
- 주성분을 모두 추출해냈다면 처음 d개의 주성분으로 정의한 초평면에 투영하여 데이터셋의 차원을 d차원으로 축소 시킬 수 있음
- 이 초평면은 분산을 가능한 한 최대로 보존하는 투영임을 보장함
- 초평면에 훈련 세트를 투영하고, d차원으로 축소된 데이터셋 X를 얻기 위해서는 행렬 X와 V의 첫 d열로 구성된  
  행렬 W(d)를 행렬 곱셈하면 됨
- X(d-proj) = XW(d)
- `components_` 속성에 W^d의 전치가 담겨 있음(예를들어 첫 번째 주성분을 정의하는 단위 벡터는 `pca.components_.T[:0]` 입니다)

### 설명된 분산의 비율
- 설명된 분산의 비율(explained variance ratio)도 유용한 정보 중 하나
- 이 비율은 각 주성분의 축을 따라 잇는 데이터셋의 분산 비율을 나타냄

### 적절한 차원 수 선택하기
- 축소할 차원 수를 임의로 정하기보다는 충분한 분산이 될 때까지 더해야 할 차원 수를 선택하는 것이 좋음
- 데이터 시각화를 위해 차원을 축소하는 경우 차원을 2개나 3개로 줄이는 것이 일반적임
- 아니면 설명된 분산을 차원 수에 대한 함수로 그려 적절한 변곡점을 찾아 주성분 수를 정함
- 보존하려는 분산의 비율을 `n_components`에 0.0에서 1.0 사이로 설정하는 편이 훨씬 낫다

### 압축을 위한 PCA
- 차원을 축소하고 난 후에는 훈련 세트의 크기가 줄어듬
- 예를 들어 MNIST 데이터셋에 분산의 95%를 유지하도록 PCA를 적용해보자
- 각 샘플은 원래 784개 특성이 아니라 150개 정도만 가지고 있음
- 대부분의 분산은 유지되었지만 데이터셋은 원본 크기의 20% 미만이 되었음
- 이는 상당한 압축률이고 이런 크기 축소는 (SVM 같은) 분류 알고리즘의 속도를 크게 높일 수 있음
- 또한 압축된 데이터셋에 PCA 투영의 변환을 반대로 적용하여 784개의 차원으로 되돌릴 수도 있음  
  투영에서 일정량의 정보를 잃어버렸기 때문에 이렇게 해도 원본 데이터셋을 얻을 수는 없음
- 원본 데이터와 재구성된 데이터 사이의 평균 제곱 거리를 <b>재구성 오차(recontruction error)</b> 라고 함

### 랜덤 PCA
- 랜덤 PCA는 성분확률적 알고리즘을 사용해 처음 d개의 주에 대한 근사값을 빠르게 찾음
- 이 알고리즘의 계산 복잡도는 O(m x n^2) + O(n^3)이 아닌 O(m x d^2) + O(d^3)임
- 따라서 d가 n보다 많이 작으면 완전 SVD 보다 훨씬 빠름

### 점진적 PCA
- Incremental PCA(IPCA)라고 함
- PCA 구현의 문제는 SVD 알고리즘을 실행하기 위해서 전체 훈련 세트를 메모리에 올려야 한다는 것
- 따라서 점진적 PCA는 훈련 세트를 미니 배치로 나눈 뒤, IPCA 알고리즘에 한 번에 하나씩 주입
- 이런 방식은 훈련 세트가 클 때 유용하고 온라인으로 PCA를 적용 할 수도 있음 
- `IncrementalPCA` 클래스에 주입해서 사용 가능. `partial_fit()`을 미니배치마다 호출해야 함


### 커널 PCA
- 샘플을 매우 높은 고차원 공간으로 암묵적으로 매핑하여 SVM의 비선형 분류와 회귀를 가능하게 하는 수학적 기법인  
  커널 트릭에 대해서 이야기 함
- 고차원 특성 공간에서의 선형 결정 경계는 원본 공간에서는 복잡한 비선형 결정 경계에 해당하는 것을 배움
- 같은 기법을 PCA에 적용해 차원 축소를 위한 복잡한 비선형 투형을 수행할 수 있음. 이를 <b>커널 PCA</b> 라고 함
- 이 기법은 투영된 후에 샘플의 군집을 유지하거나 꼬인 매니폴드에 가까운 데이터셋을 펼칠 때도 유용
- kPCA는 비지도 학습이기 때문에 좋은 커널과 하이퍼파라미터를 선택하기 위한 명확한 성능 측정 기준이 없음  
  하지만 차원 축소는 종종 지도 학습의 전처리 단계로 활용되므로, 그리드 탐색을 사용하여 주어진 문제에서 성능이  
  가장 좋은 커널과 하이퍼파라미터를 선택할 수 있음

## 다른 차원 축소 기법
### 랜덤 투영(random projection)
- 랜덤한 선형 투영을 사용해 데이터를 저차원 공간으로 투영함

### 다차원 스케일링(multidimensional scaling, MDS)
- 샘플 간의 거리를 보존하면서 차원을 축소

### Isomap
- 각 샘플을 가장 가까운 이웃과 연결하는 식으로 그래프를 만듬
- 그런 다음 샘플 간의 지오데식 거리(geodesic distance)를 유지하면서 차원 축소

### t-SNE(t-distributed stochastic neighbor embedding)
- 비슷한 샘플은 가까이, 비슷하지 않는 샘플은 멀리 떨어지도록 하면서 차원을 축소
- 주로 시각화에 많이 사용되며 특히 고차원 공간의 있는 샘플의 군집을 시각화할 때 사용

### 선형판별분석(linear discriminant analysis, LDA)
- 사실 분류 알고리즘임. 훈련 과정에서 클래스 사이를 가장 잘 구분하는 축을 학습
- 이 축은 데이터가 투영되는 초평면을 정의하는 데 사용 가능
- 이 알고리즘의 장점은 투영을 통해 가능한 한 클래스를 멀리 떨어지게 유지시키므로 SVM 분류기 같은 다른 분류 알고리즘을  
  적용하기 전에 차원 축소에 좋음

![img](https://github.com/koni114/Machine-Learning/blob/master/img/dimensionality_reduction_1.JPG)