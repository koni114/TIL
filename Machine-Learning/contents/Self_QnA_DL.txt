## 2009~2010년 가장 중요한 딥러닝의 변화 3가지는?
## DL 의 장점 3가지는? 
## 신경망이 훈련 준비를 마치기 위해서 컴파일 
    단계에서 포함될 3가지? 
## 신경망은 입력 스케일에 민감한가?
## 텐서란 무엇인가? 
## 스칼라란 무엇인가? 
## 텐서의 축의 개수를 다른 말로 ? 
## 텐서의 핵심속성? 
## 딥러닝에서 사용되는 모든 데이터의 첫번째 축은?  
## 텐서의 실제 사례
-1D:
-2D:
-3D:
-4D:
## 이미지 데이터 차원 구성은 어떻게 되는가?
## 비디오 데이터의 차원 구성은 어떻게 되는가? 
## 다음을 해석해보아라
Keras.layers.Dense(512, activation = 'relu')
## 원소별 연산(elements-wise operation)이란?
## 브로드캐스팅(broadcasting)이란?
## 텐서 점곱(tensor product)이란?
## 딥러닝의 기하학적 해석은?
## output = relu(dot(W, input) + b) 다음 식은 기억하자
## 딥러닝 모형의 초기에는 가중치 행렬이 어떻게 구성되어 있는가? 
## W1 = W0 - step * gradient(f)(W0) 다음은 무슨 식인지 설명해 보아라
## 미니 배치 확률적 경사 하강법이란? 
## 2차원에서의 경사하강법과 딥러닝에서의 경사하강법의 가장 큰 차이는? 
## 최적화 방법(optimization method) 또는 옵티마이저(optimizer)은 무엇인가? 
## 모멘텀(momentum) 알고리즘이란? 기존 SGD의 2가지 문제점을 해결하는데 무엇인가? 
## 역전파 알고리즘이란 ?
## 신경망의 구성 단위인 층(layers)은 데이터 묘듈이다
## (samples, features) 의 2D 텐서가 저장된 간단한 벡터 데이터는 주로 어떤 층이 사용되나? 
## fully connected layer란? 
## (samples, timesteps, features) 의 3D 텐서로 저장된 시퀀스 데이터는 주로 어떤 층이 사용되나?
## 순환층(recurrent layer)이란? 
## 4D 텐서로 저장되는 이미지 데이터? 
## convolution layer란? 
## 딥러닝 층은 어떤 그래프를 가지는지? 
## 분류, 회귀, 시퀀스 예측 같은 일반적인 문제에는 
    올바른 손실 함수를 선택하는 간단한 지침이 존재
   - 2개 클래스 분류 문제 : 
   - 3개 이상의 클래스 분류 문제 :
   - 회귀문제 :  
## 케라스의 특징? 
   - 소스의 효율성 관점
   - API 관점
   - 자율성 관점
## GPU, CPU일때 사용되는 라이브러리가 다른데, 어떤 라이브러리를 사용하나? 
## GPU가 CPU보다 빠른 이유?
## keras에서 모델을 정의하는 방법은 2가지인데, 어떤 것들인가? 
## 데이터는 리스트가 아닌 텐서여야 하는데, 리스트를 어떻게 변환 할 수 있나? 
    - encoding
    - same length
## hidden unit이란? hidden unit을 크게 늘리면 어떻게 되는가? 
## model.compile, model.fit 두 함수의 역할은?
## model.fit 함수를 재호출 하면 생기는 문제? 
##  model.evaluate, model.predict 두함수의 역할은 ?
## activation function이 없으면 어떤 문제가 발생하는가? 
 - 가설 공간? 
## 최종 output의 class보다 항상 layer의 unit 층 개수는 어떻게 되어야 하나? 
## 만약 y 레이블이 46개이면 어떻게 해주어야 하는가? 
## 만약 정수 레이블을 사용하는 경우 손실함수를 어떤 것을 사용해야하나? 
## 데이터 표준화를 수행할 때 항상 조심해야 할 점? 
## self-supervised learning이란? 
## 반지도 학습(semi-supervised learning) 이란? 
## 강화 학습(reinforcement learning) 이란? 
## 검증
- 단순 hold-out 검증: train_test_split() 
- K-fold 교차 검증   : cross_validate() 
shuffling을 이용한 repeated K-fold cross-validation : RepeatedStratifiedFold 
## 데이터 중복 여부 체크하나? 
## 데이터 벡터화란? 
## trainDataset에는 결측값이 없고, testDataset에는 결측값이 있는 경우?  
    결측치는 보통 어떤 값으로 처리해야 하는가? 
    실제 결측처리는 알기가 어렵다. 보통 이럴때는 어떻게 해야할까? 
## 딥러닝과 feature engineering 과의 관계?
## 모델의 capacity라고하면 보통 무엇을 뜻하는가? 
## DL에서 overfitting을 방지하기 위한 방법? 
  - datasize
  - regularization
  - capa
  - drop-out
## 오캄의 면도날(Occam's razor) 이론이란? 
## 보편적인 ML 작업 흐름? 

#########################
## 컴퓨터 비전을 위한 딥러닝 ## 
#########################
## 합성곱 신경망이란? 
## 합성곱 신경망은 지역 패턴을 학습하는데, 이는 2가지 흥미로운 성질을 제공한다
    무엇인가? 
## 패딩(padding)이란? 
## 합성곱스트라이드(stride)란?
## 특성을 다운샘플링 하기 위해서는 보통 어떤 방식을 사용하나? 
## 최대 풀링 연산(maxPooling)이란?
## 합성곱 연산과 최대 풀링 연산의 차이? 
## 합성곱으로만 이루어진 ConvNet의 문제점?	
## 최대풀링이 평균폴링보다 더 잘 작동하는 이유?
## 가장 보편적인 서브 샘플링 방법?
## 소규모 데이터셋에서 딥러닝 학습을 위한 핵심 기술 3가지?
## 소규모 데이터셋에서의 딥러닝의 타당성?
## data augmentation이란? 
## pretrained network를 사용하는 두가지 방법 ? 
## 합성곱층 vs 완전분류기? 
## 합성곱층에서 상위층과 하위층의 특성의 차이는?
## Pretrained model의 합성곱 층의 제일 마지막 층 위에 완전 연결 층을 새로 둘 때 2가지 방법은
    무엇인가? 
## fine tuning이란?
## fine-tuning 조정 절차?

## DL 의 장점 3가지는?
- 단순함
- 확장성
- 다용도나 재사용성 가능.

## 신경망이 훈련 준비를 마치기 위해서 컴파일 
    단계에서 포함될 3가지? 
- 손실 함수
- 옵티마이저
- 평가지표

## 텐서란 무엇인가? 
- 데이터를 담는 컨테이너

## 이미지 데이터 차원 구성은 어떻게 되는가?
(샘플, height, width, color)

## 비디오 데이터의 차원 구성은 어떻게 되는가? 
(samples, frames, height, width, color_depth)
 
## 원소별 연산(elements-wise operation)이란?
- 더하기 연산에 해당
- 각 요소별로 독립적으로 적용
- 원소별 연산은 numpy에서 빠른 속도로 해결 가능

## 브로드캐스팅(broadcasting)이란?
- 작은 텐서가 큰 텐서에 반복해서 맞춰지는 것

## 텐서 점곱(tensor product)이란?
- 행렬 곱과 동일한듯

## 딥러닝의 기하학적 해석은?
- 심하게 꼬여있는 매니폴드를 푸는 역할을 함

## 미니 배치 확률적 경사 하강법이란? 
배치를 무작위적으로 추출하여 경사 하강법을 적용하는 알고리즘.

## 2차원에서의 경사하강법과 딥러닝에서의 경사하강법의 가장 큰 차이는? 
2차원에서의 경사하강법은 직관적으로 이해할 수 있지만 딥러닝에서
경사하강법은 예측 불가능. --> 딥러닝 오류의 근원

## 최적화 방법(optimization method) 또는 옵티마이저(optimizer)은 무엇인가? 
- 일반적으로 경사하강법을 통해 파라미터를 최적화 시키는데, 딥러닝은 워낙 고차원이라
파라미터 최적화가 쉽지 않아, 가중치를 계산할 때 여러 변종들을 적용해서 계산하는데,
이를 optimizer라고 함

## 모멘텀(momentum) 알고리즘이란?
과거 그래디언트가 가지고 있는 방향을 현재 그래디언트에 보정하는 방식

## 역전파 알고리즘이란 ?
입력값의 기울기를 출력층 layer로부터 역으로 전파하여 구하는 방식 이에 chainRule이 사용됨 

## 딥러닝 층은 어떤 그래프를 가지는지? 
- 비순환 유향 그래프를 가짐

## 분류, 회귀, 시퀀스 예측 같은 일반적인 문제에는 
    올바른 손실 함수를 선택하는 간단한 지침이 존재
   - 2개 클래스 분류 문제 : 이진 크로스엔트로피
   - 3개 이상의 클래스 분류 문제 : 범주형 크로스엔트로피
   - 회귀문제 :  RMSE

## 케라스의 특징? 
   - 소스의 효율성 관점 : 동일한 소스로 CPU와 GPU 모두 사용 가능
   - API 관점 : 고수준 API를 통해 쉽게 딥러닝 네트워크를 구성할 수 있음
   - 자율성 관점 : 어떤 네트워크던 구성할 수 있음

## GPU, CPU일때 사용되는 라이브러리가 다른데, 어떤 라이브러리를 사용하나? 
- CPU : eigen 저수준 텐서 라이브러리
- GPU : NVIDIA CUDA 심층 신경망 라이브러리

## GPU가 CPU보다 빠른 이유?
GPU는 병렬 처리가 가능하기 때문

## keras에서 모델을 정의하는 방법은 2가지인데, 어떤 것들인가? 
  - Sequential 클래스
  - 함수형 API

## model.compile, model.fit 두 함수의 역할은?
- model.compile : optimizer 역할, optimizer, Metrics, loss

##  model.evaluate, model.predict 두함수의 역할은 ?
- 평가하고 예측

## activation function이 없으면 어떤 문제가 발생하는가? 
 - 선형성으로 activation function이 구성되면, 가설 공간이 확장이 안됨

## 최종 output의 class보다 항상 layer의 unit 층 개수는 어떻게 되어야 하나? 
- 많아야 함

## 만약 y 레이블이 46개이면 어떻게 해주어야 하는가? 
- one-hot encoding

## 만약 정수 레이블을 사용하는 경우 손실함수를 어떤 것을 사용해야하나? 
- sparse_categorical_crossentropy 사용

## self-supervised learning 이란? 
- 지도학습이지만, 사람이 만든 label을 사용하지 않음
- 레이블을 heristic algorithm을 사용해서 입력 데이터로부터 생성

## 반지도 학습(semi-supervised learning) 이란? 
- 일부분만 labeling이 되어 있는 데이터를 기반으로 레이블을 생성하고,  
  이를 기반으로 예측을 하는 모형.

## 강화 학습(reinforcement learning) 이란? 
- 보상을 최대화 할 수 있는 행동에 대해서 학습하는 것
잘 분류된(labeled) 데이터가 아닌 환경과의 상호작용을 통해 얻은 보상으로부터 학습

## 데이터 벡터화란?
- 리스트 같은 데이터를 텐서 형태로 변환하는 것

## trainDataset에는 결측값이 없고, testDataset에는 결측값이 있는 경우?  
- trainDataset에 결측을 만들어야함

## 딥러닝과 feature engineering 과의 관계?
- 딥러닝에서 feature engineering은 크게 관련이 없음.
  왜냐면 딥러닝 모형에서 특성을 자동으로 추출해 내기 때문
  그럼에도 불구하고 특성 공학을 적용하면 좋은데, 그 이유는 적은 컴퓨팅 파워로  
  모델을 만들어 낼 수 있기 때문

## 보편적인 ML 작업 흐름? 
- 문제 정의, 데이터셋 수집
- 지표
- 평가 방법 선택
- 데이터 준비
- 모델 훈련
- 데이터 전처리 / 몸집 키우기

## 패딩(padding)이란? 
- 입력과 동일한 높이와 너비를 가진 출력 특성 맵을 얻기 위하여
입력 특성 맵의 가장자리에 적절한 개수의 행과 열을 추가시키는 행위

## 합성곱스트라이드(stride)란?
- 몇칸을 건너띄고 합성곱을 수행할 것인가? 
  실전에서는 드물게 사용

## 합성곱 연산과 최대 풀링 연산의 차이? 
- 합성곱연산 : 3x3 윈도우, 스트라이드 1, 합성곱 연산 값 도출
- 최대풀링연산 : 2x2 윈도우, 스트라이드 2, 최대값 도출

## 합성곱으로만 이루어진 ConvNet의 문제점?	
- 공간적 계층 구조를 학습하는데 잘 안됨
- 너무 적은 비율로 줄어듬 --> 심각한 과대적합 발생

## 최대풀링이 평균폴링보다 더 잘 작동하는 이유?
- 특성 맵이 각 타일에서 어떤 패턴이나 개념의 존재 유무를 인코딩 하는 경향이 있기때문

## 가장 보편적인 서브 샘플링 방법?
- 스트라이드가 없는 합성곱으로 조밀한 특성 맵을 만들고, maxpooling으로 활성화된 특성을 고르는 것

## 소규모 데이터셋에서 딥러닝 학습을 위한 핵심 기술 3가지?
- augmentation
- pretrained model
- pretrained model + fine tuning

## pretrained network를 사용하는 두가지 방법 ? 
- 특성 추출
- 미세 조정

## 합성곱층 vs 완전분류기? 
합성곱층은 사진의 일반적인 패턴이나 객체 shape의 특성을 가지고 있어
다른 domain에서도 사용이 가능
완전 분류기는 해당 class에 특화되어 있음

## 합성곱층에서 상위층과 하위층의 특성의 차이는?
- 상위층 : 이미지의 추상적인 개념을 추출(귀, 입, 코)  
- 하위층 : 이미지의 지역적인 특색을 추출(색감, 명도) 

## Pretrained model의 합성곱 층의 제일 마지막 층 위에 완전 연결 층을 새로 둘 때 2가지 방법은
    무엇인가? 
- 데이터 증식을 사용하지 않는 빠른 특성 추출
- 준비한 모델(conv_base) 위에 Dense 층을 쌓아 확장

## fine tuning이란?
특성 추출에 사용했던 pretrained model에서 상위 층 몇개의 동결을 풀어 모델의 새로운 층과
함께 훈련 시키는 것

