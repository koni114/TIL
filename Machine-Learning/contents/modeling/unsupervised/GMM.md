## 가우시안 혼합 모델(Gaussian Mixture model, GMM)
- 샘플이 파라미터가 알려지지 않은 여러 개의 혼합된 가우시안 분포에서 생성되었다고 가정한 확률 모델
- 하나의 가우시안 분포에서 생성된 모든 샘플은 하나의 클러스터를 형성
- 일반적으로 이 클러스터는 타원형
- 각 클러스터는 타원의 모양, 크기, 밀집도, 방향이 다름
- 샘플이 주어지면 가우시안 분포 중 하나에서 생성되었다는 것을 알고 있음
- 하지만 어떤 분포인지 또 이 분포의 파라미터는 무엇인지 알지 못함
- 여러 GMM 변종이 있는데, 가장 간단한 버전이 `GaussianMixture` 클래스에 구현되어 있음
- 여기에서는 사전에 가우시안 분포의 개수 k를 알아야 함. 데이터셋 X가 다음 확률 과정을 통해 생성되었다고 가정
  - 샘플마다 k개의 클러스터에서 랜덤하게 한 클러스터가 선택됨. j번째 클러스터를 선택할 확률은 클러스터의 가중치 phi(j)로 정의됨. i번째 샘플을 위해 선택한 클러스터 인덱스는 z(i)로 표시
  - z(i) = j면, 즉 i번째 샘플이 j번째 클러스터에 할당되었다면 이 샘플의 위치 x(i)는 평균이 Mu(j)고 공분산 행렬이 sigma(j)인 가우시안 분포에서 랜덤하게 샘플링됨. 이를 x(i) ~ N(Mu(j), sigma(j))와 같이 씀
- 이 생성 과정은 그래프 모형(graphical model)로 나타낼 수 있음
- 다음 그림은 확률 변수 사이의 조건부 의존성의 구조를 나타냄
![img](https://github.com/koni114/TIL/blob/master/Machine-Learning/img/GMM_1.png)
- 이 그림을 보는 방법은 다음과 같음
  - 원은 확률 변수를 나타냄
  - 사각형은 고정값을 나타냄(즉 모델의 파라미터) 
  - 큰 사각형을 plate라고 부름. 이 사각형 안의 내용이 여러 번 반복된다는 것을 나타냄
  - 각 플레이트 오른쪽 아래의 숫자(ex) M, K)는 얼마나 플레이트 안의 내용이 반복되는지를 표시  
    따라서 m개의 확률 변수 z(i)(z(1) ~ z(m))와 확률 변수 x(i)가 있음. 또한 k개의 평균 Mu(i)와 k개의 공분산 행렬이 있음. 마지막으로 가중치 벡터 phi가 있음(가중치 phi(1) ~ phi(k)까지 모두 포함)
  - 각 변수 z(i)는 가중치 phi를 갖는 범주형 분포에서 샘플링. 각 변수 x(i)는 해당하는 클러스터 z(i)로 정의된 평균과 공분산 행렬을 사용해 정규분포에서 샘플링함
  - 실선 화살표는 조건부 의존성을 표현. 예를 들어 각 확률 변수 z(i)의 확률 분포는 가중치 벡터 phi에 의존. 화살표가 플레이트 경계를 가로지르면 해당 플레이트의 모든 반복에 적용한다는 의미
  - 예를 들어 가중치 벡터 phi는 확률 변수 x(1)에서 x(m)까지 모든 확률 변수의 확률 분포에 필요 조건임
  - z(i)에서 x(i)까지 구불구불한 화살표는 스위치(switch)를 나타냄, z(i)의 값에 따라서 x(i)가 다른 가우시안 분포에서 샘플링 될 것임. 예를 들어 z(i) = j이면, x(i) ~ N(M(j), sigma(j))가 됨
  - 색이 채워진 원은 알려진 값이라는 의미. 따라서이 경우에 확률 변수 x(i)만 알고 있는 값  
    이를 관측 변수(observed variable)이라고 함. 알려지지 않은 확률 변수 z(i)를 잠재 변수(latent variable)라고 부름
- 이 모델로 <b>먼저 데이터셋 X가 주어지면 가중치 phi, 전체 분포의 파라미터 Mu(1) ~ Mu(k)와 sigma(1) ~ sigma(k)까지를 추정함</b>
- 사이킷런의 `GaussianMixture` 클래스를 사용하면 아주 쉬움!
~~~python
#########
## GMM ##
#########
from sklearn.mixture import GaussianMixture
gm = GaussianMixture(n_components=3, n_init=10)
gm.fit(X)

#- 이 알고리즘이 추정한 파라미터를 확인해보자
#- 특성이 두개 이므로, 평균이 특성마다 하나씩 반환되었고, 공분산 행렬의 크기는 2x2
print(gm.weights_)      #- phi
print(gm.means_)        #- means
print(gm.covariances_)  #- covariance

#- 이 데이터를 생성하기 위해 사용한 가중치는 0.2, 0.4, 0.4임
#- 평균과 분산 행렬도 이 알고리즘이 찾은 것과 매우 비슷함.
~~~
- 실제 이 데이터를 생성하기 위해 사용한 가중치는 0.2, 0.4, 0.4  
  (3개의 클러스터마다 데이터가 250, 500, 500개)    
- 평균과 분산 행렬도 이 알고리즘이 찾은 것과 매우 비슷
- 이 클래스는 기댓값-최대화(expectation-maximization, EM) 알고리즘을 사용
- 이 알고리즘은 k-means 알고리즘과 공통점이 많음. 클러스터 파라미터를 랜덤하게 초기화하고 수렴할 때까지 두 단계를 반복
- 먼저 샘플을 클러스터에 할당합니다(이를 기댓값 단계(expectation-step)라고 함.)
- 그다음 클러스터를 업데이트함(이를 최대화(maximization-step)) 단계라고함)
- 군집 입장에서 보면 EM을 클러스터 중심(Mu(1) ~ Mu(k)까지)뿐만 아니라 크기, 모양, 방향(공분산)과 클러스터의 상대적 가중치(phi)를 찾는 k-평균의 일반화로 생각할 수 있음
- k-평균과 달리 EM은 하드 클러스터 할당이 아니라 소프트 클러스터 할당을 사용함
- 예를 들어 기댓값 단계에서 알고리즘은(현재 클러스터 파라미터에 기반하여) 각 클러스터에 속할 확률을 예측
- 그다음 최대화 단계에서 각 클러스터가 데이터셋에 있는 모든 샘플을 사용해 업데이트됨
- 클러스터에 속할 추정 확률로 샘플에 가중치가 적용됨
- 이 확률을 샘플에 대한 클러스터의 책임(responsibility)이라고 부름
- 최대화 단계에서 클러스터 업데이트는 책임이 가장 많은 샘플에 크게 영향을 받음
- <b>k-means처럼 EM이 나쁜 솔루션으로 수렴할 수 있어, 여러 번 실행하여 가장 좋은 솔루션을 선택해야함. n_init 설정 가능</b>
- 알고리즘이 수렴했는지 여부와 반복 횟수를 확인할 수 있음
~~~python
print(gm.converged_)
print(gm.n_iter_)

# True
# 15
~~~
- 이제 각 클러스터의 위치, 크기, 모양, 방향, 상대적인 가중치를 예측했음
- 이 모델은 새로운 샘플을 가장 비슷한 클러스터에 손쉽게 할당할 수 있음(하드 군집)
- 또는 특정 클러스터에 속할 확률을 예측할 수 있음(소프트 군집)
- 하드 군집을 위해서는 `predict()` 메서드를 사용하고 소프트 군집을 위해서는 `predict_proba()` 메서드를 사용
~~~python
gm.predict(X)
gm.predict_proba(X)
~~~
- 가우시안 혼합 모델은 생성 모델(generative model)임. 즉 이 모델에서 새로운 샘플을 만들 수 있음(반환된 샘플은 클러스터 인덱스 순으로 정렬되어 있음)
~~~python
X_new, y_new = gm.sample(6)
print(X_new)
print(y_new)

[[ 1.89784885  0.06957934]
 [-0.76990798  0.5330055 ]
 [-0.71641524  0.66155383]
 [ 0.5883694   0.02480687]
 [ 0.89205127 -0.35457406]
 [ 0.27689833 -0.03134204]]

 [0 1 1 2 2 2]
~~~
- 또한 주어진 위치에서 모델의 밀도를 추정할 수 있음
- 이를 위해 `score_samples()` 메서드를 사용함. 샘플이 주어지면 이 메서드는 그 위치의 확률 밀도 함수(PDF)의 로그를 예측. 점수가 높을수록 밀도가 높음
~~~python
gm_score_samples = gm.score_samples(X)
~~~
- 이 점수의 지숫값을 계산하면 샘플의 위치에서 PDF값을 얻을 수 있음
- 이 값은 <b>하나의 확률이 아니라, 확률 밀도임</b>
- 즉 0에서 1까지의 값이 아니라, 어떤 양수값도 될 수 있음. 샘플이 특정 지역안에 속할 확률을 예측하려면 그 지역에 대해 PDF를 적분해야 함(가능한 샘플 위치 전 지역에 대해 적분해 더하면 1이 됨)
- 확률 밀도(probability density)는 하나의 확률값이 아니라 확률 변숫값이 특정 범위 안에 있을 확률을 말함
- 이 값은 확률 밀도 함수 그래프의 아래 면적이며 적분으로 계산할 수 있음
- 예를 들어 (0, 0.1) 영역 밖에서는 모두 0인 확률 분포가 있다면 이 영역의 평균적인 확률 밀도는 10이 될 것임
- 전 지역에 대해 그래프 아래 면적을 계산하면 10x0.1=1이 됨. 동일한 조건에서 2개의 확률 변수가 있다면 평균 확률 밀도는 100이 됨. 양축 방향으로 그래프 아래 공간을 계산하면 100 x 0.1 x 0.1 = 1이 됨
- 아래 그림은 이 모델의 클러스터 평균, 결정 경계(파선), 밀도 등고선을 보여줌
![img](https://github.com/koni114/TIL/blob/master/Machine-Learning/img/GMM_2.png)

- 물론 이 문제는 2D 가우시안 분포를 사용해 데이터를 생성한 쉬운 작업임(실제 데이터는 가우시안 분포나 저차원이 아닌경우가 많음)
- 또한 이 알고리즘에 정확한 클러스터 개수를 입력했음. 특성이나 클러스터가 많거나 샘플이 적을 때는 EM이 최적의 솔루션으로 수렴하기 어려움
- 이런 작업의 어려움을 줄이려면 알고리즘이 학습할 파라미터 개수를 제한해야 함
- 이런 방법 중 하나는 클러스터의 모양과 방향의 범위를 제한하는 것
- 공분산 행렬에 제약을 추가하여 이렇게 할 수 있음. 사이킷런에서는 `covariance_type` 매개변수에 다음 값 중 하나를 설정할 수 있음
  - `spherical`: 모든 클러스터가 원형. 하지만 지름은 다를 수 있음
  - `diag`: 클러스터는 크기에 상관없이 타원형도 가능. 하지만 타원의 축은 좌표축과 나란해야 함 
  - `tied`: 모든 클러스터가 동일한 타원 모양, 크기, 방향을 가짐(모든 클러스터는 동일한 공분산 행렬을 공유함)
- `covariance_type`의 기본 타입은 full임. 각 클러스터는 모양, 크기, 방향에 제약이 없음
- 다음 그림은 covariance_type을 'tied', 'spherical'로 지정했을 때 EM 알고리즘으로 찾은 솔루션임
![img](https://github.com/koni114/TIL/blob/master/Machine-Learning/img/GMM_3.png)

- GaussianMixture model을 훈련할 때의 계산 복잡도는 샘플 개수 m, 차원 개수 n, 클러스터 개수 k와 공분산 행렬에 있는 제약에 따라 결정됨. covariance_type이 "spherical", "diag"이면 데이터에 어떤 클러스터 구조가 있다고 가정하므로 O(kmn)임
- covariance_type이 "tied"나 "Full"인 경우 O(jmn^2 + kn^3)임 따라서 특성 개수가 많으면 적용하기 힘듬

### 가우시안 혼합을 사용한 이상치 탐지 
- 이상치 탐지(outlier detection)은 보통과 많이 다른 샘플을 감지하는 작업
- 이를 outlier라고 하며, 보통 샘플은 inlier라고 함
- 이상치 탐지는 다양한 애플리케이션에서 사용할 수 있음. 예를 들면 부정 거래 감지, 제조 결함이 있는 제품 감지에 사용됨
- 또는 다른 모델을 훈련하기 전에 데이터셋에서 이상치를 제거하는 데 사용됨
- 가우시안 혼합 모델을 이상치 탐지에 사용하는 방법은 매우 간단. 밀도가 낮은 지역에 있는 모든 샘플을 이상치로 볼 수 있음. 이렇게 하려면 밀도 임곗값을 정해야 함
- 예를 들어 결함 제품을 감지하려는 제조 회사는 일반적으로 결함 제품의 비율을 알고 있음
- 이를 4%로 가정해보자. 밀도 임곗값을 이 값으로 설정하면 밀도가 낮은 지역에 있는 샘플의 4%를 얻을 수 있음
- 만약 False Positive(실제 negative인데, positive으로 예측)가 너무 많다면 임곗값을 더 낮추고, False Negative가 많다면 임곗값을 더 높여야 함
- 이는 일반적인 precision/recall trade-off임
- 다음은 4% 를 밀도 임곗값으로 사용하여 이상치를 구분하는 방법을 보여줌
~~~python
import numpy as np
densities = gm.score_samples(X)
density_threshold = np.percentile(densities, 4)
anomalies = X[densities < density_threshold]
~~~
- 이와 비슷한 작업은 특이치 탐지(novelty detection)임. 이 알고리즘은 이상치로 오염되지 않은 "깨끗한" 데이터셋에서 훈련한다는 것이 이상치 탐지와 다름
- 이상치 탐지는 이런 가정을 하지 않음. 실제로 이상치 탐지는 데이터셋을 정제하는 데 자주 사용됨
- 가우시안 혼합 모델은 이상치를 포함해 모든 데이터에 맞추려고 함. 따라서 이상치가 너무 많으면 모델이 정상치를 바라보는 시각이 편향되고 일부 이상치를 정상으로 판단할 우려가 있음
- 이런 일이 일어나면 먼저 한 모델을 훈련하고 가장 크게 벗어난 이상치를 제거합니다.그다음 정제된 데이터셋에서 모델을 다시 훈련함
- 또 다른 방법은 안정적인 공분산 추정 방법을 사용하는 것(`EllipticEnvelope` 클래스 참조)
- k-means 처럼 GaussianMixture 알고리즘은 클러스터의 개수를 지정해야 함

### 클러스터 개수 선택하기
- k-평균에서는 이너셔나 실루엣 score를 통해 최적의 클러스터 개수를 선택함
- 가우시안 혼합에서는 이런 지표를 사용할 수 없음 
- 이런 지표들은 클러스터가 타원형이거나 크기가 다를 때는 안정적이지 못하기 때문
- 대신 정의된 BIC(Bayesian information criterion)나 AIC(Akaike information criterion)과 같은 이론적 정보 기준을 최소화하는 모델을 찾음
- BIC와 AIC의 식은 다음과 같음
<p align = 'center'><img src="https://latex.codecogs.com/svg.image?AIC&space;=&space;2p&space;-&space;2log(\hat{L})" title="AIC = 2p - 2log(\hat{L})" /></p>
<p align = 'center'><img src="https://latex.codecogs.com/svg.image?BIC&space;=&space;log(m)p&space;-&space;2log(\hat{L})" title="BIC = log(m)p - 2log(\hat{L})" /></p>

- m은 샘플의 개수
- p는 모델이 학습할 파라미터의 개수
- L은 모델의 가능도 함수(likelihood function)의 최댓값
- BIC와 AIC는 모두 학습할 파라미터가 많은 모델에게 벌점을 가하고 데이터에 잘 학습하는 모델에게 보상을 더함
- 이 둘은 종종 동일한 모델을 선택함. 둘의 선택이 다를 경우 BIC가 선택한 모델이 AIC가 선택한 모델보다 더 간단한(파라미터가 적은) 경향이 있음
- 하지만 데이터에 아주 잘 맞지 않을 수 있음(특히 대규모 데이터셋에서 그럼)
- `bic()`와 `aic()` 메서드를 사용해 BIC와 AIC를 계산함
~~~python
gm.bic(X)
gm.aic(X)
~~~


#### 가능도 함수(likelihood function)
- 확률(probability)와 가능도(likelihood)는 종종 구별 없이 사용됨. 하지만 통계학에서 이 둘은 다른 의미로 사용됨
- 파라미터 theta인 확률 모델이 주어지면 <b>확률</b>은 미래 출력 x가 얼마나 그럴듯한지 설명함(파라미터 값 theta를 알고 있다면)
- 반면 <b>가능도</b>는 출력 x를 알고 있을 때 특정 파라미터 값 theta가 얼마나 그럴듯한지 설명함
- -4와 +1이 중심인 두 개의 가우시안 분포를 가진 1D 혼합 모델을 생각해보자. 간단하게 나타내기 위해 이 모델은 두 분포의 표준편차를 제어하기 위한 파라미터 theta를 하나 가짐
- 아래 그림에서 왼쪽 위 그래프는 x와 theta의 함수로 전체 모델 f(x; theta)를 보여줌
- 미래 분포 x의 확률 분포를 예측하려면 모델 파라미터 theta를 지정해야 함
- 예를 들어 theta를 1.3 (수평선)으로 설정했다면 왼쪽 아래 그래프와 같은 확률 밀도 함수(f(x; theta=1.3))를 얻음
- x가 -2와 +2 사이에 들어갈 확률을 예측하려 한다면 이 범위에서 PDF의 적분을 계산해야 함(즉, 그림자 부분의 면적)
- 하지만 theta를 모른 채 대신 샘플 x = 2.5(왼쪽 위 그래프에 있는 수직선) 하나를 관측했다면 어떻게 할 수 있을까요?
- 이 경우 오른쪽 위 그래프에 나타난 가능도 함수 L(theta|x=2.5) = f(x=2.5; theta)를 얻음

![img](https://github.com/koni114/TIL/blob/master/Machine-Learning/img/GMM_4.png)

- 간단히 말해 PDF는 x의 함수임(theta 고정). 반면 가능도 함수는 theta의 함수(x 고정)
- 가능도 함수가 확률 분포가 아니라는 것을 이해하는 것이 중요함. 가능한 모든 x에 대해서 확률 분포를 적분하면 항상 1이됨. 하지만 가능한 모든 theta에 대해서 가능도 함수를 적분하면 어떤 양숫값도 될 수 있음
- 데이터셋 X가 주어졌을 때 일반적으로 모델 파라미터에 대해 가장 그럴듯한 값을 예측함
- 이를 위해 X에 대한 가능도 함수를 최대화하는 값을 찾아야 함. 이 예에서 샘플 x = 2.5 하나를 관측했다면 theta의 최대 가능도 추정(maximum likelihood estimate, MLE)는 theta = 1.5임
- theta에 대한 사전 확률 분포 g가 존재한다면 L(theta|x)를 최대화하는 것보다 L(theta|x)g(theta)를 최대화 하는 것이 가능함
- 이를 최대 사후 확률(maximum a-psteriori, MAP)이라고 함. MAP가 파라미터 값을 제약하므로 이를 MLE의 규제 버전으로 생각할 수 있음
- 가능도 함수를 최대화하는 것은 이 함수의 로그를 최대화하는 것과 동일(오른쪽 아래 그래프)
- 로그 함수는 항상 증가하는 함수이기 때문에 theta가 로그 가능도를 최대화하면 이는 가능도도 최대화함
- 일반적으로 로그 가능도를 최대화하는 것이 더 쉬운데, 예를 들어 여러 개의 독립적인 샘플 x(1) ~ x(m)을 관측했다면 개별 가능도 함수의 곱을 최대화하는 theta를 찾아야 함. 하지만 로그 가능도 함수의 합을 최대화하는 것이 동일하면서도 훨씬 쉬움
- 로그의 곱셈을 덧셈으로 바꿀 수 있는 성질 덕분임(log(ab) = log(a) + log(b))
- 가능도 함수를 최대화하는 theta값 theta hat을 추정하고 나면 AIC와 BIC를 계산하기 위해 필요한 값인 L = L(hat theta, X)를 계산할 준비가 됨. 이를 모델이 데이터에 얼마나 잘 맞는지 측정하는 값으로 생각할 수 있음
