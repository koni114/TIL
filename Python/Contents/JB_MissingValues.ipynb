{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNH300WzZqKZ"
   },
   "source": [
    "### 결측값 확인하기 : isnull, notnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmV4-I-5aEns"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_left = pd.DataFrame({\n",
    "    'KEY': ['K0', 'K1', 'K2', 'K3'],\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': [0.5, 2.2, 3.6, 0.4]})\n",
    "\n",
    "df_right = pd.DataFrame({\n",
    "    'KEY': ['K2', 'K3', 'K4', 'K5'],\n",
    "    'C': ['C2', 'C3', 'C4', 'C5'],\n",
    "    'D': ['D2', 'D3', 'D4', 'D5']})\n",
    "\n",
    "df_all = pd.merge(df_left, df_right, how='outer', on='KEY')\n",
    "df_all\n",
    "\n",
    "#- DataFrame 전체의 결측값 여부 확인\n",
    "#- df.isnull(), pd.isnull(df), df.notnull(), pd.notnull(df)\n",
    "#- df.isnull()과 pd.isnull(df)은 같은 의미\n",
    "#- df.notnull()과 pd.notnull(df)은 같은 의미\n",
    "\n",
    "pd.isnull(df_all)\n",
    "pd.notnull(df_all)\n",
    "\n",
    "df_all.isnull()\n",
    "df_all.notnull()\n",
    "\n",
    "#- 특정 변수, 특정 컬럼에 결측값 입력하기 ** 중요!\n",
    "#- ** string 형식인 경우에 None을 할당하면, 'None'으로 입력\n",
    "#- ** float 형식인 경우에 None을 할당하면,  NaN으로 자동으로 입력됨\n",
    "df_all.loc[[0,1], ['A', 'B']] = None\n",
    "df_all\n",
    "\n",
    "#- 컬럼별 결측값 개수 구하기 : df.isnull().sum()\n",
    "df_all.isnull().sum()\n",
    "\n",
    "#- 행단위로 결측값 개수 구하기\n",
    "df_all.isnull().sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6P9CIIQbp-u"
   },
   "source": [
    "### 결측값 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "od9ZT-OrijBa"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "  np.arange(10).reshape(5, 2),\n",
    "  columns= ['C1', \"C2\"],\n",
    "  index = ['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "df.loc[['b', 'e'], ['C1']] = None\n",
    "df.loc[['b', 'c'], ['C2']] = None\n",
    "\n",
    "#- 결측 존재시, sum(), cumsum() --> 결측을 제외하고 계산\n",
    "df.sum()\n",
    "df['C1'].sum()\n",
    "df['C1'].cumsum()\n",
    "\n",
    "#- mean(), std() 연산 시 : NaN은 분석 대상에서 제외\n",
    "#  --> 산술 평균이나 표준편차 값을 계산할 때, NaN이 포함된 경우는 아예 분모에서 카운트를 제외\n",
    "df.mean()\n",
    "df.std()\n",
    "\n",
    "#- DataFrame 컬럼 간 연산 시, 하나의 Row에 NaN이 하나라도 포함되어 있으면 NaN return\n",
    "df['C3'] = df['C1'] + df['C2']\n",
    "df\n",
    "\n",
    "#- DataFrame 끼리의 연산(df1 + df2) \n",
    "#- 같은 명의 컬럼인 경우에는 NaN을 0으로 계산하고 연산. \n",
    "#- 같은 명의 컬럼이 없는 경우는 모든 값을 NaN으로 연산\n",
    "df2 = pd.DataFrame({\n",
    "    'C1':[1, 1, 1, 1, 1],\n",
    "    'C4':[1, 1, 1, 1, 1]},\n",
    "    index = ['a', 'b', 'c', 'd','e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YV0lVYUizqL"
   },
   "source": [
    "### 결측값 채우기\n",
    "- 결측값을 특정 값으로 채우기\n",
    "- 결측값을 앞 방향 또는 뒷 방향으로 채우기\n",
    "- 결측값 채우는 회수를 제한하기\n",
    "- 결측값을 특정 통계량으로 채우기\n",
    "- 결측값을 다른 변수의 값으로 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ofS8ZYZmIFW"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "  np.arange(15).reshape(5, 3),\n",
    "  columns= ['C1', \"C2\", \"C3\"])\n",
    "\n",
    "#- 결측값으로 대체하는 방법은 None으로 할당하거나, np.nan 할당\n",
    "df.iloc[0,0] = None\n",
    "df.loc[1, ['C1', 'C3']] = np.nan\n",
    "df.loc[2, ['C2']] = np.nan\n",
    "df.loc[3, ['C2']] = np.nan\n",
    "df.loc[4, ['C3']] = np.nan\n",
    "df\n",
    "\n",
    "#- (1) 결측값을 특정 값으로 채우기 : df.fillna()\n",
    "df_fill_zero = df.fillna(0)\n",
    "df_fill_zero\n",
    "\n",
    "df_fill_missing = df.fillna(\"missing\")\n",
    "df_fill_missing\n",
    "\n",
    "#- (2) 결측값을 앞 방향 또는 뒷 방향으로 채우기\n",
    "df.fillna(method = 'ffill')   #- 앞 방향\n",
    "df.fillna(method = 'pad')     #- 앞 방향\n",
    "\n",
    "df.fillna(method = 'bfill')     #- 뒷 방향\n",
    "df.fillna(method = 'backfill')  #- 뒷 방향\n",
    "\n",
    "#- 앞/뒤 방향으로 결측값 채우는 회수를 제한하기\n",
    "#- --> 컬럼별 데이터에서 결측값이 연속으로 생성되어 있는 부분에서 limit을 걸어서 NaN을 채울 최대 수를 지정\n",
    "#- limit paramter로 값 지정\n",
    "\n",
    "df.fillna(method = 'ffill', limit = 1)\n",
    "df.fillna(method = 'bfill', limit = 1)\n",
    "\n",
    "#- 결측값을 변수별 평균으로 대체하기 : df.where\n",
    "\n",
    "#- 컬럼에 존재하는 결측값을 컬럼별로 할당\n",
    "#- 하단의 두 가지 방법 사용 가능\n",
    "df.fillna(df.mean())\n",
    "df.where(df.notnull(), df.mean(), axis = 'columns')\n",
    "\n",
    "#- C1 컬럼의 평균을 가지고, (C1, C2, C3) 결측값 대체 예제\n",
    "df.fillna(df.mean()['C1'])\n",
    "\n",
    "#- C1, C2 컬럼만 각각 결측값 대체하고 C3는 대체 안하는 경우\n",
    "df.fillna(df.mean()['C1':'C2'])\n",
    "\n",
    "#- 결측값을 다른 변수의 값으로 대체하기\n",
    "#- C2 컬럼에 결측값이 없으면 C2 값을 그대로 사용, 있으면 C1 컬럼의 값을 가져다가 대체\n",
    "#- 단순 for loop를 사용하는 것 보다, np.where, pd.notnull를 사용하는 것이 훨씬 유리\n",
    "df['C2_New'] = np.where(pd.notnull(df['C2']) == True, df['C2'], df['C1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5zxDDKmmaXn"
   },
   "source": [
    "### 결측값 있는 행 제거 : dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVHbOIp-DzeA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(5,4),\n",
    "    columns = ['C1', 'C2', 'C3', 'C4'])\n",
    "df.iloc[[0,1], [0]] = None\n",
    "df.iloc[[2], [1]] = None\n",
    "df_drop_row = df.dropna(axis = 0) # 행제거\n",
    "df_drop_col = df.dropna(axis = 1) # 열제거\n",
    "df['C1'].dropna() # C1 컬럼만 선택하여 열제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SpC0cPoE0ez"
   },
   "source": [
    "### 결측값 보간하기(interporlation of missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsaUl5PGFoYc"
   },
   "outputs": [],
   "source": [
    "# 시계열 데이터의 값에 선형으로 비례하는 방식으로 값을 보간(interpolate)\n",
    "from datetime import datetime\n",
    "datestrs = ['12/01/2016', '12/03/2016', '12/04/2016', '12/10/2016']\n",
    "datestrs = pd.to_datetime(datestrs)\n",
    "ts = pd.Series([1, np.nan, np.nan, 10], index = datestrs)\n",
    "\n",
    "# (1) 시계열 데이터의 값에 선형으로 비례하는 방식으로 결측값 보간\n",
    "ts.interpolate()\n",
    "ts.interpolate(method='time')  # --> method = time 지정시, index 날짜를 기준으로 linear하게 보간됨\n",
    "\n",
    "# (2) DataFrame 값에 선형으로 비례하는 방식으로 결측값 보간\n",
    "df = pd.DataFrame({'C1':[1, 2, np.nan, np.nan, 5], 'C2':[6, 8, 10, np.nan, 20]})\n",
    "df.interpolate(method = 'values')\n",
    "\n",
    "# (3) 결측값 보간 개수 제한하기 : limit\n",
    "ts.interpolate(method = 'time', limit = 1)\n",
    "df.interpolate(method = 'values', limit = 1)\n",
    "\n",
    "# (4) 보간 방향 설정하기 : limit_direction = both, forward, backward\n",
    "ts.interpolate(method = 'time', limit = 1, limit_direction = 'both')\n",
    "df.interpolate(method = 'values', limit = 1, limit_direction = 'backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LfgAGSV_Fo3"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datestrs = ['12/01/2016', '12/03/2016', '12/04/2016', '12/10/2016']\n",
    "datestrs = pd.to_datetime(datestrs)\n",
    "ts = pd.Series([1, np.nan, np.nan, 10], index = datestrs)\n",
    "\n",
    "df = pd.DataFrame({'C1':[1, 2, np.nan, np.nan, 5], 'C2':[6, 8, 10, np.nan, 20]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhlLFx5AUZtw"
   },
   "source": [
    "### 결측값, 원래 값을 다른 값으로 대체하기 : replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5aVEyXb8JaI"
   },
   "outputs": [],
   "source": [
    "## replace 와 fillna 함수는 유사한 면이 있지만,\n",
    "## replace 함수는 결측값이 아닌 대체값 용도로 사용이 가능하며, list, mapping dict 등으로 좀더 유연하고 포괄적으로 사용할 수 있는 장점이 있음\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ser = pd.Series([1, 2, 3, np.nan])\n",
    "\n",
    "# (1) 결측값, 실측값으로 대체\n",
    "ser.replace(2, 20)\n",
    "ser.replace(np.nan, 20)\n",
    "\n",
    "# (2) list를 list로 대체 \n",
    "ser.replace([1, 2, 3, 4, np.nan], [6, 7, 8, 9, 10])\n",
    "\n",
    "# (3) mapping dict로 원래 값, 교체할 값 매핑 : replace({old1 : new1, old2 : new2})\n",
    "ser.replace({1:100, 2:200, 3:300, np.nan:400})\n",
    "\n",
    "# (4) DataFrame의 특정 컬럼 값 교체하기: df.replace({'col1':old_val}, {'col1':new_val})\n",
    "df = pd.DataFrame(\n",
    "    {'C1':['a_old', 'b', 'c', 'd', 'e'],\n",
    "     'C2':[1,2,3,4,5],\n",
    "     'C3':[6,7,8,9,np.nan]}\n",
    ")\n",
    "df = df.replace({'C1':'a_old'}, {'C1':'a'})\n",
    "df = df.replace({'C3':np.nan}, {'C3': 10})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i156GF8x_EO5"
   },
   "source": [
    "### 중복값 확인 및 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHOvzm9W_flr",
    "outputId": "88b44023-8f03-4a30-fc65-03c3a625dc86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    {'key1':['a', 'b', 'b', 'c', 'c'],\n",
    "     'key2':['v', 'w', 'w', 'x', 'y'],\n",
    "     'col':[1, 2, 3, 4, 5]}\n",
    ")\n",
    "\n",
    "# (1) 중복 데이터가 있는지 확인 : df.duplicated()\n",
    "df.duplicated(['key1'])\n",
    "df.duplicated(['key1', 'key2'])\n",
    "\n",
    "# (2) 중복이 있으면 처음과 끝 중 무슨 값을 남길 것인가? : keep = 'first', 'last', False\n",
    "# keep = 'first' --> 중복시 첫번째 값만 False, 나머지는 True\n",
    "# keep = 'last'  --> 중복시 마지막 값만 False, 나머지는 True\n",
    "# keep = False   --> 중복값 모두 True, 중복되는 행 자체를 남기지 않음\n",
    "df.duplicated(['key1'], keep = 'first')\n",
    "df.duplicated(['key1'], keep = 'last')\n",
    "df.duplicated(['key1'], keep = False)\n",
    "\n",
    "# (3) drop_duplicates()\n",
    "df.drop_duplicates(['key1'], keep = 'first')\n",
    "df.drop_duplicates(['key1'], keep = 'last')\n",
    "df.drop_duplicates(['key1'], keep =  False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "JB_MissingValues.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
