## part1 - 개요
- 데이터를 다양한 방법으로 변화시키고 정리하는 법
- 병렬-분산 처리
- 테스크 조직화
- 스트림 프로세싱

### 데이터 엔지니어링이란
- 데이터 기반 의사결정을 위한 인프라 만들기
- 비즈니스 의사결정을 위하여 데이터 엔지니어링 필요
  - 가격책정
  - 모니터링
  - 분석
- 서비스 운영/개선을 위한 의사결정을 위해 데이터 엔지니어링 필요
  - A/B 테스트
  - UI/UX  
  - 운영 자동화

### 모던 데이터 엔지니어링 아키텍처
#### 데이터 웨어하우스
- 과거에는 컴퓨팅 파워와 용량이 비싸며, 용도가 정해져 있었고, 데이터가 나올 곳도 정해져 있었음
- 과거 데이터 관리 방식
  - 데이터의 형식, 스키마를 미리 만들어야 함
  - 데이터의 변동이 별로 없음
  - 효율적인 데이터베이스 모델링이 중요 
  - ETL 의 세가지 step 으로 진행됨
- 현재 데이터 관리 방식
  - 데이터로 할 수 있는 일이 다양해지고 형태를 예측하기 불가능해지면서 스키마 정의가 힘들어짐
  - 실시간성을 요구하는 기능들
  - 빨라지는 기능 추가
  - 실시간 로그
  - 비정형 데이터
  - 서드 파티 데이터(데이터가 한군데서만 나오는게 아니라 여러 군데에서 발생) 
- 컴퓨팅 파워도 많이 저렴해짐
- 최대한 많은 데이터를 미리 저장해두고 많은 양의 프로세싱을 더할 수 있게 됨
- 일반적인 회사에서는 컴퓨팅 파워에 대한 비용 최적화보단 비즈니스 속도를 최적화하는 것이 이득이 큼
- <b>최근에는 ETL -> ELT 방식의 아키텍처로 변환되고 있음</b>
  - 데이터, 로그를 Spark 또는 Flink를 통해 어느정도 정리 후 저장(E & L)
  - 어플리케이션 혹은 분석 Tool에서 이용 가능하도록 변환(T) 
- 데이터 인프라 트렌드
  - 클라우드 웨어하우스 - Snowflake, Google Big Query
  - Hadoop 에서 Databricks, Presto 같은 다음 세대로 넘어가고 있음
  - 실시간 빅데이터 처리(Stream Processing)
  - ETL -> ELT
  - Dataflow 자동화(Airflow)
  - 데이터 분석 팀을 두기 보단 누구나 분석할 수 있도록
  - 중앙화 되는 데이터 플랫폼 관리(access control, data book) 

#### 데이터 엔지니어링 도구들
![img](https://github.com/koni114/TIL/blob/master/Data-Engineering/fastcampus/img/DE_01.png)

- 일반적인 엔지니어링은 "수집 및 변환" 그리고 "데이터 처리"에 집중

### Batch and Stream processing
#### Batch
- 일괄 처리라는 의미
- 많은 양의 데이터를 정해진 시간에 일괄적으로 처리하는 것
  - 한정된 대량의 데이터
  - 특정 시간
  - 일괄 처리 
- 전통적으로 쓰이는 데이터 처리 방법
- 실시간성을 보장하지 않아도 될 때
- 데이터를 한꺼번에 처리할 수 있을 때
- 무거운 처리를 할 때(ML 학습)
- 예시
  - 매일 다음 14일의 수요와 공급을 예측
  - 매주 사이트에서 관심을 보인 유저들에게 마케팅 이메일 전송
  - 매주 발행하는 뉴스레터
  - 매주 새로운 데이터로 머신러닝 알고리즘 학습
  - 매일 아침 웹 스크래핑/크롤링
  - 매달 월급 지급  

#### Stream processing
- 실시간으로 쏟아지는 데이터를 계속 처리하는 것
- 불규칙적으로 데이터가 들어오는 환경을 가정
  - 여러개의 이벤트가 한꺼번에 들어올 때
  - 오랜 시간동안 이벤트가 하나도 들어오지 않을 때 
  - 배치로 처리하게 되면 불필요한 리소스를 소모하며, 스트림 프로세싱을 통해 처리하면 리소스를 효율적으로 가져갈 수 있음  
- 스트림 프로세싱
  - 실시간성을 보장해야 할 때
  - 데이터가 여러 소스로부터 들어올 떄
  - 데이터가 가끔 들어오거나 지속적으로 들어올 때
  - 가벼운 처리를 할 떄(Rule-based) 
- 스트림 프로세싱 예
  - 사기 거래 탐지(Fraud Detection)
  - 이상 탐지(Anomaly Detection)
  - 실시간 알림
  - 비즈니스 모니터링
  - 실시간 수요/공급 측정 및 가격 책정
  - 실시간 기능이 들어가는 어플리케이션 

#### Batch vs Stream
- 일반적인 배치 플로우
  - 데이터를 모아서
  - 데이터베이스에 읽어서 처리
  - 다시 데이터베이스에 담기 
- 일반적인 스트림 처리 플로우
  - 데이터가 들어올때마다(ingest)
  - 쿼리/처리 후 State 를 업데이트
  - DB에 담기 

#### 마이크로 배치
- 데이터를 조금씩 모아서 프로세싱하는 방식
- Batch 프로세싱을 잘게 쪼개서 스트리밍을 흉내내는 방식
- 대표적으로 Spark Streaming이 마이크로 배치 방식을 사용

#### 실 서비스 활용 예 - 머신러닝
- 우버 내부에서 배달에 걸리는 시간등을 예측하는데 사용
- 온라인 
  - 실시간 예측을 위한 부분
  - 지금의 데이터를 처리
  - 데이터가 무한이라고 가정
- 오프라인
  - 실시간이 아니어도 되는 부분 
  - 과거의 데이터를 처리 
  - 데이터가 한정적이라고 가정       

![img](https://github.com/koni114/TIL/blob/master/Data-Engineering/fastcampus/img/DE_02.png)

- 데이터를 관리할 때, <b>온라인은 실시간 데이터를 스트림 엔진을 통해 DB에 저장</b>
- 오프라인은 과거의 데이터를 한꺼번에 처리하는 배치 파이프라인을 통해 DB에 저장
- 머신러닝 학습은 무거운 프로세스이기 때문에 오프라인 배치 프로세싱으로 학습
- 학습된 머신러닝 모델
  - 다른 배치 프로세싱에도 쓰일 수 있도록 배포
  - 실시간 온라인 서비스에서도 쓸 수 있도록 배포

### Dataflow Orchestration
#### Orchestration 이란?
- 테스크 스케줄링
- 분산 실행
- 테스크간 의존성 관리

#### Orchestration 은 왜 필요한가? 
- 서비스가 커지면서 데이터 플랫폼의 복잡도가 커짐
- 데이터가 사용자와 직접 연관되는 경우가 늘어남  
  (워크플로우가 망가지면 서비스도 망가짐)
- 테스크 하나하나가 중요해짐
- 테스크간 의존성도 생김

### 데이터 엔지니어링 프로젝트 소개
- 배치 파이프라인과 스트림 파이프라인을 동시에 사용하는 ML 데이터 학습 + 서빙 파이프라인

#### 배치 파이프라인
- Data(Source) -> Spark Job(데이터 프리프로세싱) -> Spark Job(ML 학습) -> Data(저장)
- Spark Job은 apache Airflow 사용

#### 스트림 파이프라인
- 데이터(Source) -> Kafka(이벤트 처리) -> Flink(이벤트 처리) -> Data(저장)

![img](https://github.com/koni114/TIL/blob/master/Data-Engineering/fastcampus/img/DE_03.png)