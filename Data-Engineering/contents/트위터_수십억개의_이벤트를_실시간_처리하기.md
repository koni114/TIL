# 트위터 수십억 개의 이벤트를 실시간 처리하기
- 트위터는 어떻게 수십억 개의 이벤트를 실시간으로 처리할 수 있을까? 에 대한 처리 방법 알아보기

## 트위터 데이터
- 트위터는 매일 페타바이트(PB) 규모의 데이터를 생산하며 약 4천억 개의 이벤트를 실시간으로 처리하고 있음
- 이러한 이벤트는 다양한 데이터 소스로부터 생성되며, 하둡(Hadoop), 버티카(Vertica), 맨하탄(Manhattan) 분산 데이터베이스, 카프카(Kafka), 트위터 이벤트버스(Twitter Eventbus), GCS, 빅쿼리(BigQuery), PubSub 등 다양한 플랫폼과 스토리지 시스템을 사용

- 실시간 데이터 수집시 고려해야 할 것.
  - 수집 대상(데이터 선정)
  - 집계 수준, 시간 단위 등 다양한 측정 항목(Metrics)과 측정 기준(Dimension)
    - 낮은 지연시간과 높은 정확도로 빠른 응답을 보장해야 함
    - 해당 시스템 구축을 위해서는 워크플로우 -> 전처리 -> 이벤트 집계 -> 데이터 제공의 단계 구분 필요 
  - 데이터 규모에 맞는 DB 선정 및 event/batch streamming platform 선정
    - DataBase: In-memory 기반 DB 
    - event streamming/stream processing : kafka, Flink, Databricks/Spark