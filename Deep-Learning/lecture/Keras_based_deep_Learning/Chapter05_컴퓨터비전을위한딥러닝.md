## Chapter_05 컴퓨터 비전을 위한 딥러닝

### 5.1 합성곱 신경망 소개
- 컨브넷(convnet)이라고 불리우는 합성곱 신경망(convolutional neural network)은  
  컴퓨터 비전에 사용됨
- 컨브넷은 (image_height, image_width, image_channels) 크기의 입력 텐서를 가짐  
  MNIST에서는 이미지 포멧인 (28, 28, 1) 크기의 입력을 처리하도록 convnet을 설정해야 함  

#### 간단한 convnet 만들기
~~~
model = model.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28,  1)))
model.add(layers.MaxPooling2D(2, 2))
model.add(layers.Conv2D(64, (3 ,3), activation = 'relu'))
model.add(layers.MaxPooling2D(2, 2))
model.add(layers.Conv2D(64, (3 ,3), activation = 'relu'))

model.add(layers.flatten())
model.add(layers.Dense(64, activation = 'relu'))
model.add(layers.Dense(10, activation = 'softmax'))
~~~

- Conv2D, MaxPooling2D 층의 출력은 (height, width, channels) 크기의 3D 텐서
- 너비와 높이는 네트워크가 깊어질수록 작아지는 경향이 있음  
  --> 출력층에 가까워 질수록 너비와 높이가 작아진다는 말  
- model.add를 통해 층을 추가할 때, 순서가 꼬이지 않도록 조심 

#### 합성곱 연산
- dense layer와 합성곱 층 사이의 근본적인 차이  
  --> 완전 연결 층은 전역 패턴을 학습하는 반면에 합성곱 층은 지역 패턴을 학습  
- 이 핵심 특징은 convNet에 2가지 흥미로운 성질을 제공

1. 학습된 패턴은 평행 이동 불변성(translation invariant)을 가짐
- 예를 들어, 왼쪽 이미지 상단 모서리에서 어떤 패턴을 학습했으면, 오른쪽 상단 모서리에 동일한 패턴을 인식할 수 있음  
반면에 Dense Layer는 다르게 인식  
잘 생각해보면, 우리가 볼 때 평행 이동으로 인해 다르게 인식되지 않음  
--> 적은 샘플로 일반화 능력을 가질 수 있게 됨

2. 패턴의 공간적 계층 구조를 학습할 수 있음
- 첫 번째 합성곱 층이 edge같은 작은 지역 패턴을 학습하고,  
  두 번째 합성곱 층이 첫 번째 합성곱 층의 특성으로 구성된 더 큰 패턴을 학습  
  --> 이런 방식을 이용하여 convNet은 복잡하고 추상적인 시각적 개념을 효과적으로 학습  

- 합성곱 연산은 특성 맵(feature map) 이라고 불리우는 3D 텐서에 적용  
이 텐서는 2개의 공간 축(높이와 너비)과 깊이 축(채널 축)으로 구성  
-> RGB(컬러) 이미지는 channel이 3, 흑백은 1

- 합성곱 연산은 이러한 feature Map에서 작은 패치들을 추출하고  
  모든 패치에 같은 변환을 적용하여 출력 특성 맵(output feature map)을 만듬  

- output feature Map도 높이와 너비를 가지는 3D tensor  
  깊이(channel)은 층의 매개변수로 결정되기 때문에 그때 그때 다름  
  깊이 축은 더 이상 RGB를 나타내지 않음  
  일종의 filter 수를 나타냄 

- 합성곱 층에서 filter는 해당 층의 파라미터  
  Conv2D의 첫 번째 매개변수가 출력 특성 맵의 차원을 결정  
  필터는 입력 데이터의 어떤 특성을 인코딩한 결과  
  ex) 하나의 필터가 '입력에 얼굴이 있는지'를 인코딩 할 수 있음  

- model.add(layers.Conv2D(64 ( < -- ), (3, 3),  activation = 'relu'))  
  --> 64개의 filter가 존재  

- MNIST 예제에서 첫 번째 합성곱 층이 (28, 28, 1) 크기의 맵을 입력으로 받아 
  (26, 26, 32) 크기의 특성 맵을 출력함  
  --> 32개의 출력 채널은 각각 (26, 26) 크기의 배열을 가짐  
  이 값은 입력에 대한 필터의 응답 맵(response map)임  
  출력 맵 = 응답 맵

- 즉 특성 맵이란, 깊이 축에 있는 각 차원은 하나의 특성  
  2D 텐서(output[:, :, n])는 입력에 대한 이 필터 응답을 나타내는 2D 공간상의 맵

- 합성곱은 2개의 핵심적인 파라미터로 구성  
  1. 출력될 때 사용되는 패치의 크기  
     -> 3x3, 5x5 크기를 사용  
  2. 특성 맵의 출력 깊이  
     합성곱으로 계산할 필터의 수. MNIST 예제 같은 경우 32로 시작해서 64로 끝남    

- Conv2D 층에서 크게 2가지의 파라미터가 전달  
  --> Conv2D(특성 맵의 출력 깊이, (패치의 높이, 패치의 폭))

- 3D 입력 특성 위를 3x3 또는 5x5 크기의 윈도우가 sliding 하면서  
  모든 위치에서 3D 특성 패치를 추출하는 방식으로 합성곱이 작용  
  이때 3D 특성 패치는 출력 깊이만큼 생성  

- ex) 입력 특성 맵(5, 5, 2) 일 때, 너비 5, 높이 5 입력 깊이가 2  
  이를 3x3 패치로 출력 깊이가 3인 출력 특성 맵을 만든다고 하면(-> Conv2D(3, (3, 3)))  
  이 때 입력 패치는 (3, 3, 2)인 패치가 3개(깊이 3) 적용 된 것.  
  결과적으로 출력 특성 맵은 (3, 3, 3)이 나옴  
  --> 그림으로 이해하기(...p.177)

- 출력 특성 맵의 공간상 위치는 입력 특성 맵의 같은 위치에 대응  
  ex) 출력의 오른쪽 모서리의 특징은 입력의 오른쪽 아래 부근의 특징을 내포

- 출력 높이와 너비는 입력 높이와 너비와 다를 수 있음. 이유는 크게 2가지  
  - 경계 문제. input feature map에 padding을 추가 할 수 있음
  - 스트라이드(stride)의 사용 여부에 따라 다름 

#### 패딩(Padding)
- 입력과 동일한 높이와 너비를 가진 출력 특성 맵을 얻기 위해  
  입력 특성 맵의 가장자리에 적절한 개수의 행과 열을 추가 시키는 것  
- 이 때 추가 되는 행의 값이 0이면 zero padding 이라고 부름  
  3x3 윈도우 시, 상하좌우 1행씩 추가
  5x5 윈도우 시, 상하좌우 2행씩 추가

- Conv2D 층에서 padding 매개변수로 설정 가능  
  - padding = 'valid' : 패딩을 사용하지 않음  
  - padding = 'same'  : 입력과 동일한 높이와 너비를 가진 출력을 만들기 위해 패딩
  - default는 valid임

#### 합성곱 스트라이드
- 출력 크기에 영향을 미치는 다른 요소인 스트라이드  
- 합성곱 내 사용되는 패치(3x3, 5x5 window) 가 몇칸을 건너띄고 이동할 것인가?  
  를 결정하는 파라미터
- 기본 default가 1. 1이면 연속적으로 윈도우가 이동하는 것  
  우리가 생각하는 기본 이동  
  스트라이드가 2라고 하면, 5x5 입력 특성 맵에서 3x3 window를 사용하면  
  2x2 출력 특성 맵이 나옴  
  --> 그림으로 이해하자(p.179)

- 스트라이드 합성곱은 실전에서는 드물게 사용  
  하지만 특정 모델에서는 유용하게 사용 가능(https:/goo.gl/qvNTyu)

- 특성을 다운 샘플링 하기 위해서는  
  최대 풀링(max pooling)을 사용하는 경우가 많음  

#### 최대 풀링 연산(maxPooling)
- 특성 맵을 다운샘플링 하는 것이 최대 풀링 역할  
- 입력 특성 맵에서 윈도우에 맞는 패치를 추출, 각 채널별로 최대값을 추출  
  합성곱과 개념적으로는 비슷하지만, 추출한 패치에 학습된 선형 변환을 적용하는 대신 하드코딩된 최댓값 추출(해당 위치 값 중 가장 큰 값 추출)

- 합성곱과의 차이점  
  - 최대 풀링 : 2x2 윈도우와 스트라이드 2를 사용하여 특성 맵을 절반 크기로 다운 샘플링
  - 합성곱 : 3x3 윈도우(default)와 스트라이드 1을 사용  

- 왜 이런식으로 특성 맵을 다운 샘플링 하는 것일까?  
  반대로 풀링 연산을 제외하고, 합성곱으로만 이루어진 convNet을 사용한면 안되는 것일까?  

#### 합성곱으로만 이루어진 ConvNet의 2가지 문제점
- 앞선 MNIST의 CNN 모형을 기반으로 문제점을 파악해보자  
  --> 합성곱 층 3개로 이루어진 CNN 모형이라고 가정해보자
 
 1. 특성의 공간적 계층 구조를 학습하는데 도움이 잘 안됨  
  - 예를 들어 3x3 윈도우가 가지고 있는 정보량은 최초 입력 특성 맵의 7x7 윈도우 밖에 안됨  
  (7x7 크기 합성곱 -> 5x5 크기 합성곱 -> 3x3 크기 합성곱)
  - 마지막 합성곱 층의 특성이 전체 입력에 대한 정보를 가지고 있어야 함

2. 최종 특성 맵은 22 x 22 x 64 = 30976개의 가중치를 가짐
   -  합성곱만 계속 하게되면 줄어드는 비율이 -2만큼씩이므로, 너무 적은 비율로 줄어듬
   - 이 ConvNet을 펼친 후(flatten) Dense 층과 연결한다면, 15.8백만 개의 가중치가 생김  
   - 작은 모델 치고는 너무 많은 가중치이고 심각한 과대적합 발생  

- 결과적으로 다운샘플링 하는 이유는,
  - 특성 맵의 가중치 수를 효과적으로 줄이기 위함
  - 연속적인 합성곱 층이 점점 커진 윈도우를 통해 바라보도록 만들어 필터의 공간적 계층 구조 구성

- 최대풀링(max pooling)이 아닌 평균풀링(average pooling) 사용 가능  
  but, 최대풀링이 더 잘 작동하는 편  
  why? 특성이 특성 맵의 각 타일에서 어떤 패턴이나 개념의 존재 여부(있다, 없다) 여부를 인코딩 하는 경향이 있기 때문  
  따라서 특성의 평균값보다 여러 특성 중 최대값을 사용하는 것이 더 유용  

- 가장 보편적인 서브샘플링 방법? 
  스트라이드가 없는 합성곱으로 조밀한 특성 맵을 만들고, 작은 패치에 대해서 최대로 활성화된 특성을 고르는 것  
  스트라이드(2x2) 합성곱으로 듬성듬성 윈도우를 슬라이딩 하거나,  
  입력 패치를 평균해서 특성 정보를 놓치거나 희석시키는 것보다 나음  

### 5.2 소규모 데이터셋에서 밑바닥부터 convNet 훈련하기
- 매우 적은 데이터에서 이미지 분류 모델을 훈련하는 일은 흔한 경우임  
  여기서 말하는 매우 적음은 100 ~ 10000개
- 실용적인 예제로 4000개의 고양이/강아지 사진을 가지고  
  고양이와 강아지를 분류할 수 있는 모델을 만들어보자  

- 훈련 데이터 : 2000개
- 검증 데이터 : 1000개
- 테스트 데이터 : 1000개

- 2000개의 훈련 샘플을 그대로 사용, 기준이 되는 기본 성능 생성  
  --> 71% 성능의 모델 생성. 이유는 과대적합  
  이러한 모델을 augmentation을 통해 성능을 82까지 향상시켜보자  

#### 소규모 데이터셋에서 딥러닝 학습을 위한 핵심 기술 2가지
- pretrained model 네트워크로 특성 추출(90%의 정확도)
- pretrained model 네트워크를 세밀하게 튜닝(92%의 정확도)
- 이러한 전략은 작은 데이터셋에서 분류 문제를 수행할 때 반드시 알아야 하고,  
  도구 상자에 포함되어 있어야 함  

#### 소규모 데이터셋에서의 딥러닝의 타당성  
- 보통 딥러닝은 많은 데이터가 필요하다고 말함  
- 부분적으로는 맞음  
  딥러닝의 근본적인 특징은 훈련 데이터에서 특성 공학 없이 흥미로운 특성을 찾을 수 있는 것임  
- 하지만 많은 데이터라고 하는 것은 상대적임  
  훈련하려고 하는 네트워크의 깊이에 상대적  
- ConvNet은 지역적이고 평행 이동으로 변하지 않는 특성들을 학습하기 때문에  
  지각에 관한 문제에서 매우 효율적으로 데이터를 사용  
  --> 매우 작은 이미지 데이터셋에서 어떤 종류의 특성 공학을 사용하지 않고  
  컨브넷을 처음부터 훈련해도 납득할 만한 결과를 만들 수 있음    

#### 데이터 전처리
- JPEG file로 되어 있는 경우, 부동 소수 타입의 텐서로 적절히 전처리 되어 있어야 함  

1. 사진 파일을 읽는다
2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩
3. 부동 소수 타입 센서로 변환  
4. 0 ~ 255 사이의 스케일을 0 ~ 1 사이로 조정(신경망은 작은 값을 선호)

- keras는 자동으로 처리하는 유틸이 존재
- keras.preprocessing.image에 이미지 처리를 위한 헬퍼 도구들이 존재
- ImageDataGenerator class는 disk에 있는 이미지 파일을 전처리된  
  배치 텐서로 자동 변환해주는 python generator를 만들어 줌

#### fit generator
- fit_generator 메서드는 fit 함수와 동일하되, 데이터 제너레이터 사용
- 첫 번째 입력변수로 python generator 사용
- 데이터가 끝없이 생성되기 때문에 케라스 모델에 하나의 epoch를 정의하기 위해 
  generator에서 얼마나 많은 샘플을 뽑을 것인지 알려주어야 함  
- step_per_epoch(샘플의 배치 수) 설정해 주어야 함  
- validation data 매개변수를 전달 할 수 있음  
  파라미터 값은 데이터 제너레이터도 가능하지만, 넘파이 배열의 튜플도 가능  
- validation_data로 제너레이터를 전달하면 검증 데이터의 배치를 끝없이 반환  
  step_per_epoch 처럼, validation_steps 매개변수에 지정해야 함  

#### 데이터 증식(data augmentation) 사용하기  
- data augmentation은 기존의 있는 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방식  
- 그럴듯한 이미지를 여러가지 랜덤한 변환을 통해 샘플을 늘림  
- 데이터 증식을 통해 증식된 데이터와 함께 모델을 훈련시키고, 모델의 일반화를 만들어냄  
- generator를 통해 데이터 증식을 진행할 때, 전체 data volume이 증가하는 것이 아니라, 전체 volume에서 augmentation 부분이 추가되는 것  

- 케라스에서는 ImageDataGenerator가 읽은 이미지에 여러 종류의 랜덤변환을 적용토록 설정 가능  
    
#### 데이터 증식을 위한 파라미터 종류 설명
- rotation_range  
  랜덤하게 사진을 회전시킬 각도 범위(0 ~ 180 사이)  
  회전 각도 --> - rotation_range ~ + rotation_range

- width_shift_range, height_shift_range  
  사진을 수평과 수직으로 랜덤하게 평행 이동시킬 범위  
  전체 너비와 높이에 대한 비율  
  1보다 큰 실수이거나 정수일 때는 픽셀 값으로 간주  
  실수가 입력되는 경우, [-width_shift_range, +width_shift range) 가 됨 
  (폐구간, 개구간 확인)  

- shear_range  
  랜덤하게 전단 변환을 적용할 각도 범위.   
  keras 에서의 전단 변환은 y좌표가 증가함에 따라  
  조금씩 가로 방향으로 이동하는 가로 방향 전단 변환.
	-> y축 음수 위치에서 오른쪽 방향으로 이미지를 밀어   
  평생사변형으로 바뀐다고 생각하면 직관적임.   

- zoom_range  
  랜덤하게 사진을 확대할 범위
  실수가 입력되면 1-zoom_range ~ 1+zoom_range 사이로 확대 또는 축소가 됨.  
  
- horizontal_flip  
  랜덤하게 이미지를 수평으로 뒤집음.  
  수평 대칭을 가정할 수 있을 때 사용(ex) 풍경/인물 사진)  
  -> 좌우 반전  

- fill_mode  
  회전이나 가로/세로 이동으로 인해 새롭게 생성해야 할 픽셀을 채울 전략  
  -> nearest : 인접한 픽셀을 사용  
  -> constant : cval 매개변수의 값을 사용  
  -> reflect, wrap도 있음  

- 적은 수의 원본 이미지에서 결국 증식된 것이기 때문에  
  여전히 입력 데이터들 사이에 상호 연관성이 큼  
  --> 새로운 정보를 만들어 낼 수 없고, 단지 기존 정보의 재조합만 가능  
  --> 과대적합을 제거하기에 충분치 않을 수 있으므로, DropOut을 추가 가능  

- </b>검증 데이터는 augmentation data 사용해서는 안됨</b>

### 5.3 사전 훈련(pretrained model)된 convNet 사용하기
- 작은 이미지 데이터셋에 딥러닝을 적용하는 가장 효과적인 방법은  
  pretrained model을 사용하는 것  
- pretrained network는 대규모 이미지 분류 문제를 위해 대량의 데이터셋에서  
  미리 훈련되어 저장된 네트워크  
- 새로운 문제가 원래 작업과 완전히 다른 클래스에 대한 것이여도  
  이런 특성은 많은 컴퓨터 비전 문제에 유용  
- ex) 동물이나 생활 용품으로 이루어진 원본 데이터를 가지고 만든  
  모델을 가구 아이템을 식별하는 것 같은 용도로 사용 가능  
- 학습된 특성을 다른 문제에 적용할 수 있는 유연성은  
  딥러닝의 핵심 장점  

#### VGG16 pretrained model 통한 실습   
- keras.applications module에 VGG16 모델이 들어가 있음
- pretrained network를 사용하는 두가지 방법 존재  
  - 특성 추출(feature extraction)
  - 미세 조정(fine tuning)

#### 특성 추출
- 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서  
  흥미로운 특성을 뽑아 내는 것  
- 이런 특성을 사용하여 새로운 분류기를 처음부터 훈련  
- ConvNet은 이미지 분류를 위해 두 부분으로 구성  

1. 합성곱 기반 층
  - 특성 추출은 사전에 훈련된 네트워크의 합성곱 기반 층을 선택하여  
    새로운 데이터를 통과 시키고, 출력으로 새로운 분류기(마지막 출력 층)를 훈련시킴  
  - 일반적으로 합성곱 층만 재사용 함
  - 완전 출력 층은 잘 재사용 하지 않음. why? 합성곱 층에 의해 학습된 표현이  
    더 일반적이여서 재사용이 가능하기 때문  

- 합성곱 층 vs 완전 연결 분류기  
  - 합성곱층  
    사진에 대한 일반적인 콘셉트의 존재 여부를 기록한 맵  
    주어진 컴퓨터 비전 문제에 상관없이 유용하게 사용 가능  
  - 완전 연결 분류기  
    모델이 훈련된 클래스 집합에 특화되어있음  
    분류기는 전체 사진에 어떤 클래스가 존재할 확률에 관한 정보만 담고 있음  
    완전 연결 층에서 찾은 표현은 더 이상 입력 이미지에 있는 객체의 위치 정보를  
    가지고 있지 않음. -> 공간 개념을 제거  

- 합성곱 층에서 추출한 일반성 수준은 "모델의 층의 깊이"에 달려 있음  
  (몇번째 층이냐에 따라서 일반성 수준이 다름) 
  - 모델의 하위 층 : 지역적으로 매우 일반적인 특성 맵을 추출(edge, 색깔, 질감)
  - 모델의 상위 층 : 추상적인 개념 추출(강아지 눈, 귀, 코)

- 상위 층은 출력 층과 가까운 층, 하위 층은 입력 층과 가까운 층을 말함

#### VGG16 모델 만들기
- 3개의 매개변수 전달
1. weight
  - 모델을 초기화할 가중치 체크포인트 지정  

2. include_top
  - 최상위 완전 연결 층을 포함할지 여부 선택  
  - 기본값은 ImageNet의 클래스 1000개에 대응하는 완전 연결 분류기 포함  
  - 별도의(고양이와 강아지를 분류할 수 있는) 완전 연결 층을 추가할 것이므로 X

3. input_shape
  - 네트워크에 주입할 이미지 텐서의 크기(선택 사항)  
  - 지정하지 않으면, 어떠한 크기의 입력도 처리 가능  
  - 만약에 지정해 주려면 합성곱 층 하단에 올라가야 하므로, (224, 224, 3)이 되어야 함  
  
- 최종 특성 맵의 크기는 4, 4, 512임
  이 특성 위에 완전 연결 층을 놓을 것인데, 2가지 방법 가능  

1. 데이터 증식을 사용하지 않는 빠른 특성 추출  
  - 새로운 데이터 셋에서 합성곱 기반 층을 실행하고 난 출력을 넘파이 배열로 disk에 저장  
  - 다음 데이터를 독립된 완전 연결 분류기에 입력으로 사용  
  - 합성곱 연산은 비용(= 시간)이 매우 오래 걸리는데, 이 방법은 합성곱 기반 층을   
  - 한번만 실행시키면 되기 때문에 비용이 적게 듬. 하지만 data augmentation 은 사용 불가능  

2. 준비한 모델(conv_base) 위에 Dense 층을 쌓아 확장  
  - 거의 대부분 이 방법을 사용하는 것 같음  
  - 다음 입력 데이터에서 end-to-end로 전체 모델 실행(처음 입력 층 ~ 분류기까지 전부)  
  - 모델에 노출된 모든 입력 이미지가 매번 합성고 기반 층을 통과하기 때문에 데이터 증식 사용 가능  
  - 비용이 많이 듬  

#### 데이터 증식을 통한 특성 추출
- VGG16 합성곱 기반 층은 1,414,688개의 매우 많은 파라미터를 가지고 있음  
- 합성곱 기반 층 위에 추가한 분류기는 200만개의 파라미터를 가짐  
- 모델을 훈련하기 전에 합성곱 기반 층을 동결하는 것이 아주 중요
- 특히 출력층 쪽 Dense 층은 랜덤하게 초기화 되었기 때문에  
  매우 큰 가중치 업데이트 값이 네트워크에 전파됨  
  --> 결과적으로 기준 가중치가 크게 훼손

- keras에서는 trainable 속성을 False로 설정하여 네트워크 동결 가능  
  model.trainable = False

#### 미세 조정(fine tuning)
- 모델을 재사용하는데 널리 사용되는 또 하나의 기법 중 하나
- 특성 추출에 사용했던 동결 모델에 상위 몇 개를 동결에서 해제하고  
  모델에 새로 추가한 층과 함께 훈련
- 주어진 문제에 좀더 밀집하게 재사용 모델의 표현을 조정하는 것이기 때문에  
  fine-tuning이라고 함  

- 랜덤하게 초기화된 상단 분류기를 훈련하기 위해서는 VGG16의 합성곱 기반 층을  
  동결해야 함  
- 분류기가 미리 훈련되어 있지 않으면 훈련되는 동안 너무 큰 오차 신호가  
  네트워크에 전파됨  

- 네트워크 미세 조정하는 단계는 다음과 같음  
  - 사전 훈련된 기반 네트워크 위에 새로운 네트워크 추가  
  - 기존 pretrained model 네트워크 동결
  - 새로 추가된 네트워크 훈련
  - 기존 pretrained model 네트워크에서 일부 층 동결을 해제  
  - 동결을 해제한 층과 새로 추가한 층을 함께 훈련  

#### 미세 조정시 고려해야 할 사항 
- 주로 상위 층을 fine tuning 하는 것이 좋음  
  why? 하위 층(입력층 쪽)은 주로 기본적인 특성을 인코딩.  
  상위 층으로 갈수록 좀 더 특화된 특성을 인코딩
- 훈련해야 할 파라미터가 커질수록 과대적합의 위험이 있음  

#### 정리
- ConvNet은 Computer vision분야에서 가장 뛰어난 ML 모델.  
  작은 데이터셋에서도 좋은 성능을 냄  
- data augmentation을 통해 과대 적합 문제을 해결할 수 있음
- 특성 추출, fine-tuning 방식을 통해서 기존 pretrained model을 효과적으로  
  재사용 가능

### 5.4 ConvNet 학습 시각화
- 딥러닝은 보통 black-box 모델이라고 얘기하지만, ConvNet 은 아니다  
  ConvNet은 주로 이미지 데이터를 학습하기 때문에 오히려 시각화하기 좋음  

#### 시각화 기법 3가지  
- ConvNet의 중간층의 출력을 시각화  
  - 연속된 컨브넷 층이 입력을 어떻게 변형시키는지 이해      
  - 개별적인 컨브넷 필터의 의미를 파악하는데 도움  

- 컨브넷 필터를 시각화  
  - 컨브넷 필터가 찾으려는 시각적인 패턴과 개념이 무엇인지 상세하게  
    이해하는데 도움  

- 클래스 활성화에 대한 heatmap을 이미지에 시각화  
  - 이미지의 어느 부분이 주어진 클래스에 속하는 데 기여했는지 이해하고, 
    이미지에서 객체 위치를 추정하는데 도움이 됨  

#### ConvNet의 중간층의 출력을 시각화하기  
- 어떤 입력이 주어졌을 때 여러 합성곱과 폴링층이 출력하는 특성맵을 그리는 것  
  --> 층의 출력이 활성화 함수의 출력이여서 종종 activation이라고 부름  

- 네트워크에 의해 학습된 필터들이 어떻게 입력을 분해하는지 보여줌  
  필터를 지나고 난 후의 이미지를 확인할 수 있기 때문  

- 너비, 높이, 깊이 3개 차원에 대해 특성 맵을 시각화 하는 것이 좋음  
  각 channel은 비교적 독립적인 특성을 인코딩 함
  특성 맵의 각 채널 내용은 독립적인 특성을 인코딩하므로, 
  각 채널의 2D 이미지로 시각화 하는 것이 좋음  
  --> 각 층마다 특성 개수(filter 개수)만큼 이미지로 그려짐 

- 예제) 확인하고 싶은 특성 맵을 출력하기 위하여  
  이미지 배치를 입력으로 받아 모든 합성곱과 폴링 층의 activation을 출력하는  
  케라스 모델을 만들 것  
  --> keras의 Model class 사용(<-> Sequential 사용)

- 모델 객체를 만들 때 2개의 paramter 필요  
  - 입력 텐서
  - 출력 텐서

#### 각 층마다의 활성화를 시각화 하면 생기는 특징들
- 첫 번째 층은 여러 종류의 edge 감지기를 모아 둔 것 처럼 보임    
  -> 이 단계의 활성화에는 초기 사진의 모든 정보가 유지  

- 상위 층으로 갈수록 '고양이 눈', '고양이 귀' 처럼 고수준의 개념을 인코딩하기 시작함  
  --> 이미지의 시각적 콘텐츠에 관한 정보가 점점 줄어들고, 
  이미지의 클래스에 관한 정보가 점점 증가!

- </b>비어 있는 활성화가 깊어짐에 따라 늘어남</b>  
  첫 번째 층에서는 모든 필터가 입력 이미지에 활성화되었지만  
  층을 올라가면서 활성화되지 않는 필터들이 생김  
  필터에 인코딩된 패턴이 입력 이미지에 나타나지 않았다는 것을 의미  
  (입력 이미지에 값이 없다보니 커널을 거친 필터도 당연히 안보인다!)  

- 중간층의 활성화 시각화를 통해 알 수 있는 점
  - 층에서 추출한 특성은 층의 깊이를 더해 갈수록 더 추상적이게 됨
  - 심층 신경망은 입력되는 원본 데이터에 대한 정보 정제 파이프라인처럼 작동함  

#### 컨브넷 필터 시각화
- 각 필터가 반응하는 시각적 패턴을 그려 보는 것
- 빈 입력 이미지에서 시작해 특정 필터의 응답을 최대화하기 위해 컨브넷 입력 이미지에 경사 상승법을 적용  
--> 입력 데이터를 최대로 하게 되면, 해당 데이터가 필터를 거쳤을 때 
최대로 반응한다는 의미와 동일. 즉, 이 필터가 어떤 경우일 때 최대로 응답하는지를 알 수 있게 된다.

- 전체 과정
  - 특정 합성곱 층의 한 필터 값을 최대화하는 손실 함수 정의  
  - 이 활성화 값을 최대화하기 위해 입력 이미지를 변경하도록 확률적 경사 상승법 이용  

- 소스 분석

1. ImageNet에 사전 훈련된 VGG16 네트워크에서 block3_conv1 층 필터 0번의 활성화를 손실로 정의
2. 경사상승법을 구현하기 위해 모델의 입력에 대한 손실의 그래디언트가 필요

- keras.backend.function() 함수는 입력 값을 받아  
  지정된 출력 텐서들을 얻을 수 있는 keras.backend.Function 객체를 만들어 줌
- 필터 시각화를 통해 컨브넷 층이 바라보는 방식을 이해할 수 있음  
- 컨브넷의 각 층은 필터의 조합으로 입력을 표현할 수 있는 일련의 필터를 학습!  
  -> 이는 푸리에 변환을 사용하여 신호를 일련의 코사인 함수로 분해할 수 있는 것과 비슷  
- 이 컨브넷 필터들은 모델의 상위 층으로 갈수록 점점 더 복잡해지고 개선됨  

#### 컨브넷 필터 시각화 예제 적용
- 모델에 있는 첫 번째 층(block1_conv1)의 필터는 간단한 대각선 방향의 에지와 색깔을 인코딩
- block2_conv1 필터는 에지와 색깔의 조합으로 만들어진 간단한 질감을 인코딩
- 더 상위 층의 필터는 깃털, 눈, 나뭇잎 등 자연적인 이미지에서 찾을 수 있는 질감을 닮아 가기 시작


#### 경사 상승법 과정을 부드럽게 하기 위해 사용하는 한 가지 기법
- 그래디언트 텐서를 L2 노름(텐서에 있는 값을 제곱한 합의 제곱근)으로 나누어 정규화
- 이렇게 하면 입력 이미지에 적용할 수정량의 크기를 항상 일정 범위 안에 놓을 수 있음
- 이 방법을 그래디언트 클리핑(gradient clipping) 이라고 함
- 경사 상승법은 keras.optimizers 모듈 아래 있는 옵티마이저를 사용할 수 없고, 직접 학습 단계를 구현해야함  

#### 클래스 활성화의 히트맵 시각화하기
- 이미지의 어느 부분이 컨브넷의 최종 분류 결정에 기여하는지 이해하는데 도움이 됨
- 분류에 실수가 있는 경우, 컨브넷의 결정 과정을 디버깅 하는데 도움을 줌
- 일반적으로 ** 클래스 활성화 맵(Class Activation Map, CAM) 시각화라고 부름
- 입력 이미지에 대한 클래스 활성화의 히트맵을 만듬
- CAM은 특정 출력 클래스에 대해 입력 이미지의 모든 위치를 계산한 2D 점수 그리드
- 클래스에 대해 위치가 얼마나 중요한지 알려줌

- 예제는 Grad-CAM : Visual Expanations from Deep Networks via Gradient-based localization 에 기술되어 있는 것.
- 입력 이미지가 주어지면 합성곱 층에 있는 특성 맵의 출력을 추출
- 특성 맵의 모든 채널 출력에 채널에 대한 클래스의 그래디언트 평균을 곱함
- '입력 이미지가 각 채널을 활성화하는 정도'에 대한 공간적인 맵을   
  '클래스에 대한 각 채널의 중요도'로 가중치를 부여하여 '입력 이미지가 클래스를 활성화하는 정도'에 대한 공간적인 맵을 만드는 것!

### 요약
- 컨브넷은 시각적인 분류 문제를 다루는데 최상의 도구!
- 컨브넷은 우리가 보는 세상을 표현하기 위한 패턴의 계층 구조와 개념을 학습
- 학습된 표현은 쉽게 분석할 수 있음! 컨브넷은 블랙박스가 아닙니다!
- 이미지 분류 문제를 풀기 위해 자신만의 컨브넷을 처음부터 훈련시킬 수 있음
- 과대적합을 줄이기 위해 데이터를 증식하는 방법을 배움
- 사전 훈련된 컨브넷을 사용하여 특성 추출과 미세 조정하는 방법을 배움
- 클래스 활성화 히트맵을 포함하여 컨브넷이 학습한 필터를 시각화 할 수 있음!


### 용어 정리
- 패치(Patch)  
  합성곱 연산에서 사용되는 2D 형식의 보드라고 생각하면 됨  
  쉽게 말하자면.. 합성곱 연산에서 사용되는 2D tensor라고 생각하면 되지 않을까 싶음    

- 패딩(Padding)  
  입력과 동일한 높이와 너비를 가진 출력 특성 맵을 얻기 위해  
  입력 특성 맵의 가장자리에 적절한 개수의 행과 열을 추가 시키는 것  
  이 때 추가 되는 행의 값이 0이면 zero padding 이라고 부름  
  3x3 윈도우 시, 상하좌우 1행씩 추가  
  5x5 윈도우 시, 상하좌우 2행씩 추가  

- python generator  
  제너레이터는 반복자처럼 작동하는 객체  
  for, in 연산자에 사용할 수 있음  
  -> preprocessing generator를 만들면 for, in 연산자와 함께 사용 가능 하다는 의미  

- generator는 batch를 무한정 생성해 내므로, break은 반드시 포함 시켜야 함

- 전단 변환(shear transformation)  
  직사각형 형태의 이미지를 대각선 방향으로 밀어  
  평행사변형 형태의 이미지로 변환시키는 변환 방법  
  
- VGG16 model
  캐런 시몬연과 엔드류 지서먼이 2014년에 개발  
  간단하고, ImageNet 데이터셋에 널리 사용되는 컨브넷 구조.  
  사실 오래되었고, 최고 성능에는 못미치고 다른 모델보다는 조금 무거움.  
  이전 실습한 모델과 개념이 거의 유사하기 때문에 사용  
  합성곱 층 16개, 완전 연결 층 3개로 이루어져 있음  

- 동결(freezing)  
  훈련하는 동안 가중치 업데이트가 되지 않도록 막는다는 뜻  
  이렇게 하지 않으면 합성곱 기반 층에 사전 학습된 표현이 훈련하는 동안 학습되버림  

- 히트맵(headMap)  
  히트맵에서 사용되는 전형적인 컬러맵은 파란색(낮은 값), 녹색, 빨간색을  
  사용하는 jet 컬러맵

- 그래디언트 클리핑(gradient clipping)  
  그래디언트 텐서를 L2노름으로 나누어 정규화 하는 것  
  L2 노름으로 나눈 그래디언트의 L2 노름은 1이 됨  
  keras.optimizers 모듈 아래 있는 옵티마이저를 사용할 땐  
  clipnorm, clipvalue 매개변수를 설정하여 자동으로 그래디언트 클리핑을 수행할 수 있음!  
  clipnorm 매개변수 값이 그래디언트의 L2 노름보다 클 경우 각 그래디언트의 L2 노름을 clipnorm 값으로 정규화 함.  
  clipvalue 매개변수를 지정하면 그래디언트 최대 절대값은 clipvalue가 됨  
