## Chapter03 신경망 시작하기
* 세가지 기본 예제에 적용해보기
  * 영화 리뷰를 긍정 또는 부정으로 분류하기(이진 분류)
  * 신문 기사를 토픽으로 분류하기(다중 분류)
  * 부동산 데이터를 바탕으로 주택 가격 예측하기(회귀)

### 3.1 신경망의 구조
#### 층(layer) : 신경망의 구성 단위
* 층은 하나 이상의 텐서를 입력으로 받아 텐서를 출력하는 데이터 모듈
* 어떤 종류의 층은 상태가 없지만, '가중치'라는 상태가 있을 수 있음
* 가중치에는 학습한 지식이 담겨 있음
* 층마다 적절한 텐서 포멧과 데이터 처리 방식이 다름

##### (samples, features) 의 2D 텐서가 저장된 간단한 벡터 데이터
*  fully connected layer 나 dense layer라 불리우는 densely connected layer에 의해 처리되는 경우가 많음
  * fully connected layer : 이전 레이어의 모든 노드가 다음 노드에 전부 연결되어 있는 레이어를 말함
  동의어 -->  dense layer, densely connected layer

##### (samples, timesteps, features) 의 3D 텐서로 저장된 시퀀스 데이터
* LSTM과 같은 순환 층(recurrent layer)에 의해 처리
* 순환층(recurrent layer) : 현재 층에 대한 결과를 기억하고, 이 기억을 새로운 데이터가 들어왔을 때 활용하여 다시 개선하는 층을 말함

##### 4D 텐서로 저장되는 이미지 데이터
* 2D 합성곱 층(convolution layer)에 의해 처리
* 2D 합성곱 층 : 입력을 받아 dot product를 진행하고, 선택에 따라 non-linear 연산 수행

* 케라스는 호환 가능한 층(입력과 출력 형태가 맞는 층) 파이프라인을 구성함으로써 딥러닝 모델을 만듬
* 층 호환성(layer compatibility) : 각 층이 특정 크기의 입력 텐서만 받고 특정 크기의 출력 텐서를 반환하는 사실을 말함
* 케라스는 모델에 추가된 층을 자동으로 상위 층에 맞추어 줌
--> input shape를 지정하지 않아도 됨

#### 모델 : 층의 네트워크
* 딥러닝 모델은 층으로 만든 Directed Acyclic Graph.
비순환 유향 그래프(Directed Acyclic Graph) : 그래프의 edge에 방향이 있고, cycle 하지 못하는 그래프를 말함
* 우리는 다양한 네트워크를 보게 될 것이지만, 자주 등장하는 것들은 다음과 같음
  * 가지(branch)가 2개인 네트워크
  * 출력이 여러 개인 네트워크
  * 인샙션(Inception) 블록
* 네트워크 구조는 가설 공간(hyperthesis space)를 정의함
* 즉 네트워크 구조를 선택함으로써 가능성 있는 공간(가설 공간)을 입력데이터에서 출력데이터로 매핑하는 일련의 특정 텐서 연산으로 제한하게 됨
* 딱 맞는 네트워크 구조를 선택하는 것은 과학보다는 예술에 가까움
 --> 연습을 통해 길러야 함

#### 손실 함수와 옵티마이저 : 학습 과정을 조정하는 열쇠
* 손실 함수
  * 여러 개의 출력을 내는 신경망은 여러 개의 손실 함수를 가질 수 있음(출력 당 하나씩)
  하지만 경사 하강법 과정은 하나의 스칼라 손실 값을 기준으로 함(쉽게 말하면, 정확도 판단 기준은 하나로 계산한다는 의미)
*  문제에 맞는 올바른 목적함수를 선정하는 것은 매우 중요(**)
네트워크가 손실을 최소화하기 위해 편법을 사용할 수 있음
* 분류, 회귀, 시퀀스 예측 같은 일반적인 문제에는 올바른 손실 함수를 선택하는 간단한 지침이 존재
  * 2개 클래스 분류 문제 : 이진 크로스엔트로피
  * 3개 이상의 클래스 분류 문제 : 범주형 크로스엔트로피
  * 회귀 문제 : 평균 제곱 오차
  * 시퀀스 문제 :  connection Temporal Classification

### 3.2 케라스 소개
* 모든 종류의 딥러닝 모델을 간편하게 만들고 훈련시킬 수 있는 파이썬을 위한 딥러닝 프레임워크(요즘은 R도 나옴)
* 케라스 특징
  * 동일한 코드로 CPU와 GPU에서 실행
  * 사용하기 쉬운 API를 가지고 있어 딥러닝 모델의 프로토타입을 빠르게 만들 수 있음
  * CNN, RNN 지원. 이를 자유롭게 조합해서 만들 수 있음
  * 어떤 네트워크 구조도 만들 수 있음(GAN 등 어떤 딥러닝 모델에도 적합)
* 케라스는 딥러닝 모델을 만들기 위한 고수준의 구성 요소를 제공하는 모델 수준의 라이브러리
* 텐서 조작이나 미분같은 저수준의 조작은 다루지 않음
대신 케라스의 backend engine 에서 제공하는 최적화되고 특화된 텐서 라이브러리 제공

* 케라스는 텐서플로를 사용하기 때문에 CPU와 GPU 모두 작동
* CPU에서 실행될 때, Eigen이라고 불리는 저수준 텐서 연산 라이브러리 이용
* GPU에서는 NVIDIA CUDA 심층 신경망 라이브러리라고 불리는 고도로 최적화된 딥러닝 연산 라이브러리 사용

#### 케라스를 사용한 개발 : 빠르게 둘러보기
* 모델을 정의하는 방법은 2가지
  * Sequential 클래스(층을 순서대로 쌓아올린 네트워크)
  * 함수형 API(완전히 임의의 구조를 만들 수 있는 비순환 유향 그래프) --> 해당 예제는 notebook 확인!
* 모델 구조가 정의된 후에는 Sequential 클래스로 정의됐는지, 함수형 API로 정의됐는지 상관 없음
* 컴파일 단계에서 학습과정이 설정됨
모델이 사용할 옵티마이저, 손실 함수, 측정 지표 설정
  * 컴파일 : 소스 코드를 바이너리 코드로 변환하는 과정
 * 마지막으로 입력 데이터의 넘파이 배열을 모델의 fit() 메서드에 전달함으로써 학습 과정이 이루어짐

### 3.3 딥러닝 컴퓨터 세팅
* 최신 NVIDIA GPU에서 딥러닝 코드 실행 권장
* 최신 GPU를 사용하면 2배, 5배, 10배 정도 속도가 빨라짐
* 컴퓨터에 GPU 카드를 설치하고 싶지 않다면, 대안으로 AWS EC2 GPU 인스턴스나 구글 클라우드 플랫폼 고려

### 3.4 영화 리뷰 분류 : 이진 분류 예제
* 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정으로 분류

#### IMDB 데이터셋
* 인터넷 영화 DB로부터 가져온 양극단의 리뷰 5만 개로 이루어진 IMDB 데이터셋 이용
* 데이터셋은 훈련 데이터 25000개와 테스트 데이터 25000 개
* 각각 50%는 부정, 50%는 긍정 리뷰로 구성
* 케라스에 포함되어 있음
* 각 리뷰가 숫자 시퀀스로 변환되어 있음
* 각 숫자는 사전에 있는 고유한 단어를 나타냄

#### 데이터 준비
* 신경망에 리스트를 주입할 수는 없음. 리스트를 텐서로 바꿔야 함. 크게 2가지 방법으로 구성
* 같은 길이가 되도록 리스트에 패딩(Padding)을 추가.
(samples, sequence_length) 크기의 정수 텐서로 변환(2D tensor)
 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용(Embedding 층을 말함)
 -> 가장 긴 리뷰는 2,494개의 단어로 이루어져 있으므로, 훈련 데이터를 변환한 텐서의 크기는 (25000, 2494)

* 리스트를 one-hot encoding 하여 0과 1의 벡터로 변환(one-hot encoding = categorical encoding)
ex) [3,5] 인 영화 리뷰 데이터 1개를 3,5의 위치 값은 1 나머지는 0인 10000차원 벡터로 변환!
10000인 이유는, 초기 setting 값에서 가장 빈도가 많은 단어 10000개만 추출하였기 때문.
부동 소수 벡터 데이터를 다룰 수 있는 Dense 층을 신경망의 첫 번째 층으로 사용
-> 텐서의 크기 (25000, 10000)

* 레이블을 벡터로 만드는 방법 2가지
  * 레이블의 리스트를 정수 텐서로 변환
  * one-hot encoding.
  범주형 인코딩에 널리 사용되기 때문에 범주형 인코딩이라고도 부름.
  레이블의 인코딩은 각 레이블의 인덱스 자리는 1이고, 나머지는 0

#### 신경망 모델 만들기
* 입력 데이터가 벡터고, 	레이블은 스칼라(0또는1)임
앞으로 볼 수 있는 문제 중 가장 간단
--> 이런 문제에 잘 작동하는 네트워크의 종류는 relu 활성화 함수를 사용한 완전 연결 층을 그냥 쌓은 것
* 이 때의 완전 연결 층은, Dense(16, activation = 'relu')
* 16의 의미는 은닉 유닛(hidden unit)의 수 --> 은닉 유닛은 층이 나타내는 표현 공간에서 차원이 됨
* 16개의 은닉 유닛이 있다는 것은 가중치 행렬 W가 (input_dimension, 16) 이라는 뜻
--> 즉 입력 데이터와 W를 dot product를 수행하면 16차원으로 표현된 공간으로 투영
* 은닉 유닛을 늘리면 더욱 복잡한 표현을 학습할 수 있지만, 계산 비용이 커지고 원하지 않는 패턴을 학습할 수 있음
--> overfitting 확률이 커짐

#### 옵티마이저 설정
* 케라스에 rmsprop, binary_crossentropy, accuracy가 포함되어 있음.
* 즉,  위의 문자를 셋팅하면 옵티마이저, 손실함수, 측정 지표를 지정하는 것이 가능.
--> 내가 원하는 손실 함수, 측정 함수를 지정하고 싶을 때?
loss, metrics에 함수 객체를 할당
~~~
model.compile(
	optimizer = optimizers.RMSprop(lr = 0.001),
	loss = losses.binary.crossentropy,
	metrics = [metrics.binary_accuracy]
)
~~~

#### 모델 훈련하기
* model.fit 함수를 이용하여 모델 훈련
~~~
model.fit(
	partial_x_train,
	partial_y_train,
	epoch = 20,
	batch_size = 512,
)
~~~

* <b>중요! model.fit 함수를 재호출 하면 학습된 모델을 다시 학습하므로, 처음부터 다시 학습하려면 model 객체를 다시 만들어야 함</b>
* model.fit 함수는 history 객체 반환.
-> loss, acc, val_loss, val_acc 에 대한 값을 반환받을 수 있음.

#### 최종 결과 도출하기
* evaluate function을 이용하여 정확도 계산
~~~
# 2번째 인덱스 값을 통해 정확도를 추산할 수 있음.
results = model.evaluate(x_test, y_test)
~~~
* predict function을 통하여 실제 확률 값 계산
~~~
y_pred = model.predict(x_test)
~~~
* 이진 분류에서 1인 값을 양성(positive) 샘플, 0인 값을 음성(negative) 샘플이라고 부름
* 예측 하려고 하는 값이 1이 됨! 암을 진단하는 문제에서 악성 종양이 양성(positive)가 됨
* Dense 층을 쌓을 때 두 가지 중요한 구조상의 결정이 필요
  * 층의 개수
  * 층별 유닛(노드) 개수

#### 활성화 함수(activation function)
* relu와 같은 활성화 함수는 비선형성(non-linear)라고 부름
* 이러한 활성화 함수가 없다면 선형적인 연산으로 구성됨
* 선형성의 단점
  * 가설 공간은 제약 조건이 많으며, 선형 층을 깊게 쌓아도 하나의 선형 연산이기 때문에 층을 여러개로 구성하는 장점이 없음
  * 층을 추가해도 가설 공간이 확장되지 않음
* 따라서 가설 공간을 풍부하게 만들어 층을 깊게 만드는 장점을 살리기 위하여 비선형성 또는 활성화 함수를 추가해야 함
* 가장 많이 쓰는 함수가 relu, 음수 처리 방식이 달라지는 prelu, elu 등도 있음

#### 손실함수 설정
* 이진 분류에서는 주로 cross-entropy를 사용

#### 훈련 검증(cross-validation)
* 처음 본 데이터에 대해 모델의 정확도를 측정하기 위해서는 원본 데이터에서 10000개의 검증 세트를 만들어야 함

### 용어 정리
* epoch : 인공 신경망에서 전체 데이터셋에 대해 forward pass/backward pass 과정을 거치는 것을 말함
1 epoch 란, 전체 데이터 한번에 대해서 한번 학습을 완료한 상태
* batch size : 전체 데이터 셋에 대해서 모델을 한 번 학습할 때 사용하고자 하는 batch size를 말함.
ex) batch size = 20 이면, 전체 데이터 셋을 20으로 나눠 해당 데이터 만큼 학습을 진행 한다는 의미
* 은닉 유닛(hidden unit)
hidden layer 에서 하나의 노드를 의미
* 크로스엔트로피(crossentropy)
확률 분포간의 차이를 측정 하는 계산법(?). 이진 분류에 사용하는 방법

### 3.5 뉴스 기사 분류 : 다중 분류
* 로이터(Reuter) 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어보자

#### 로이터 데이터셋
* 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있음
* 어떤 토픽은 다른 것에 비해 데이터가 많음

#### 모델 구성
* 이 토픽 분류 문제는 앞선 영화 분류 문제와 비슷
* but!! 새로운 제약 사항이 추가 -> 출력 클래스의 개수가 2개에서 46개로 증가(차원 크기가 훨씬 커짐)
* 어떻게 해야할까?
영화 분류에서 사용했던 Dense 층을 쌓으면, 각 층은 이전 층의 출력에서 제공한 정보만 사용 가능
-> 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그다음 층에서 이를 복원할 방법이 없음!
즉, 각 층이 모두 bottleneck이 될 수 있음
* 영화 분류에서는 16개의 은닉 unit을 setting 했지만, 46개의 클래스를 구분하기에는 너무 제약이 큼.
* 따라서 규모를 더 키워야 할 필요성존재
16 -> 64로 증가!

#### 레이블을 벡터로 변경
* 영화 리뷰와는 다르게 레이블을 벡터로 변경해주어야 함
* y 레이블이 46개 존재하므로, 이를 0,1 one-hot vector로 변경해 주어야 함

#### 레이블과 손실을 다루는 다른 방법
* 레이블을 인코딩하는 다른 방법은 정수 텐서로 변환하는 것. -> ex) [ 3, 10, 1, ..., 3, 3, 24]
* 일반적으로 사용하는 손실 함수 : categorical_crossentropy는 레이블이 범주형 인코딩(one-hot encoding)되어 있을 것이라고 기대!
* 정수 레이블을 사용할 때는 sparse_categorical_crossentropy를 사용해야 함
-> 이 손실 함수는 인터페이스만 다를 뿐이고, 수학적으로는 categorical_crossentropy와 동일

<b>충분히 큰 중간층을 두어야 하는 이유</b>
* 마지막 출력이 46차원이기 때문에 중간층(hidden unit)이 46개보다 적어서는 안됨
why? 이런 손실의 대부분은 많은 정보(46개의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문!

### 3.6 주택 가격 예측 : 회귀 문제
#### 보스턴 주택 가격 데이터셋
* 1970년 중반 보스턴 외곽 지역의 범죄율, 지방세율 등의 데이터가 주어졌을 때 주택 가격의 중간 값을 예측.
* 데이터 포인트 : 506개
* train : 404, test : 102
* 입력 데이터의 feature는 scale이 다름

#### 스케일 조정
* 상이한 스케일을 신경망에 주입하게 되면, 문제가 됨
why? 특성의 스케일이 다르면 전역 최소 점을 찾아가는 경사 하강법의
경로가 스케일 큰 특성에 영향을 많이 받음.
--> 표준화 수행(중앙 : 0, 표준편차 1)

* 표준화 수행시 정말 조심해야 할 점(중요 ** )
테스트 데이터를 표준화 할 때, 절대로 테스트 데이터 자체를 표준화 시켜서는 안됨.
테스트 데이터를 훈련 데이터의 mean, std를 이용해서 표준화 시켜주어야 함!

* 표준화 뿐만 아니라, 모든 데이터 변환이 마찬가지.

#### 모델 구성
* 샘플 개수가 적기 때문에 64개의 유닛을 가진 2개의 은닉 층으로 작은 네트워크 구성.
-> overfitting을 방지하기 위한 방법
* 회귀는 마지막 층에 활성화 함수가 없음
* 활성화 함수의 역할은 값을 제한해주는 역할이 있는데, 회귀에서는 값 그대로를 예측해야 하므로, 활성화 함수가 필요 없음
* 회귀 모형이므로, 손실 함수를 mean square error 를 사용!
* 지표는 mae(mean absolute error : 예측 값과 실제 값의 절대값 차)를 사용
ex) MAE가 0.5면, 500달러 정도 차이남을 의미!(더 직관적으로 이해하기 위해서 MAE를 보자)

#### K-Fold를 이용한 훈련 검증
* 데이터의 수가 적고, 검증 세트를 새로 편성 할 때마다 각각의 값 들이 차이가 많이나므로, K-Fold 검증 수행
* 이 책에서는 일반적으로 K가 4또는 5라고 얘기함
* 최종 점수는 해당 검증 점수의 평균
* 일반적으로 K값을 기준으로, for loop를 통해 데이터를 split -> model.fit -> model.evaluate -> 정확도 저장.
* 이를 마지막으로 all_scores에 저장해 평균 값을 계산하는 형식! 어렵지 않음.

#### 지수이동평균(exponential moving average)
* 일반적으로 시계열 데이터를 부드럽게 만들기 위하여 사용
* 현재 계산한 [ 이동평균 = 이전 계산된 이동평균 * factor + (1 - factor) ] 식을 이용해서 계산!
