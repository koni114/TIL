{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수형 API에서는 직접텐서들의 입출력을 다룸.\n",
    "# 함수처럼 층을 사용하여 텐서를 입력받고 출력함\n",
    "\n",
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, ))\n",
    "dense = layers.Dense(32, activation = 'relu')\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 22:28:20.204729 17332 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0726 22:28:20.295485 17332 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0726 22:28:20.312442 17332 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 간단한 예제를 통해 Sequential 모델과 함수형 API로 만든 모델 비교\n",
    "from keras.models import Sequential, Model\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "\n",
    "# Sequential\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation = 'relu', input_shape = (64, )))\n",
    "seq_model.add(layers.Dense(32, activation = 'relu'))\n",
    "seq_model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# 함수형 API\n",
    "input_tensor = Input(shape = (64, ))\n",
    "x = layers.Dense(32, activation = 'relu')(input_tensor)\n",
    "x = layers.Dense(32, activation = 'relu')(x)\n",
    "output_tensor = layers.Dense(10, activation = 'softmax')(x)\n",
    "model = Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델이 같음을 확인할 수 있음.\n",
    "model.summary()\n",
    "seq_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_8:0\", shape=(?, 64), dtype=float32) at layer \"input_8\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-043b7a4edaa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 함수형API에서는 input_tensor 와 output_tensor의 모델 변환이 맞아야 함.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0munRelated_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munRelated_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Graph disconnected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[1;32m--> 231\u001b[1;33m             self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1441\u001b[0m                                          \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                          \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1444\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_8:0\", shape=(?, 64), dtype=float32) at layer \"input_8\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# 함수형API에서는 input_tensor 와 output_tensor의 모델 변환이 맞아야 함.\n",
    "unRelated_tensor = Input(shape = (32, ))\n",
    "Model(unRelated_tensor, output_tensor) # Graph disconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 객체를 사용한 컴파일, 훈련, 평가 API는 Sequential 클래스 같습니다.\n",
    "# optimizer     : rmsprop\n",
    "# loss function : categorical_crossentropy\n",
    "# 해당 compile 값을 기본으로, 위에서 만든 API 함수에 넣어보고, 모델 생성 후 평가해보기\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 814us/step - loss: 11.5014\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 11.4966\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 11.4949\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4939\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 11.4928\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 11.4915\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.4907\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 11.4898\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.4885\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 11.4877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b83811400>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 293us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 01:00:57.533487 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 01:00:57.626231 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 01:00:57.629223 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 01:00:59.111261 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 01:00:59.209995 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2개의 입력을 가진 질문-응답 모델의 함수형 API 구현하기.\n",
    "# text_size = 1000\n",
    "# question_size = 10000\n",
    "# answer_vocabulary_size = 500\n",
    "\n",
    "# 다중 입력 모델 만들기\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "\n",
    "text_vocabulary_size = 1000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# input_text 생성\n",
    "text_input = Input(shape = (None,), dtype = 'int32', name = 'text') # 이름은 text 라고 하는 Input_model 생성\n",
    "embedded_text = layers.Embedding(\n",
    "    text_vocabulary_size, 64)(text_input) # 입력을 크기가 64인 벡터의 크기로 임베딩\n",
    "encoded_text  = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "\n",
    "question_input = Input(shape = (None,), dtype = 'int32', name = 'question') # 이름은 text 라고 하는 Input_model 생성\n",
    "embedded_question = layers.Embedding(\n",
    "    question_vocabulary_size, 32)(question_input) # 입력을 크기가 64인 벡터의 크기로 임베딩\n",
    "encoded_question  = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question] ,axis = -1)  # 인코딩된 질문과 텍스트를 연결. axis -> -1 : 입력 값의 마지막 축\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation = 'softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss       = 'categorical_crossentropy',\n",
    "             metrics    = ['acc']\n",
    "             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 01:05:57.492202 14276 deprecation.py:323] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0727 01:06:01.554370 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 6.2146 - acc: 0.0030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.2022 - acc: 0.0300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.1869 - acc: 0.0270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.1202 - acc: 0.0070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.0382 - acc: 0.0060\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.9836 - acc: 0.0060\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.9243 - acc: 0.0040\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.8697 - acc: 0.0130\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.8170 - acc: 0.0070\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.7655 - acc: 0.0120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e16b8a7f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 입력 모델에 데이터 주입하기\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length  = 100\n",
    "\n",
    "# text, question input 에 필요한 데이터 생성\n",
    "# 샘플 수 text: 1000개, length : 100, 1 ~ 1000.\n",
    "#         question : 1000개, length : 1 ~ 10000.\n",
    "text     = np.random.randint(1, text_vocabulary_size, size = (num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size = (num_samples, max_length)) \n",
    "\n",
    "# y_train data 만들기 (answer)\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size = num_samples)\n",
    "answers = to_categorical(answers)\n",
    "# model.fit\n",
    "# epochs, batch_sizes\n",
    "model.fit([text, question], answers, epochs = 10, batch_size = 128)                      # 1번째 방법. list 형식으로 input Data 전달\n",
    "# model.fit({'text':text, 'question': question }, answers, epochs = 10, batch_size = 128)  # 2번째 방법. dict 형식으로 전달.\n",
    "\n",
    "# model.evaluate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 01:31:53.185845 14276 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3개의 출력을 가진 함수형 API 구현하기\n",
    "# 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측하는 모델 생성\n",
    "\n",
    "# Model format\n",
    "# Embedding 층\n",
    "# Conv1D -> 5층~\n",
    "# MaxPooling1D -> 2층~ \n",
    "# GlobalMaxPooing1D -> 1층~ \n",
    "# Dense -> 1층~\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    " \n",
    "vocabulary_size = 50000 # input data 단어 size\n",
    "num_income_groups = 10  # 소득 수준 1 ~ 10 \n",
    "\n",
    "posts_input    = Input(shape = (None,), dtype = 'int32', name = 'posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation = 'relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 출력 층에 이름을 부여하고, 알맞는 출력 형태를 지정하자.\n",
    "age_prediction    = layers.Dense(1, name = 'age')(x)    # 나이\n",
    "income_prediction = layers.Dense(num_income_groups, activation = 'softmax', name = 'income')(x)\n",
    "gender_prediction = layers.Dense(1, activation = 'sigmoid', name = 'gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력이 3개 이므로, 모델 compile 시, loss function을 3개 지정 해주야 함.\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss      = ['mse', 'categorical_crossentropy', 'binary_crossentropy']\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = {\n",
    "        'age'    : 'mse',\n",
    "        'income' : 'categorical_crossentropy',\n",
    "        'gender' : 'binary_crossentropy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 시, 가중치를 지정할 수 있음.\n",
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = {\n",
    "        'age'    : 'mse',\n",
    "        'income' : 'categorical_crossentropy',\n",
    "        'gender' : 'binary_crossentropy'\n",
    "    },\n",
    "    \n",
    "    loss_weights = {\n",
    "        'age' : 0.25,\n",
    "        'income' : 1.,\n",
    "        'gender' : 10.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_2: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-187da87be180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbranch_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbranch_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_2: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "# 인셉션 V3(Inception V3) 모델 함수형 API로 만들어보기.\n",
    "# x는 4D Data라고 가정.\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "branch_1 = layers.Conv2D(128, 1, activation = 'relu', strides = 2)(x)\n",
    "\n",
    "branch_2 = layers.Conv2D(128, 1, activation = 'relu')(x)\n",
    "branch_2 = layers.Conv2D(128, 3, activation = 'relu', strides = 2)(branch_2)\n",
    "\n",
    "branch_3 = layers.Average2D(128, 3, activation = 'relu', strides = 2)(x)\n",
    "branch_3 = layers.Conv2D(128 , 3, activation = 'relu')(branch_3)\n",
    "\n",
    "branch_4 = layers.Conv2D(128, 1, activation = 'relu')(x)\n",
    "branch_4 = layers.Conv2D(128 , 3, activation = 'relu')(branch_4)\n",
    "branch_4 = layers.Average2D(128, 3, activation = 'relu', strides = 2)(branch_4)\n",
    "\n",
    "output = layers.concatenate([branch_1, branch_2, branch_3, branch_4], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 잔차 연결(Residual Connection)\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(x)\n",
    "..\n",
    "y = layers.add([y, x])\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides = 2, padding = 'same')(x)\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 17:12:16.614800 18252 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 17:12:16.653696 18252 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 17:12:16.664670 18252 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'left_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aac36e43f0b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mleft_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'left_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 층 가중치 공유 예제\n",
    "# 두 문장이 유사한지, 유사하지 않는지를 확인하는 예제.\n",
    "# 왜 가중치 공유를 해야하는가?\n",
    "# -> A와 B의 유사도는 B와 A의 유사도와 같음. 즉 두 개의 모델을 각각 만들 필요가 없고, A,B가 들어왔을 때 같은지, 같지 않은지만\n",
    "#    확인하면 됨.\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "left_input  = Input(shape = (None, 128))  # 크기가 128인 벡터의 가변 길이 시퀀스\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input  = Input(shape = (None, 128)) # 크기가 128인 벡터의 가변 길이 시퀀스\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# concatenate function으로 노드 병합\n",
    "merged = layers.concatenate([left_input, right_input], axis = -1) # 왜 axis = -1 인가?\n",
    "predictions = layers.Dense(1, activation = 'sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 층과 모델.\n",
    "# 층 내에 모델 자체가 들어갈 수 있음.\n",
    "# y = model(x) .            #\n",
    "# y1, y2 = model([x1, x2])  # \n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras import applications # Xception 모델을 호출하기 위한 import\n",
    "\n",
    "xception_base = applications.Xception(weights = None, include_top = False)\n",
    "\n",
    "left_input  = Input(shape = (250, 250, 3)) # 250, 250, 3 RGB\n",
    "right_input = Input(shape = (250, 250, 3))\n",
    "\n",
    "# 같은 비전 모델이 두번 사용.\n",
    "left_features  = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 17:48:40.619823 18252 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 17:48:40.660715 18252 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0727 17:48:40.671685 18252 deprecation.py:323] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d3450be0d23b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m               metrics = ['acc'])\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m model.fit(x, y,\n\u001b[0m\u001b[0;32m     26\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# 콜백 함수 예시\n",
    "# 1. EarlyStopping 과 ModelCheckPoint param 설정\n",
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "    \n",
    "    keras.callbacks.EarlyStopping( # 성능 향상이 멈추면 훈련을 중지하게끔 하는 함수\n",
    "        monitor  = 'val_acc', # 모델의 검증 정확도 모니터링\n",
    "        patience = 1,\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'my_model.h5', # 모델 파일의 경로\n",
    "        monitor  = 'val_loss',\n",
    "        save_best_only = True, # monitor, save_best_only parameter 값을 통해 \n",
    "                               # 해당 val_loss 값이 좋아지지 않으면 모델을 저장하지 않겠다는 의미\n",
    "    )\n",
    "]\n",
    "\n",
    "# 2. model.compile 생성\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(x, y,\n",
    "          epochs = 10,\n",
    "          batch_size = 32,\n",
    "          callbacks  = callbacks_list,       # --> model.fit 함수에서 callbacks param 값에 callback 함수 전달\n",
    "          validation_data = (x_val, y_val))  # --> validation_data에 값이 없으면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f2ee6191cdad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m ]\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m model.fit(x, y,\n\u001b[0m\u001b[0;32m     12\u001b[0m           \u001b[0mepoch\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# ReduceLROnPlateau\n",
    "# -> 학습 손실이 개선되지 않을 때, 자동으로 학습률을 조정.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor  = 'val_loss',\n",
    "        factor   = 0.1,       # --> 콜백이 호출될 때 학습률을 10배로 줄임. : 학습률 x 0.1 \n",
    "        patience = 10,        # --> 검증 손실이 10 에포크 동안 좋아지지 않으면 콜백이 호출.\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x, y,\n",
    "          epoch      = 10,\n",
    "          batch_size = 32,\n",
    "          callbacks  = callbacks_list, \n",
    "          validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자신만의 콜백을 만들기.\n",
    "# 매 에포크의 끝에서 검증 세트의 첫 번째 샘플로 모델에 있는 \n",
    "# 모든 층의 활성화 출력을 계산하여 디스크에 저장하는 자작 콜백의 예.\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model): #  호출하는 모델에 대한 정보를 전달하기 위해 훈련하기 전에 호출 됨.\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers ]               # 해당 층의 활성화 출력을 array로 만듬.\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs) # 각 층의 활성화 출력을 반환하는 Model 객체. \n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "            \n",
    "        validation_sample = self.validation_data[0][0:1]                       # 검증데이터의 첫 번째 샘플을 가져옵니다.\n",
    "        actiavtions       = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_') + str(epoch) + '.npz', 'wb')         # 배열을 디스크에 저장. \n",
    "        np.savez(f, activations)           \n",
    "        f.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMDB 감성 분석 문제 \n",
    "# !D 컨브넷 훈련\n",
    "# IMDB 어휘 사전에서 빈도가 높은 2000개의 단어 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000 # 특성으로 사용할 단어의 수\n",
    "max_len      = 500  # 사용할 텍스트의 길이(가장 빈번한 max_feature개의 단어만 사용)\n",
    "\n",
    "# train : 25000\n",
    "# test  : 25000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features) # 빈도가 높은 2000개의 단어만 사용하여 만든 input data.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_len) \n",
    "x_test  = sequence.pad_sequences(x_test, maxlen = max_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 20:28:18.966359  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 20:28:19.044150  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 20:28:19.054124  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 20:28:19.220679  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0727 20:28:19.372272  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 20:28:19.480979  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0727 20:28:19.503919  5724 deprecation.py:323] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length = max_len, name = 'embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation = 'relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation = 'relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 콜백과 함께 모델 훈련\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir         = 'my_log_dir',       # 로그 파일이 기록될 위치\n",
    "    histogram_freq  = 1,                  # 1 에포크마다 활성화 출력의 히스토그램을 기록\n",
    "    embeddings_freq = 1,                  # 1 에포크마다 임베딩 데이터 기록.\n",
    "    embeddings_data = x_train[:100]       # 책에는 없지만 추가 해야함.! \n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 20:41:24.889057  5724 deprecation_wrapper.py:119] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:887: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 53s 3ms/step - loss: 0.2943 - acc: 0.7129 - val_loss: 0.6450 - val_acc: 0.6440\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.2491 - acc: 0.6616 - val_loss: 0.6821 - val_acc: 0.5874\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.2298 - acc: 0.5833 - val_loss: 0.7362 - val_acc: 0.5084\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.1799 - acc: 0.5508 - val_loss: 0.9541 - val_acc: 0.4566\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.1637 - acc: 0.4848 - val_loss: 0.9808 - val_acc: 0.4212\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.1402 - acc: 0.4263 - val_loss: 1.0727 - val_acc: 0.3696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0727 20:49:19.584925  5724 deprecation.py:323] From C:\\Users\\koni1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 48s 2ms/step - loss: 0.1225 - acc: 0.3657 - val_loss: 0.9941 - val_acc: 0.3494\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 50s 3ms/step - loss: 0.1141 - acc: 0.3145 - val_loss: 1.2332 - val_acc: 0.2938\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 47s 2ms/step - loss: 0.1125 - acc: 0.2644 - val_loss: 1.1109 - val_acc: 0.2952\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1101 - acc: 0.2386 - val_loss: 1.1412 - val_acc: 0.2828\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.1219 - acc: 0.2013 - val_loss: 1.1940 - val_acc: 0.2602\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.1056 - acc: 0.1813 - val_loss: 1.2563 - val_acc: 0.2430\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 47s 2ms/step - loss: 0.1063 - acc: 0.1663 - val_loss: 1.2766 - val_acc: 0.2394\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.1089 - acc: 0.1498 - val_loss: 2.1729 - val_acc: 0.1868\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 47s 2ms/step - loss: 0.1116 - acc: 0.1396 - val_loss: 1.2671 - val_acc: 0.2188\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.1029 - acc: 0.1211 - val_loss: 1.2721 - val_acc: 0.2062\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 50s 3ms/step - loss: 0.1018 - acc: 0.1149 - val_loss: 1.2351 - val_acc: 0.2124\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.0990 - acc: 0.1078 - val_loss: 1.3067 - val_acc: 0.2028\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.1063 - acc: 0.0969 - val_loss: 1.3576 - val_acc: 0.1880\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.1009 - acc: 0.0827 - val_loss: 1.3151 - val_acc: 0.1882\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 128,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b9f73cf47fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# keras.utils.plot_model 유틸리티 사용하여 그래프 그려보기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# show_shape : 모델 층의 크기 정보 추가.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         raise ImportError(\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "# keras.utils.plot_model 유틸리티 사용하여 그래프 그려보기\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes = True, to_file = 'model.png') # show_shape : 모델 층의 크기 정보 추가.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작은 데이터셋에서 이미지 분류 문제를 위한 가벼운 깊이 분리 컨브넷을 만드는 예제.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
