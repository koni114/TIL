Chapter08 - 생성 모델을 위한 딥러닝.
인공 지능은 창작 활동으로 범위를 넓히고 있음.
여러 분야에서 특히 예술 분야에서는 AI가 사람의 능력을 증가시키는 도구로 사용될 것임.
즉 인공적인 지능이 아니라 확장된 지능(augmented intelligence)임.

이 장에서는 예술 창작이 딥러닝이 어떻게 쓰일 수 있는지 다양한 각도에서 살펴보자.
- 시퀀스 데이터 생성(글을 쓰거나 작곡을 할 수 있음)
- 딥드림(이미지 창작)
- 변이형 오토인코더
- 적대적 생성 네트워크(Generative adverserial network)

## --------------------------------------------- ##

8.4 변이형 오토인코더를 사용한 이미지 생성.

이미지의 잠재 공간에서 샘플링해 완전히 새로운 이미지나 기존 이미지를 변형하는 방식이
현재 가장 인기있고 성공적으로 창조적 AI 애플리케이션을 만들 수 있는 방법.
그 중 두 기법인 VAE, GAN를 다뤄보자.

실제 이 두 기법은 이미지에만 해당되는 것이 아님.
두 기법은 소리, 음악, 텍스트의 잠재 공간을 만들 수 있음.

8.4.1 이미지의 잠재 공간에서 샘플링하기.
이미지 생성의 핵심 아이디어는 각 포인트가 실제와 같은 이미지로 매핑될 수 있는
저차원 잠재공간의 표현을 만드는 것.

잠재 공간의 한 포인트를 입력으로 받아 이미지를 출력하는 모듈을 생성자(generator) 또는
디코더(decoder)라고 부름.
잠재 공간 -> 이미지로 변환하는 모듈(generator, decoder)

GAN과 VAE는 이미지의 잠재 공간 표현을 학습하는 2개의 전략이고, 나름대로의 특징을 가짐.
VAE : 구조적인 잠재 공간을 학습하는 데 뛰어남.
        이 공간에서 특정 방향은 데이터에서 의미 있는 방향을 인코딩함.
GAN : 매우 실제 같은 이미지를 만듬.
        여기서 만든 잠재 공간은 구조적이거나 연속성이 없을 수 있음.

8.4.2 이미지 변형을 위한 개념 벡터(concept vector)
잠재 공간이나 임베딩 공간이 주어지면, 이 공간의 어떤 방향은 원본 데이터의 흥미로운 변화를 인코딩한 축일 수 있음.
ex) 얼굴 이미지에 대한 잠재 공간에 웃음 벡터가 있을 수 있음.
    잠재 공간의 z 포인트가 어떤 얼굴의 임베딩된 표현이라면, 잠재 공간의  z + s 포인트는 같은 얼굴이 웃고 있는 표현을 임베딩한 것.
    -> 이런 벡터를 찾아내면 이미지를 잠재 공간에 투영해서 의미 있는 방향으로 이 표현을 이동한 후 이미지 공간으로 디코딩하여 복원하면 
        변형된 이미지를 얻을 수 있음.

이미지 공간에서 독립적으로 변화가 일어나는 모든 차원이 개념 벡터.

8.4.2 변이형 오토인코더
변이형 오토인코더는 생성 모델의 한 종류로 개념 벡터를 사용하여 이미지를 변형하는데 아주 적절 함.
오토인코더는 입력을 저창원 잠재 공간으로 인코딩 한 후, 다시 디코딩하여 복원 하는 네트워크.
변이형 오토인코더는 딥러닝과 베이즈 추론(Bayesian inference)의 아이디어를 혼합한 오토인코더의 최신 버전.

고전적인 오토인코더는 인코더 모듈을 사용하여 잠재 벡터 공간으로 매핑.
다음, 디코더 모듈을 사용하여 원본 이미지와 동일한 차원으로 복원하여 출력.

오토인코더는 동일한 이미지를 타깃 데이터로 사용하여 훈련(개념적으로 중요**)
즉, 원본 입력을 재구성하는 방법을 학습.
코딩(coding, encoding 결과)에 여러 제약을 가하면 오토인코더가 변화된 잠재 공간의 표현을 학습함
일반적으로 더 저차원이되게 하거나, sparse 하게되도록 많은 제약을 가함.
이런 경우, 인코더는 입력 데이터의 정보를 적은 수의 비트에 압축하기 위해 노력 함.

원본 입력 -> 인코더 -> 압축된 표현(잠재 공간) -> 디코더 -> 재구성된 입력

현실적으로 전통적인 오토인코더는 특별히 유용하거나 구조화가 잘된 잠재 공간을 만들지 못함.
압축도 매우 뛰어나지 않음.
VAE는 이러한 오토인코더에 약간의 통계 기법을 추가하여 학습하도록 만듬.

입력이미지를 고정된 코딩으로 압축하는 대신, VAE는 이미지를 어떤 통계 분포의 파라미터로 변환.
이는 입력 이미지가 통계적 과정을 통해 생성되었다고 가정하여 인코딩과 디코딩하는 동안 무작위성이 필요하다는 것을 의미함.

VAE는 평균*과 분산 파라미터*를 사용하여 이 분포에서 무작위로 하나의 샘플을 추출.
이 샘플을 디코딩하여 원본 입력으로 복원.

이런 무작위한 과정은 안정성을 향상하고 잠재 공간 어디서든 의미 있는 표현을 인코딩하도록 만들어줌.
즉, 잠재 공간에서 샘플링한 모든 포인트는 유효한 출력으로 디코딩됨.

VAE 기술적인 작동 순서.
1. 입력 샘플 input_img를 잠재 공간 두 파라미터 z_mean, z_log_var로 변환.
2. 입력 이미지가 생성되었다고 가정한 잠재 공간의 정규 분포에서 포인트 z를 
   z= z_mean + exp(0.5 * z_log_var) * epsilon 처럼 무작위로 샘플링.

** z_log_var는 분산에 로그를 적용한 것.
분산은    exp(z_log_var),
표준편차 exp(0.5 * z_log_var)

인코더 네트워크는 음수를 출력할 수도 있기 때문에 표준편차가 아닌 분산의 로그 값을 출력하도록 학습.

3. 디코더 모듈은 잠재 공간의 이 포인트를 원본 입력 이미지로 매핑하여 복원.
   
epsilon이 무작위로 만들어지기 때문에 input_img를 인코딩한 잠재 공간의 위치(z_mean)에 가까운 포인트는 input_img와
비슷한 이미지로 디코딩될 것.
-> 잠재 공간을 연속적이고 의미있는 공간으로 만들어 줌.
    잠재 공간에서 가까운 2개의 포인트는 아주 비슷한 이미지로 디코딩될 것.

VAE 파라미터는 2개의 손실 함수로 훈련.
- 재구성 손실(reconstruction loss) :  디코딩된 샘플이 원본 입력과 동일하도록 만듬
			          크로스엔트로피 손실을 사용
- 규제 손실(regularization loss)     :  잠재 공간을 잘 형성하고 훈련 데이터에 과대적합을 줄임.
			          쿨백 라이블러 발산(Kullback - Leibler divergence)을 사용.
개략적인 VAE 구현 코드
z_mean,  z_log_var = encoder(input_img)
z 		= z_mean + exp(0.5 * z_log_var) * epsilon
reconstructed_img = decoder(z)
model		= Model(input_img, reconstructed_img)

이 모델을 recontruction loss, regularization loss를 사용하여 훈련.

층에서 직접 손실 함수를 정의해야 하고,
이 때문에 모델 훈련을 수행할때, loss function과 y_train을 지정하지 않아도 됨.

## --------------------------------------------- ##

8.5 적대적 생성 신경망(generative adverserial network)
GAN은 생성된 이미지가 실제 이미지와 통계적으로 거의 구분이 되지 않도록 강제하여
아주 실제 같은 합성 이미지를 생성함.

** GAN을 직관적으로 이해해보자.
가짜 피카소그림을 만드는 위조범이 있다고 생각해보자.
처음에 위조범은 형편없이 그림을 위조함. 진짜 피카소 그림과 위조품을 섞어서 그림 판매상에게 보여줌.
판매상은 각 그림이 진짜인지, 평가하고 어떤 것이 피카소 그림 같은지 위조범에게 피드백을 줌.
위조범은 자신의 화실로 들어가 새로운 위조품을 준비함.
점점 시간이 지나갈수록 능숙해짐.
판매상도 마찬가지로 그림을 판별하는데 더욱 능숙해짐.
결국, 서로 많이 배워 훌륭한 피카소 위조품을 만들게 됨.

결과적으로 GAN의 네트워크 크게 2개로 구분됨
생성자 네트워크(generator Network)      : 랜덤 벡터를 입력으로 받아 합성된 이미지로 디코딩
판별자 네트워크(discriminator Network)  : 이미지를 입력으로 받아 훈련 세트에서 온 이미지인지, 생성자 네트워크가 만든 이미지인지 판별함.

생성자는 점점 실제와 같은 이미지를 생성해냄.
판별자는 생성된 이미지가 실제인지 판별하는 기준을 설정하면서 생성자의 능력 향상에 적응해 감.

VAE와는 달리 GAN의 잠재 공간은 의미 있는 구조를 보장하지 않음.
특히 이 공간은 연속적이지 않다.

* GAN은 최적화의 최소값이 고정되지 않음.
보통 경사 하강법은 고정된 어떠한 손실 공간에서 최소점을 찾는 것인데, GAN은 이동할 때마다 공간이 변함.
즉, 최적화 과정이 최솟값을 찾는 것이 아니라, 두 힘간의 평형점을 찾는 다이나믹 시스템.
따라서 GAN은 훈련하기 어렵기로 유명함.

** 8.5.1 GAN 구현 방법.
구체적인 구현은 심층 합성곱 GAN(DCGAN)임.
-> 생성자와 판별자가 심층 컨브넷.
특히 생성자의 업샘플링을 위해 Conv2DTranspose 층을 사용.

CIFAR10 데이터셋의 이미지로 GAN을 훈련.
이 데이터셋은 32 X 32 크기의 RGB 이미지 5만개, 10개 CLASS
문제를 간단하게 만들기 위해 flog 이미지만 사용해보자.

GAN 구조
1. generator는 (latent_dim,) 크기의 벡터를 (32, 32, 3) 크기의 이미지로 매핑

2. discriminator는 (32, 32, 3) 크기의 이미지가 진짜일 확률을 추정. 이진 값으로 매핑.

3. 생성자와 판별자를 연결하는 gan 네트워크를 만듬. 
   gan(x) = discriminator(generator(x)) 
   잠재공간의 벡터를 판별자의 평가로 매핑.
   즉 판별자는 생성자가 잠재공간의 벡터를 디코딩한 것이 얼마나 현실적인지를 평가

4. 진짜 / 가짜 label과 함께 진짜 이미지와 가짜 이미지 샘플을 사용하여 판별자를 훈련함.
   일반적인 이미지 분류 모델을 훈련하는 것과 동일.

5. 생성자를 훈련하려면, GAN 모델 손실에 대한 생성자 가중치의 그래디언트를 사용.
   이 말은 매 단계마다 생성자에 의해 디코딩된 이미지를 판별자가 "진짜"로 분류하도록 만드는 방향으로 생성자의 가중치를 이동한다는 의미
   -> 판별자를 속이도록 학습

8.5.2 훈련 방법.
GAN을 훈련하고 튜닝하는 것은 어렵기로 유명.
이는 과학보다는 연금술에 가까움.
이러한 지침은 과학적 증명 보다는 경험에 가까움

- 생성자의 마지막 활성화로 다른 종류의 모델에서 멀리 사용하는 sigmoid 대신 tanh 함수를 사용
- 균등 분포가 아니고 정규 분포를 사용하여 잠재 공간에서 포인트를 샘플링
- GAN 훈련은 동적 평형을 만들기 때문에 여러 방식으로 갇힐 가능성이 높음.
  무작위성을 높이면 이를 방지하는 데 도움.
  이를 위해 2가지 기법 이용 -> 판별자에 dropout을 사용하거나 판별자를 위해 레이블에 랜덤 노이즈를 사용.

- 희소한(0이 많은) 그래디언트는 GAN 훈련을 방해할 수 있음.
  딥러닝에서 희소는 바람직한 현상이지만 GAN에서는 그렇지 않음
  그래디언트를 회소하게 만들 수 있는 것은 1. MaxPooling, 2. Relu activation.
-> 최대 풀링 대신 스트라이드 합성곱을 사용.
    ReLu 대신 leakyReLu 사용. 음수가 포함되기 때문에 sparse한 성질이 조금 완화됨.

-  생성자에게 픽셀 공간을 균일하게 다루지 못하여 생성된 이미지에서 체스판 모양이 종종 나타남.
   이를 해결하기 위해 생성자와 판별자에서 스트라이드 Conv2DTranspose 나 Conv2D를 사용할 때 스트라이드 크기로 나누어질 수 있는
   커널 크기 사용.

GAN에서 발생하는 많은 문제점 중 하나는, 생성자가 노이즈 같은 이미지를 생성하는 데서 멈추는 것.
-> 판별자, 생성자 양쪽에 모두 드롭아웃을 사용하는 것이 해결 방법 일 수 있음.

훈련할 때, 생성자가 판별자를 속이는 능력이 커지도록 학습.
이 모델은 잠재 공간의 포인트를 "진짜" 또는 "가짜" 의 분류 결정으로 변환.
훈련에 사용되는 타겟 레이블은 항상 '진짜 이미지'

gan을 훈련한다는 것은, 
discriminator가 가짜 이미지를 보았을 때 진짜라고 예측하도록 만들기 위해 generator 의 가중치를 업데이트 하는 것.
훈련하는 동안 판별자를 동결하는 것이 중요.
GAN을 훈련할 때 가중치가 업데이트 되지 않음.
판별자의 가중치가 훈련하는 동안 업데이트 되면 판별자는 항상 "진짜"를 예측하도록 훈련됨. 
-> 이것은 우리가 원하는 바는 아님.

8.5.6 DOGAN 훈련 방법.
훈련 반복 내용을 요약 해보자 .

1. 잠재 공간에서 무작위로 포인트를 뽑음(random Noise)
2. 이 랜덤 노이즈를 사용하여 generator에서 이미지 생성
3. 생성된 이미지와 진짜 이미지를 섞음
4. 진짜와 가짜가 섞인 이미지와 이에 대응하는 타깃을 사용하여 discriminator를 훈련.
   target은 "진짜" 또는 "가짜" 임
5. 잠재 공간에서 무작위로 새로운 포인트를 뽑음.
6. 이 랜덤 벡터를 이용하여 gan을 훈련.
   모든 타겟은 "진짜"로 설정. 판별자가 생성된 이미지를 모두 "진짜 이미지"로 예측하도록 생성자의 가중치를 업데이트
   결국 생성자는 판별자를 속이도록 훈련.




















 









