# chapter_16 성능
- R은 빠른 속도의 언어가 아니다. 이것은 우연이 아니다
- R은 의도적으로 사용자들이 데이터 분석과 통계적 분석을 비교적 쉽게 하도록 설계되었다
- 컴퓨터를 더 편하게 다루기 위해 고안된 것이 아님

## 16.1 R은 왜 느린가? 
- R의 성능에 대해 이해하기 위해 언어로서와 그 언어의 구현으로서 R에 대해 생각해 보는 것이 도움이 됨
- R 언어는 추상적이다. R 언어는 R 코드가 의미하는 바와 동작하는 방법을 정의함
- 그 구현은 견고하다. 즉 R 코드를 읽어 결과를 계산함
- R 언어가 공식적으로 정의되어 있지 않기 때문에 R 언어와 GNU R의 구별은 다소 분명하지 않음
- R 언어 정의가 있기는 하지만 그것은 형식적이지 않고 불완전함
- R언어는 거의 대부분 GNU R이 동작하는 방법에 따라 정의되어 있음
- 이것은 언어가 동작해야 하는 방법의 모든 측면을 아주 상세하게 묘사하고 공식적 요건을 규정함으로써 언어와 구현 간의 명확한 구분을 하고 있는 C++과 Javascript 같은 다른 언어와는 대조됨
- 그럼에도 불구하고, R 언어와 GNU R 간의 구분은 여전히 유용
- 즉 언어의 낮은 성능은 현재의 코드를 수정하기 전에는 개선하기 어려우므로 구현에 따라 낮은 성능을 수정하는 것이 더 좋음
- 디자인과 구현에 따른 성능 제약 이외에도, 많은 R 코드는 단순히 느리다
- 왜냐하면 그렇게 쓰여졌기 때문. 프로그래밍이나 소프트웨어 개발에 관한 공식적 훈련을 받은 R 사용자가 거의 없기 때문
- 다음의 장에서 볼 수 있는 것처럼 대부분의 R 코드를 더 빠르게 하기가 상대적으로 쉽다는 것을 의미

## 16.2 마이크로벤치마킹
- 마이크로벤치마크는 실행하는 데 마이크로초(ms)나 나노초(ns) 정도가 걸리는 정도의 매우 작은 코드 조각의 성능 측정치
- 매우 저수준의 R 코드 스니핏의 성능을 설명하기 위해 마이크로 벤치마크를 사용할 것인데,   
  R이 동작하는 방법에 대한 직관을 개선하는 데 도움을 줌
- 이 직관은 전반적으로 실제 코드의 속도를 높이는 데는 유용하지 않음
- 마이크로벤치마크에서 관찰된 차이는 전형적으로 실제 코드의 고차 효과(high-order effect)에 압도됨
- 쉽게 말하면 원자 미만의 물리학에 대한 깊은 이해가 빵을 구울 때 많이 유용한 것은 아님
- R의 마이크로벤치마크를 위한 최고의 도구는 <b>microbenchmark</b> 패키지임
- 이 패키지는 아주 작은 양의 시간이 걸리는 연산을 비교할 수 있도록 하면서 매우 정확한 시점을 제공
- 예를 들어 다음 코드는 제곱근을 계산하는 두 가지 방법의 속도를 비교
~~~r
library(microbenchmark)
x <- runif(100)
microbenchmark(
    sqrt(x),
    x ^ 0.5
)

#> Unit: nanoseconds
#>     expr  min   lq    mean median   uq   max neval
#>  sqrt(x)  600  701 1330.07  801.0  901 18701   100
#>   x^0.5  3401 4000 5171.07 4001.5 4301 22602   100
~~~ 
- 기본값으로 `microbenchmark()`는 각 표현식을 100번 실행
- 실행 과정 중에 이 함수는 표현식의 순서도 무작위로 섞음
- `microbenchmark()`는 그 결과를 최솟값, 1사분위수, 중간값, 3사분위수 그리고 최댓값으로 요약
- 중간값에 초점을 맞추고 가변성에 대한 직관을 얻기 위해 3사분위수와 1사분위수를 사용해라
- 이 사례에서 특수 목적의 `sqrt()`를 사용하는 것이 일반적인 멱승의 연산자보다 빠르다는 것을 알 수 있음
- 모든 마이크로벤치마크에서처럼 단위(units)에 주위 깊게 관심을 기울여라
- 각 계산은 약 800 ns, 또는 10억분의 800초가 걸림. 실행 시간에 대해 마이크로벤치마크의 효과를 계산하는데 도움이 되기 위해, 1초가 걸리기 전에 실행할 필요가 있는 함수가 얼마나 많은 지에 대해 생각해 보는 것이 유용
- 마이크로벤치마크가
  - 1ms면 1000번 호출이 1초
  - 1Ms면 100만번 호출이 1초
  - 1ns면 10억번 호출이 1초

## 16.3 언어 성능
- 이 절에서는 R 언어의 성능을 제한하는 세 가지 상충관계(<b>극도의 다이나미즘(dynamism), 가변 환경에서 이름 찾기, 함수 인자의 느슨한 평가</b>)에 대해 탐구해 볼 것임
- 얼마나 GNU R의 속도가 느린지를 보여 주는 마이크로벤치마크로 각 상충효과를 설명할 것임
- GNU R을 벤치마크 대상으로 하는데, R 언어를 벤치마크할 수는 없기 때문
- 이것은 결과가 단지 그 설계에 따른 비용인 것을 시사하지만 그럼에도 불구하고 유용하다는 것을 의미
- 반드시 속도, 유연성, 구현의 용이성 간의 균형을 맞춰야 한다는 언어 설계의 핵심인 상충관계를 설명하기 위해 이런 세 가지 사례를 선정하였음

### 16.3.1 극도의 다이나미즘(dynamism)
- R은 극도로 동적인 프로그래밍 언어임
- 거의 모든 것이 생성된 이후에 수정될 수 있음. 몇 가지 사례만 갖고도 다음의 것들을 할 수 있음
  - 본문, 인자, 함수의 환경의 변경
  - 제너릭으로 S4 메소드를 변경
  - S3 객체에 새로운 필드를 추가하거나 그 클래스를 변경
  - <<- 으로 환경 외에 객체를 수정
- 유일하게 많이 변경되지 못하는 것은 <b>보호된 네임스페이스(sealed namespace)</b>의 객체인데 이것은 패키지를 로드할 때 생김
- 다이나미즘의 장점은 사전 계획을 최소화 할 수 있다는 점
- 새롭게 시작할 필요없이 풀이에 대한 풀이를 반복하면서 언제라도 바꿀 수 있음
- 다이나미즘의 단점은 주어진 함수 호출로 인해 무슨 일이 벌어질지 정확하게 예측하기가 어렵다는 점
- 어떤 일이 일어날 지 예측하기가 쉬울 수록 인터프리터나 컴파일러가 최적화하기 쉬우므로, 이런 다이나미즘이 문제가 될 수 있음
- 인터프리터가 앞으로 어떻게 될지 예측하지 못하면 올바른 것을 찾기 전에 많은 대안을 고려해야만 함
- 예를 들어 다음의 루프는 R에서 느린데, x가 항상 정수형인지 문자형인지 R은 알 수 없기 때문
- 이것은 모든 루프 순환에서 R이 올바른 + 메소드를 찾아야 한다는 것을 의미함
~~~r
x <- 0L
for (i in 1:1e6){
    x <- x + 1
}
~~~
- 올바른 메소드를 찾는 비용은 원시 함수가 아닌 경우에 더 큼
- 다음의 마이크로벤치마크는 S3, S4 그리고 RC에 대한 메소드 디스패치의 비용을 묘사 한 것
- 각 OO 시스템에 대한 제너릭과 메소드를 생성하고 난 뒤 제너릭을 호출하여 메소드를 찾고 호출하는 데 시간이 얼마나 걸리는지 보았음
~~~r
f  <- function(x) NULL              #- 시험된 함수
s3 <- function(x) UseMethod("s3")
s3.integer <- f

A <- setClass("A", representation(a = "list"))
setGeneric("s4", function(x) standardGeneric("s4"))
setMethod(s4, "A", f)

B <- setRefClass("B", methods = list(rc = f))

a <- A()
b <- B$new()

microbenchmark(
    fun = f(),
    S3  = s3(1L),
    S4  = s4(a),
    RC  = b$rc() 
)

#> Unit: nanoseconds
#> expr  min     lq     mean median   uq    max neval
#>  fun  100  200.0   222.98    201  202   1101   100
#>   S3 2301 2501.0  9772.14   2602 2801 712001   100
#>   S4 1100 1301.0  8204.96   1601 1701 653301   100
#>   RC 7401 7701.5 10569.95   8101 8301 234701   100
~~~
- S3와 S4 메소드 디스패치는 시간이 많이 걸리는데 제너릭을 호출할 때 마다 R이 매번  
  올바른 메소드를 찾아야 하기 때문
- R은 호출 간 메소드를 캐싱해 보다 좋은 성능을 보일 수 있지만,  
  캐싱을 제대로 하는 것은 어려운 일이고, 악명 높은 버그의 원인임

### 16.3.2 가변 환경으로 이름 탐색
- R 언어에서 이름과 관련된 값을 찾는 것은 놀라울 정도로 어려운 일
- 이것은 렉시칼 스코핑과 극도의 다이나미즘이 결합되었기 때문
- 아래의 사례를 살펴보자. 각각의 경우에 다른 환경으로부터의 a를 출력함
~~~r
a <- 1
f <- function(){
    g <- function(){
        print(a)
        assign("a", 2, envir = parent.frame())
        print(a

        a <- 3
        print(a)
    }
    g()
}
f()
#> [1] 1
#> [1] 2
#> [1] 3
~~~ 
- 이는 이름 탐색을 단번에 할 수 없다는 것을 의미
- 즉, 매번 처음부터 시작해야 함
- 이 문제는 거의 모든 연산이 렉시칼하게 스코핑된 함수 호출이라는 사실로 더욱 심해짐
- 다음의 간단한 함수는 +와 ^ 두 개 함수를 호출한다고 생각할 것임
- 실제로는 네 개의 함수를 호출하는데, {와 (이 R에서 정규 함수이기 때문
~~~r
f <- function(x, y){
    (x + y) ^ 2
}
~~~
- 이런 함수는 전역 환경에 있는 것이기 때문에 R은 탐색 경로의 모든 환경을 통해 찾아야 하고, 그것은 쉽게 10개 또는 20개의 환경이 될 수 있음
- 다음의 마이크로벤치마크는 성능 비용에 대한 힘트를 제시해 준다
- f()의 환경과 +, ^, (, 그리고 {가 정의된 베이스 환경 사이에서 하나 이상의 환경으로 네 가지 버전의 f()를 생성하였음
~~~r
f <- function(x, y){
  (x + y) ^ 2
}

random_env <- function(parent = globalenv()){
  letter_list <- setNames(as.list(runif(26)), LETTERS)
  list2env(letter_list, envir = new.env(parent = parent))
}


set_env <- function(f, e){
  environment(f) <- e
  f
}

f2 <- set_env(f, random_env())
f3 <- set_env(f, random_env(environment(f2)))
f4 <- set_env(f, random_env(environment(f3)))

microbenchmark(
  f(1, 2),
  f2(1, 2),
  f3(1, 2),
  f4(1, 2),
  times = 10000
)

#> Unit: nanoseconds
#>     expr   min  lq   mean   median  uq     max neval
#>   f(1, 2)  300  400 668.42    400   400 1901000 10000
#>   f2(1, 2) 700  700 880.54    800   800   20700 10000
#>   f3(1, 2) 700  800 904.26    800   800   22300 10000
#>   f4(1, 2) 700  800 980.95    800   900   66000 10000
~~~
- `f()`와 베이스 환경 간의 추가적인 환경은 약 30ns까지 함수를 느리게 함
- R이 오로지 각 이름의 값을 한 번만에 찾을 필요가 있도록 캐싱 시스템을 구축할 수 있을지도 모름
- 이것은 어려운 일인데, `<<-`, `assign()`, `eval()` 그리고 기타 이름과 관련된 값을 변경하는 방법은 너무나 많기 때문
- 어떤 캐싱 시스템은 캐시가 올바로 무효화하고 시간이 지난 값을 얻지는 않았는지를 확실히 하기 위해 이런 함수들에 대해 알아야 할지도 모름
- 다른 간단한 수정은 덧쓸 수 없는 내장 제약 조건을 더 추가할 것임
- 예를 들어 R이 항상 정확하게 `+`, `-`, `{`, 그리고 `(`가 의미하는 것이 무엇인지 알고 반복적으로 그 정의를 찾을 필요가 없다는 것을 의미
- 이것은 인터프리터를 보다 복잡하게 하므로(특별한 경우가 더 많기 때문에) 유지보수하기 어렵게 되고, 언어가 덜 유연하게 됨
- 이것은 R 언어를 변경할 수 있지만, `{`와 `(`같은 함수를 덧쓰는 것은 좋지 않은 아이디어이기 때문에 기존의 많은 코드에 거의 영향을 미치지 않음

### 16.3.3 느슨한 평가의 간접적 부하
- R에서 함수 인자는 느슨하게 평가됨
- 느슨한 평가를 구현하기 위해 R은 결과를 계산하는데 필요한 표현식과 그 계산이 수행될 환경을 포함하고 있는 프로미스 객체를 사용
- 이런 객체를 생성하는 것은 다소 간접적 부하가 발생하여 함수에 대한 추가적인 각 인자가 그 속도를 감소시킴
- 다음의 마이크로벤치마크는 아주 간단한 함수의 런타임을 비교한 것
- 각 함수 버전은 하나의 추가적 인자를 가짐
- 추가적 인자를 더하는 것은 함수를 20ns까지 저하시킨다는 것을 보여줌
~~~r 
f0 <- function() NULL
f1 <- function(a = 1) NULL
f2 <- function(a = 1, b = 1) NULL
f3 <- function(a = 1, b = 2, c = 3) NULL
f4 <- function(a = 1, b = 2, c = 4, d = 4) NULL
f5 <- function(a = 1, b = 2, c = 4, d = 4, e = 5) NULL
microbenchmark(f0(), f1(), f2(), f3(), f4(), f5(), times = 10000)

 #> expr min  lq   mean median  uq    max neval
 #> f0() 100 200 283.20    200 200 735600 10000
 #> f1() 200 200 345.07    300 300 502700 10000
 #> f2() 200 300 406.70    300 300 571300 10000
 #> f3() 200 300 479.47    300 400 538400 10000
 #> f4() 300 400 523.55    400 400 542600 10000
 #> f5() 300 400 593.21    400 500 578000 10000
~~~
- 대부분의 다른 프로그래밍 언어에서 추가적 인자를 더하는 것은 간접 효과가 없음
- 컴파일된 많은 언어들이 (위의 사례에서처럼) 인자가 절대 사용되지 않으면 경고를 보내고 자동으로 그 인자들을 제거

## 16.4 구현 성능
- R 언어의 디자인은 최대 이론적 성능을 제한하고 있지만, 현재의 GNU R은 그 최대치 근처에도 있지 않음
- 즉 성능을 개선하기 위해서 할 수 있는 것들을 많이 있다는 것임
- 이 절에서는 정의 때문이 아니라 구현 때문에 느린 GNU R의 몇가지 측면을 알아본다
- R은 20년 이상이 되었음. R은 거의 80억 줄의 코드(C가 45%, R이 20%, 포트란 35%)로 되어 있음
- 현재 R-core는 20명의 맴버를 갖고 있지만, 오로지 6명만 매일 개발에 참여하고 있음
- R-core중 누구도 R에 전속으로 일하고 있지 않음
- 대부분은 통계학 교수들임. 기존의 코드를 깨지 않아야 한다는 조심성 때문에 R-core는 새로운 코드에 대해 매우 보수적인 경향이 있음
- R-core는 R을 빠르게 하는 것이 아니라 데이터 분석과 통계에 대한 안정적인 플랫폼을 구축하는 것
- 현재는 느리지만, 작은 노력으로 빠르게 할 수 있는 R의 작지만 설명하기에 좋은 사례 일부분을 보일 것임
- 이것은 base R에 중요한 부분이 아니지만, 과거에는 좌절의 원인이 되었던 것.
- 이것들은 대부분의 코드 성능에 영향을 미치진 않지만 특별한 경우에는 중요할 수 있음

### 16.4.1 데이터 프레임에서 값 하나를 추출하기
- 다음의 마이크로벤치마크는 내장 데이터 세트인 mtcars에서 단일 값에 접근하는 다섯 가지 방법을 보여줌
- 성능의 차이는 놀랄 만하다. 즉 가장 느린 방법은 가장 빠른 방법에 비해 30배 이상 오래 걸림
- 성능에 있어서 그런 큰 차이를 가질 이유는 없음. 단순히 이 차이를 수정할 시간이 없었던 것
~~~r
microbenchmark(
"[32, 11]"      = mtcars[32, 11],
"$carb[32]"     = mtcars$carb[32],
"[[c(11, 32)]]" = mtcars[[c(11, 32)]],
"[[11]][32]"    = mtcars[[11]][32],
".subset2"      = .subset2(mtcars, 11)[32]
)

#> Unit: nanoseconds
#>          expr  min    lq  mean median    uq     max neval
#>      [32, 11] 9900 10200 11041  10400 10850   35000   100
#>     $carb[32] 1000  1300  1403   1400  1400    6100   100
#> [[c(11, 32)]] 4800  5000  5770   5200  5550   37000   100
#>    [[11]][32] 4600  4800 93683   5100  5400 8855000   100
#>      .subset2  200   300   312    300   300     800   100
~~~

### 16.4.2 ifelse(), pmin(), pmax()
- 몇 가지 베이스 함수는 느리다고 알려져 있음
- 예를 들어 벡터의 가장 작은 값이 최소한 a이고, 가장 큰 값이 최대한 b인 것을 확인하는 함수인 `squish()`의 세 가지 구현을 살펴보자
- 첫번째 구현인 `squish_ife()`는 `ifelse()`를 사용함. `ifelse()`는 상대적으로 일반적이고, 모든 인자를 충분히 평가해야 하기 때문에 느리다고 알려져 있음
- 두 번째 구현인 `squish_p()`는 `pmin()`과 `pmax()`를 사용함
- 이 두 함수는 매우 특화되어 있기 때문에 빠를 수 있다고 예상할 수 있음  
  그러나 실제로는 느린 편임. 이것들의 어떤 수의 인자도 취할 수 있고 어떤 메소드를 사용할지 판단하는 데 상대적으로 복잡한 확인을 거쳐야 하기 때문  
- 마지막 구현은 기본 하위 할당을 사용
~~~r
squish_ife <- function(x, a, b){
  ifelse(x <= a, a, ifelse(x >= b, b, x))
}

squish_p <- function(x, a, b){
  pmax(pmin(x, b), a)
}

squish_in_place <- function(x, a, b){
  x[x <= a] <- a
  x[x >= b] <- b
  x
}

x <- runif(100, -1.5, 1.5)
microbenchmark(
  squish_ife  =  squish_ife(x, -1, 1),
  squish_p    =  squish_p(x, -1, 1),
  squish_in_place = squish_in_place(x, -1, 1),
  unit = "us"
)
#> Unit: microseconds
#>            expr  min    lq   mean   median   uq    max   neval
#>      squish_ife  14.2 15.00 45.333  15.55   16.4 2895.5   100
#>        squish_p  12.3 13.05 31.006  13.70   14.1 1680.3   100
#>  squish_in_place  2.3  2.80 27.499   3.10    3.3 2434.1   100  
~~~
- `pmin()`과 `pmax()`를 사용하는 것이 `ifelse()`보다 약 세 배 더 빠르고 서브세팅을 직접 사용하는 것이 약 두 배 더 빠르다
- 종종 C++를 이용하여 더 빠르게 구현할 수 있음
- 다음의 사례는 정리된 것이 아니지만, 상대적으로 단순한 C++ 구현과 최선의 R 구현을 비교함
- 심지어 C++를 한번도 써본 적이 없더라도 여전히 이 기본적 전략을 따를 수 있어야 함
- 즉 벡터의 모든 요소를 반복하고 그 값이 a 보다 작거나 b보다 큰지에 따라 다른 행동을 수행해야 함
~~~cpp
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
NumericVector squish_cpp(NumericVector x, double a, double b){
    int n = x.length();
    NumericVector out(n);

    for(int i = 0; i < n; ++i){
        double xi = x[i];
        if (xi < a){
            out[i] = a;
        }else if(xi > b){
            out[i] = b;
        }else{
            out[i] = xi;
        }
    }

    return out; 
}
~~~
~~~r
microbenchmark(
    squish_in_place = squish_in_place(x, -1, 1),
    squish_cpp      = squish_cpp(x, -1, 1),
    unit            = "us"
)
~~~
- C++ 구현이 순수한 R 구현보다 약 두 배 더 빠름

## 16.5 대체적 R 구현
- 몇 가지의 흥미롭고 새로운 R 구현이 있음
- 이것은 모두 최대한 기존의 언어 정의가 가깝게 유지하려고 하지만, 모던한 인터프리터 설계로부터 아이디어를 적용하여 속도를 개선함
- 가장 성숙한 네 개의 오픈 소스 프로젝트는 다음과 같음
  - Radford Neal의 <b>pqR</b>. R 2.15.0에서 구축된 이것은 많은 명백한 성능 이슈를 수정하고, 보다 나은 메모리 관리와 자동화된 멀티쓰레딩 지원을 제공
  - BeDataDriven의 <b>Renjin</b>. Renjin은 Java 가상 머신을 사용하여 포괄적 테스트 도구를 갖고 있음
  - Purdue 대학의 한 팀에 의해 개발되고 있는 <b>FastR</b>. FastR은 Renjin과 유사하고, 보다 명백하게 최적화를 달성했지만, 아직 다소 덜 성숙되어 있음
  - Justin Talbot과 Zachary Devito의 <b>Riposte</b>. Riposte는 실험적이고 의욕적임  
    이것으로 구현한 R의 일부분은 극도로 빠름  
- pqR, Renjin, FastR, Riposte가 탐구하는 가장 중요한 접근법 중 하나는 지연된 평가(defered evaluation)  아이디어임  
- Riposte의 저자인 Justin Talbot은 다음과 같이 지적함  
  "길이가 긴 벡터의 경우 R의 실행은 완전히 메모리 제약적. 메모리를 매개로 벡터를 읽고 쓰는 데 거의 대부분의 시간을 소비함"
- 이런 매개 벡터를 제거할 수 있다면 성능을 향상시키고 메모리 사용을 감소시킬 수 있음
- 아래의 사례는 지연된 평가가 도움을 줄 수 있는 방법에 대한 아주 간단한 사례를 보여줌
- 100만 개의 요소를 가지는 x, y, z라는 세 개의 벡터가 있고 z가 TRUE일 때 x + y의 합을 찾기 원한다고 하자
~~~r
x <- runif(1e6)
y <- runif(1e6)
z <- sample(c(T, F), 1e6, rep = TRUE)

sum((x + y)[z])
~~~ 
- R에서 이것은 100만 개 요소의 x +  y와 50만 개 요소의 (x + y)[z], 두 개의 큰 임시 벡터를 생성함
- 이것은 중간 계산이 가능한 추가적 메모리가 필요하다는 것을 의미하고 CPU와 메모리 사이를 오가며 데이터를 이동해야 함
- CPU가 계산할 데이터가 더 들어오기를 항상 대기한다면 최대의 효율로 동작할 수 없기 때문에 이런 점은 계산을 느리게 함
- 그러나 C++ 같은 언어에서 반복을 사용하여 함수를 재작성하면 단지 하나의 매개값이 필요할뿐인데 그것은 이미 봤던 모든 값들의 합
- 테스트 환겨에서 이 C++의 접근은 벡터화된 R보다 약 두 배 빠른데, 이는 정말 빠른 것임
- 지연된 평가의 목표는 이런 변형을 자동으로 수행해 간단한게 R 코드를 작성하고, 자동으로 효율적인 기계 코드로 번역하는 것
- 정교한 번역자는 멀티 코어의 대부분을 사용할 수 있게 하는 방법도 알아낼 수 있음
- 위의 사례에서 4코어를 갖고 있다면 각 코어에서 조건부 합을 수행하고, 네 개의 개별 결과를 나중에 합하도록 x, y, z를 네 개의 조각으로 분할할 수도 있음
- 지연된 평가는 또한 벡터화될 수 있는 연산을 자동으로 탐색하는 루프로도 동작할 수 있음

## 용어 정리
- GNU
  - GNU(그누)는 운영 체제의 하나이자 컴퓨터 소프트웨어의 모음집을 뜻함